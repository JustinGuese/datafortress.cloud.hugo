<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>serverless on Datafortress.cloud</title><link>https://datafortress.cloud/tags/serverless/</link><description>Recent content in serverless on Datafortress.cloud</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor/><webMaster/><lastBuildDate>Fri, 17 Jun 2022 11:10:07 +0600</lastBuildDate><atom:link href="https://datafortress.cloud/tags/serverless/index.xml" rel="self" type="application/rss+xml"/><item><title>Going from Wordpress to serverless, unhackable high-speed static websites</title><link>https://datafortress.cloud/blog/wordpress-to-serverless-highspeed-scalable-unhackable/</link><pubDate>Fri, 17 Jun 2022 11:10:07 +0600</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/blog/wordpress-to-serverless-highspeed-scalable-unhackable/</guid><description>
&lt;h1 id="going-from-wordpress-to-serverless-unhackable-high-speed-static-websites">Going from Wordpress to serverless, unhackable high-speed static websites&lt;/h1>
&lt;p>I have been building websites in the past, but have always been struggling with the slow performance of WordPress. If it is loaded with plugins, it will need quite some resources and can be a pain if you are just developing an idea on a small server.&lt;/p>
&lt;p>Additionally, safety is of concern as well, and as a system that &lt;a href="https://en.wikipedia.org/wiki/WordPress">33,6% of websites are using&lt;/a>, it is quite attractive for hackers to find exploits and other issues in it.
But again, as it is massively popular, there is almost every time a plugin for the issues you are having, which makes it easy to use, and a great &amp;ldquo;all-in-one&amp;rdquo; tool.&lt;/p>
&lt;h2 id="idea-1-improving-wordpress-development">Idea 1: Improving WordPress Development&lt;/h2>
&lt;p>One of the first things I did in the past has been to develop WordPress locally (e.g. &lt;a href="https://www.smashingmagazine.com/2018/04/wordpress-local-development-beginners-setup-deployment/">see this AWS post&lt;/a>), and then just publish the result on a server. Programming and writing speeds increased enormously, but the uploading part proved to be a problem, as WordPress links are usually &amp;ldquo;hardwired&amp;rdquo; into the SQL database it uses. Meaning all my links were referring to &amp;ldquo;&lt;a href="https://www.datafotress.cloud">https://www.datafotress.cloud&lt;/a>&amp;rdquo; (My Computer) instead of the target domain. There are ways to solve this, like rewriting your URLs in SQL, or using rewriting htaccess rules to refer &amp;ldquo;old&amp;rdquo; URLs to the &amp;ldquo;new&amp;rdquo; ones, but still, it was a lot of struggle to get going.&lt;/p>
&lt;h2 id="idea-2-online-development-with-offloaded-media-files">Idea 2: Online Development with Offloaded Media files&lt;/h2>
&lt;p>This URL rewriting issue got on my nerves real quick, and local development is bad for multiple developers. That is why I decided to &amp;ldquo;go online&amp;rdquo; again, and work &amp;ldquo;with the cloud&amp;rdquo;. The architecture I followed has been to deploy one development server, that is only accessible to developers, and to upload media files to shared storage (AWS S3) from which end users are pulling the media files. As media files (pictures, videos, &amp;hellip;) are the most demanding parts of WordPress, speed increased drastically, and additionally, it has been easy to set up a CDN on top of it, which basically means the media files are deployed all over the world at unlimited capacity (basically serverless). This means, that one user in e.g. Puerto Rico does not need to access my server in Frankfurt, but has a &amp;ldquo;local&amp;rdquo; copy close to him. Additionally, as the &amp;ldquo;heavy&amp;rdquo; part of WordPress has been &amp;ldquo;outsourced&amp;rdquo;, only &amp;ldquo;small&amp;rdquo; servers were needed to handle PHP requests and the &amp;ldquo;back-office&amp;rdquo; parts of WordPress. Feel free to ask me more about it in the comments or a direct message, or &lt;a href="https://devops.com/hosting-scalable-wordpress-on-aws/">check out a similar approach by AWS&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://datafortress.cloud/images/blog/Webp.net-resizeimage.png" alt="Architecture for wordpress on AWS">&lt;/p>
&lt;p>Together with Autoscaling, this seemed to be the most ideal setup for WordPress, and it proved great. BUT&amp;hellip;&lt;/p>
&lt;p>You still had to check for Plugin Updates, Security, and Monitoring in general. Even though AWS helps a lot to make this architecture quite resilient and fast, there is still a high operational demand. Additionally, running a separate development, database, load balancing, and so on the server can be quite cost expensive, especially for a website that does not have many users.
And what did Werner Vogels say at re:invent 2015?&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>&amp;ldquo;No server is easier to manage than no server&amp;rdquo;&lt;/strong>&lt;/p>
&lt;p>Werner Vogels at re:invent 2015&lt;/p>
&lt;/blockquote>
&lt;h2 id="excursion-a-brief-history-of-the-code-of-web">Excursion: A brief history of the Code of web&lt;/h2>
&lt;p>WordPress is great for writers and editors, but form the perspective of a solution architect it is not great. Why? Even though everything is clickable, easy to handle, and so on, all resources and information are pulled from a database in the background, even though if it is pulled for the 100000th time this day. There are methods to reduce the query load on SQL databases, like Redis and Memcached, but why should I &amp;ldquo;calculate&amp;rdquo; the same webpage for every single user? &amp;ldquo;Back in the day&amp;rdquo;, websites did just load in seconds (except someone has been on the phone) and they were super small - what has changed? Together with new design demands, today&amp;rsquo;s websites are full of effects and designs that are heavy on computational resources. Even though this is definitely an improvement to the 90s black and white style, loading times of websites increased dramatically - especially as the world&amp;rsquo;s connection standard is still mobile network.&lt;/p>
&lt;p>To render all the effects, PHP code is used in the background, which is code executed on the server itself. Meaning every time a user connects to a website, the server is calculating the website it is going to show to the user. The 90s version of websites featured just plain HTML code, which are basically simple instructions to the browser on how to handle things. Like the &lt;!-- raw HTML omitted --> tag tells the browser this is a heading, and &lt;!-- raw HTML omitted --> is a paragraph. No (sorry for reducing complexity!) calculations are needed.&lt;/p>
&lt;p>Additionally, Javascript and CSS go a similar path as CSS describes design in a similar approach to HTML, and Javascript is executed not on the server, but on the client-side. Meaning the server does not calculate itself, but &amp;ldquo;sends instructions&amp;rdquo; to the client&amp;rsquo;s browser (e.g. your phone).&lt;/p>
&lt;p>So why don&amp;rsquo;t we use just HTML, Javascript, and CSS? PHP enables us to do a lot of things and allows for content creation frameworks like WordPress to make our lives easier. But the efficient way to produce websites would be to generate them once and then just distribute them already rendered to the masses.&lt;/p>
&lt;h2 id="idea-4-going-back-to-the-roots">Idea 4: Going back to the roots&lt;/h2>
&lt;p>So am I saying we should go back to the black and white HTML pages of the 90s? Of course not, but the combination of HTML and CSS can produce great results, and Javascript becomes more and more capable to handle processes only PHP could handle in the past. And if calculations are needed, there are great new serverless possibilities available like AWS Lambda (check out my blog for some applications of Lambda).&lt;/p>
&lt;p>Going back to the main topic, I have decided to write my blog and any future websites in plain HTML, CSS, and JS, as I do not need to&lt;/p>
&lt;ol>
&lt;li>&lt;strong>manage a server&lt;/strong> - I can just host it for almost free on Github or AWS S3&lt;/li>
&lt;li>&lt;strong>worry about high-demands&lt;/strong> - S3 and Github scale automatically, meaning if thousands of visitors arrive on my website it will not crash my server
pay much - as I do not need as many calculations as with WordPress, running this blog is completely free&lt;/li>
&lt;li>&lt;strong>do not need to worry about security issues&lt;/strong> - my blog is basically unhackable&lt;/li>
&lt;/ol>
&lt;p>Additionally, the website is blazingly fast, with a Google Pagespeed score of 100%, which has a great effect on page ranking as well, as Google favors high-speed websites. The only reason why the current score is down to 90%, is that I decided to include CRM and tracking tools on my blog. When was the last time you saw a free website achieving this score?&lt;/p>
&lt;p>All in all, it is just great, but am I writing all the HTML code by myself?&lt;/p>
&lt;h2 id="introducing-static-website-generators">Introducing: Static Website Generators&lt;/h2>
&lt;p>Of course not, and luckily there are great tools to handle this for me. Static website builders like &lt;a href="https://jekyllrb.com/">Jekyll&lt;/a> or &lt;a href="https://gohugo.io/">Hugo&lt;/a> help a lot to let you basically just type in Markdown language (basically a simple txt file) and convert your texts into HTML and a nice website. The code is just calculated once and can be uploaded to a server, or Github pages and AWS S3 right away to be completely serverless. &lt;a href="https://datafortress.cloud/project/serverless-static-website/">How does it work? Check out my case studies on my blog for an in-depth explanation&lt;/a>.&lt;/p>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>It feels great to not worry about uptime, scaling, and security anymore. Is it harder than WordPress? It depends. As this technology just develops, there is a rethinking to be done if you worked with WordPress and others in the past, but again there are many great tools that make static website builders similar to the &amp;ldquo;known&amp;rdquo; WordPress environment, like forestry.io for example. How? &lt;a href="https://datafortress.cloud/project/serverless-static-website/">Check out my blog at www.datafortress.cloud to see the in-depth explanation&lt;/a>.
For now, I would be interested if you ever tried to go serverless, or what your experiences with WordPress are. &lt;a href="https://datafortress.cloud/contact/">Shoot me a message, or write a comment below&lt;/a>.&lt;/p></description></item><item><title>How to deploy an automated trading bot using the Facebook Prophet Machine Learning model to AWS Lambda (serverless)</title><link>https://datafortress.cloud/blog/how-to-deploy-an-automated-trading-bot-using-the-facebook-prophet-machine-learning-model-to-aws-lambda-serverless/</link><pubDate>Mon, 23 May 2022 22:00:00 +0000</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/blog/how-to-deploy-an-automated-trading-bot-using-the-facebook-prophet-machine-learning-model-to-aws-lambda-serverless/</guid><description>
&lt;p>I divided this post into the “Why did I do it” and the “Technical How To”. If you want to skip the “Why” part, feel free to directly jump to the Technical part.&lt;/p>
&lt;h1 id="why-should-i-deploy-a-machine-learning-model-in-aws-lambda">Why should I deploy a machine learning model in AWS Lambda?&lt;/h1>
&lt;p>&lt;strong>1. Reliability:&lt;/strong> The algorithm will execute independently of other systems, updates, …&lt;/p>
&lt;p>&lt;strong>2. Performance Efficiency:&lt;/strong> I can run several algorithms on one (small) system, independent from each other.&lt;/p>
&lt;p>&lt;strong>3. Cost Savings:&lt;/strong> AWS allows for &lt;a href="https://aws.amazon.com/lambda/?did=ft_card&amp;amp;trk=ft_card">3,2 million compute-seconds&lt;/a> per month, basically letting me run all my algorithms for free.&lt;/p>
&lt;p>I have been searching for a way to first make sure my investment bot surely executes because a failed execution might cost a lot of money if a trade is not canceled promptly if it goes in the wrong direction. Additionally, I wanted to avoid letting my computer run all the time and to make sure several algorithms could run next to each other, without influencing or delaying their execution.&lt;/p>
&lt;p>Furthermore, it is a nice thought to have an investing algorithm run without worrying about operating system updates, hardware failures, and power cuts, etc, which is the general advantage of serverless technologies.&lt;/p>
&lt;p>Right now, I can run several variations of the algorithm to test out alterations of the algorithm and can be sure that it will run. Another nice thing? AWS offers around 1 Million free Lambda calls, which lets me run the whole architecture in its free tier contingent.&lt;/p>
&lt;h2 id="the-investing-algorithm">The investing algorithm&lt;/h2>
&lt;p>I am going to explain the algorithm in more depth in another post on my website &lt;a href="http://www.datafortress.cloud">www.datafortress.cloud&lt;/a>, but my typical investment algorithm setup consists of:&lt;/p>
&lt;ol>
&lt;li>Testing the algorithm using &lt;a href="https://www.backtrader.com/">Backtrader&lt;/a>, an open-source backtesting framework written in python&lt;/li>
&lt;li>Converting the successful algorithm into a single python file containing a run() method that returns which investments have been done&lt;/li>
&lt;li>Transferring the python file to AWS Lambda, where I am calling the run() function with AWS Lambda’s lambda_handler function&lt;/li>
&lt;/ol>
&lt;p>In this example algorithm, I take investment decisions depending on if the current price is above or below the trendline predicted by &lt;a href="https://facebook.github.io/prophet/">Facebook’s prophet model&lt;/a>. I have &lt;a href="http://seangtkelley.me/blog/2018/08/15/algo-trading-pt2">taken ideas from Sean Kelley&lt;/a>, who wrote a Backtrader setup on how to utilize prophet with Backtrader.&lt;/p>
&lt;p>My stock universe in this setup is calculated by choosing the top 20 stocks out of the SPY500 index, which achieved the highest return in the past X timesteps.&lt;/p>
&lt;p>The data source is Yahoo finance, using the &lt;a href="https://pypi.org/project/yfinance/">free yfinance library&lt;/a>, and as my algorithmic broker of choice, I have chosen &lt;a href="https://alpaca.markets/">Alpaca.markets&lt;/a>.&lt;/p>
&lt;p>In my setup, the algorithm will execute once per day at 3 p.m. or every 15 minutes during trading hours.&lt;/p>
&lt;h3 id="the-problems-deploying-facebook-prophet-to-aws-lambda">The problems deploying Facebook Prophet to AWS Lambda&lt;/h3>
&lt;p>AWS Lambda comes with some python libraries preinstalled, but as many of you might know, this is by default quite limited (which is reasonable for Lambda’s promise). Still, Lambda allows for private packages to be installed which is quite easy for smaller packages (see the &lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/python-package.html">official documentation&lt;/a>) but becomes a little more complicated if dealing with packages that exceed 250 Mb in size. Unfortunately, Facebook’s prophet model exceeds this boundary, but luckily &lt;a href="https://towardsdatascience.com/how-to-get-fbprophet-work-on-aws-lambda-c3a33a081aaf">Alexandr Matsenov solved this issue by reducing the package size&lt;/a> and &lt;a href="https://github.com/marcmetz/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda">Marc Metz handled compilation issues to make it run on AWS Lambda&lt;/a>.&lt;/p>
&lt;p>Non-default libraries can be added to AWS Lambda by using Layers, which contain all the packages needed. If a layer is imported, you can simply import the packages in your python function as you would do it in your local setup.&lt;/p>
&lt;h2 id="how-to-technical">How to (technical)&lt;/h2>
&lt;p>Finally, let me explain how exactly you can achieve this. See this TLDR for the impatient types, or the more detailed version below.&lt;/p>
&lt;p>&lt;strong>TLDR;&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>You will need a Lambda Layer, upload mine (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">download&lt;/a>) containing Prophet, yfinance, … to an S3 bucket (private access)&lt;/li>
&lt;li>Select AWS Lambda, create a function, add a layer and paste in your S3 object URL&lt;/li>
&lt;li>Paste your lambda_function.py into the Lambda Editor (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">or use mine&lt;/a>)&lt;/li>
&lt;li>Set up your Environment variables (optional)&lt;/li>
&lt;li>Either run it manually by clicking “test” or head over to CloudWatch -&amp;gt; Rules -&amp;gt; Create Rule and set up “Schedule Execution” to run it in a specified time interval&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Detailed Explanation&lt;/strong>:&lt;/p>
&lt;h3 id="1-creating-a-custom-layer-for-aws-lambda">1. Creating a custom layer for AWS Lambda&lt;/h3>
&lt;p>You can either use my Lambda layer containing Facebook Prophet, NumPy, pandas, &lt;a href="https://github.com/alpacahq/alpaca-trade-api-python">alpaca-trading-API&lt;/a>, yfinance (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda">GitHub&lt;/a>) or compile your own using the explanation given by &lt;a href="https://medium.com/@marc.a.metz/docker-run-rm-it-v-pwd-var-task-lambci-lambda-build-python3-7-bash-c7d53f3b7eb2">Marc&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Using my Lambda Layer&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>Download the zip file from my &lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">Github repo&lt;/a> containing all packages (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">Link&lt;/a>).&lt;/li>
&lt;li>As you can only directly upload layers to Lambda until the size of 50 Mb, we will first need to upload the file to AWS S3.&lt;/li>
&lt;li>Create a bucket and place the downloaded zip file into it. Access can remain private and does NOT need to be public! Copy the URL to your file (e.g. &lt;a href="https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip" title="https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip">https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip&lt;/a>).&lt;/li>
&lt;li>Log into AWS and go to Lambda -&amp;gt; Layers (&lt;a href="https://eu-central-1.console.aws.amazon.com/lambda/home?region=eu-central-1#/layers">EU central Link&lt;/a>).&lt;/li>
&lt;li>Click “Create layer”, give it a matching name and select “Upload a file from Amazon S3”, and copy the code of step 3 into it. As Runtimes select Python 3.7. Click create.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Compiling your own Lambda Layer&lt;/strong>&lt;/p>
&lt;p>Please &lt;a href="https://medium.com/@marc.a.metz/docker-run-rm-it-v-pwd-var-task-lambci-lambda-build-python3-7-bash-c7d53f3b7eb2">follow the instructions of Marc&lt;/a>.&lt;/p>
&lt;h3 id="2-setting-up-an-aws-lambda-function">2. Setting up an AWS Lambda function&lt;/h3>
&lt;ol>
&lt;li>Open the Lambda Function Dashboard (&lt;a href="https://eu-central-1.console.aws.amazon.com/lambda/home?region=eu-central-1#/functions">EU central Link&lt;/a>) and click “Create function”&lt;/li>
&lt;li>Leave the “Author from scratch” checkbox as is and give it a fitting name.&lt;/li>
&lt;li>In “Runtime”, select Python 3.7, leave the rest as is and click “Create function”.&lt;/li>
&lt;li>In the overview of the “designer” tab, you will see a graphical representation of your Lambda function. Click on the “layers” box below it and click “Add a layer”. If you correctly set up the layer, you will be able to select it in the following dialogue. Finally, click on “Add”.&lt;/li>
&lt;li>In the “designer” tab, select your Lambda Function. If you scroll down, you will see a default python code snippet in a file called “lambda_function.py”. If you have structured your code the same as mine (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">Link&lt;/a>), you can execute your function with the run() function. If a Lambda function is called, it will execute the lambda_handler(event, context) function from which you could e.g. call the run() function. Of course, you can rename all files and functions, but for the simplicity of this project, I left it as it is.&lt;/li>
&lt;li>Feel free to just paste in &lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">my function&lt;/a> and test it.&lt;/li>
&lt;li>Clicking on “Test” should result in successful execution, otherwise, it will state the errors in the dialogue.&lt;/li>
&lt;/ol>
&lt;h3 id="3-using-environment-variables-in-aws-lambda">3. Using environment variables in AWS Lambda&lt;/h3>
&lt;p>You should never leave your user and password as cleartext in your code, which is why you should always use environment variables! Luckily, Lambda uses them as well, and they can easily be called with the python os package. E.g. in my script I am calling the user variable with os.environ[&amp;lsquo;ALPACAUSER&amp;rsquo;]. The environment variables can be set up in the main Lambda function screen when scrolling down below your code editor.&lt;/p>
&lt;h3 id="4-trigger-aws-lambda-functions-at-a-specified-time-interval">4. Trigger AWS Lambda functions at a specified time interval&lt;/h3>
&lt;p>The concept of serverless and AWS Lambda is built on the idea that a function is executed when a trigger event happens. In my setup, I wanted the function to be called e.g. every 15 minutes during trading hours, Monday to Friday. Luckily, AWS offers a way to trigger an event without the need to run a server, using the CloudWatch service.&lt;/p>
&lt;ol>
&lt;li>Head over to CloudWatch (&lt;a href="https://eu-central-1.console.aws.amazon.com/cloudwatch/home?region=eu-central-1">EU central Link&lt;/a>).&lt;/li>
&lt;li>In the left panel, select “Events” and “Rules”.&lt;/li>
&lt;li>Click on “Create Rule”, and select “Schedule” instead of “Event pattern”. Here you can use the simple “Fixed-rate” dialogue, or create a cron expression. I am using &lt;a href="https://crontab.guru/" title="https://crontab.guru/">https://crontab.guru/&lt;/a> (free) to create cron expressions. My cron expression for the abovementioned use case is “0/15 13-21 ? * MON-FRI *”.&lt;/li>
&lt;li>In the right panel, select “Add Target” and select your Lambda function. It will automatically be added to Lambda.&lt;/li>
&lt;li>Finally click on “Configure details”, give it a name, and click on “Create rule”.&lt;/li>
&lt;/ol>
&lt;h3 id="5-optional-log-analysis-error-search">5. (optional) Log Analysis, Error Search&lt;/h3>
&lt;p>If you have made it to this part, you should be done! But if you want to check if everything worked, you can use CloudWatch to have a look at the outputs of the Lambda functions. Head over to CloudWatch -&amp;gt; Logs -&amp;gt; Log groups (&lt;a href="https://eu-central-1.console.aws.amazon.com/cloudwatch/home?region=eu-central-1#logsV2:log-groups">EU central Link&lt;/a>) and select your Lambda function. In this overview, you should be able to see the output of your functions.&lt;/p>
&lt;p>If you have liked this post leave a comment or head over to my blog &lt;a href="http://www.datafortress.cloud">www.datafortress.cloud&lt;/a> to keep me motivated 😊.&lt;/p></description></item></channel></rss>