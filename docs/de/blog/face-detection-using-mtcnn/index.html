<!doctype html><html><head><title>Gesichtserkennung mittels MTCNN</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=description content="Gesichtserkennung mittels MTCNN - eine Anleitung mit Fokus auf Geschwindigkeit"><link rel=canonical href=https://datafortress.cloud/de/blog/face-detection-using-mtcnn/><link rel=alternate href=https://datafortress.cloud/de/blog/face-detection-using-mtcnn/ hreflang=de-de><link rel=icon type=image/png href=https://datafortress.cloud/images/logo.webp><meta property="og:title" content="Gesichtserkennung mittels MTCNN"><meta property="og:description" content="Gesichtserkennung mittels MTCNN - eine Anleitung mit Fokus auf Geschwindigkeit"><meta property="og:type" content="article"><meta property="og:url" content="https://datafortress.cloud/de/blog/face-detection-using-mtcnn/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2022-05-08T07:10:46+02:00"><meta property="article:modified_time" content="2022-07-07T21:15:36+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Gesichtserkennung mittels MTCNN"><meta name=twitter:description content="Gesichtserkennung mittels MTCNN - eine Anleitung mit Fokus auf Geschwindigkeit"><script type=application/ld+json>{"@context":"https://schema.org/","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/datafortress.cloud\/de\/blog\/face-detection-using-mtcnn\/"},"headline":"Gesichtserkennung mittels MTCNN","description":"Gesichtserkennung mittels MTCNN - eine Anleitung mit Fokus auf Geschwindigkeit","image":[],"datePublished":"2022-05-08T07:10:46\u002b02:00","dateModified":"2022-07-07T21:15:36\u002b02:00","author":{"@type":"Person","name":"Justin Guese"},"publisher":{"@type":"Organization","name":"Datafortress.cloud","logo":{"@type":"ImageObject","url":"https:\/\/datafortress.cloud\/images\/logo.webp"}}}</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.4/css/bulma.min.css><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.13.1/css/all.css integrity=sha384-xxzQGERXS00kBmZW/6qxqJPyxW3UR0BPsL4c8ILaIWXva5kFi7TxkIIaMiKtqV1Q crossorigin=anonymous><link rel=stylesheet href=https://datafortress.cloud//css/style.css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js></script></head><body><header><nav class=navbar><div class=navbar-brand><a class=navbar-item href=https://datafortress.cloud/ title=Datafortress.cloud><img src=https://datafortress.cloud/images/logo.webp alt="VR, Big-Data and Cloud for your Business."></a>
<a href=https://datafortress.cloud/ title="VR, Big-Data and Cloud for your Business." class=navbar-item><span class=is-size-4>Datafortress.cloud</span></a>
<a href=https://datafortress.cloud/contact class=navbar-item title="RSS feed"><span class="icon fa-lg has-text-dark"><i class="fa fa-envelope"></i></span></a>
<a href=https://datafortress.cloud/index.xml class=navbar-item title="RSS feed"><span class="icon fa-lg has-text-dark"><i class="fa fa-rss"></i></span></a>
<a role=button class=navbar-burger aria-label=menu aria-expanded=false><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div class="navbar-menu navbar-end"><a href=https://datafortress.cloud/products class=navbar-item>Products</a>
<a href=https://datafortress.cloud/services class=navbar-item>Services</a>
<a href=https://datafortress.cloud/project class=navbar-item>Portfolio</a>
<a href=https://datafortress.cloud/blog class=navbar-item>Blog</a>
<a href=https://datafortress.cloud/contact class=navbar-item>Contact</a>
<a href=https://datafortress.cloud/ class=navbar-item>about</a></div></nav><script>$(document).ready(function(){$(".navbar-burger").click(function(){$(".navbar-burger").toggleClass("is-active"),$(".navbar-menu").toggleClass("is-active")})})</script></header><main><article><div class="columns is-centered"><div class="column max-800px"><section class=section><h1 class="title is-2">Gesichtserkennung mittels MTCNN</h1><div class="columns is-tablet"><div class="columns is-mobile"><div class="column is-narrow"><figure class="image is-64x64"><img class=is-rounded src=https://datafortress.cloud/images/logo.webp alt="Justin Guese" title="Justin Guese"></figure></div><div class=column><p>Justin Guese |
<time datetime=2022-05-08>8 May 2022</time><br><time datetime=2022-07-07><span class=has-text-grey-light>Last Updated | 7 July 2022</span></time><br><span class=has-text-grey-light>1269 words | 6 minutes</span></p></div></div></div><div class="tags is-pulled-left"><a class="tag is-primary" href=https://datafortress.cloud/categories/computer-vision/>Computer Vision</a>
<a class="tag is-primary" href=https://datafortress.cloud/categories/big-data/>Big Data</a>
<a class="tag is-primary" href=https://datafortress.cloud/categories/machine-learning/>Machine Learning</a></div><div class="tags is-pulled-right"><a class="tag is-info" href=https://datafortress.cloud/tags/face-detection/>Face Detection</a>
<a class="tag is-info" href=https://datafortress.cloud/tags/neuronal-networks/>Neuronal Networks</a>
<a class="tag is-info" href=https://datafortress.cloud/tags/mtcnn/>MTCNN</a>
<a class="tag is-info" href=https://datafortress.cloud/tags/big-data/>Big Data</a>
<a class="tag is-info" href=https://datafortress.cloud/tags/machine-learning/>Machine Learning</a></div></section><section class=content><h1 id=was-ist-mtcnn>Was ist MTCNN</h1><p>MTCNN ist eine Python (pip)-Bibliothek, die von [Github-Benutzer ipacz] (<a href=https://github.com/ipazc/mtcnn>https://github.com/ipazc/mtcnn</a>) geschrieben wurde und die [das Papier Zhang, Kaipeng et al. &ldquo;Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks&rdquo; implementiert. IEEE Signal Processing Letters 23.10 (2016): 1499-1503. Querverweis. Web](<a href=https://arxiv.org/abs/1604.02878%5D(https://arxiv.org/abs/1604.02878%20%22https://arxiv.org/abs/1604.02878)>https://arxiv.org/abs/1604.02878%5D(https://arxiv.org/abs/1604.02878%20%22https://arxiv.org/abs/1604.02878)</a>.</p><p>In diesem Papier schlagen sie einen tief kaskadierten Multi-Task-Rahmen vor, der verschiedene Merkmale von &ldquo;Untermodellen&rdquo; verwendet, um jeweils ihre korrelierenden Stärken zu verstärken.</p><p>MTCNN ist auf einer CPU recht schnell, obwohl S3FD auf einer GPU immer noch schneller läuft - aber das ist ein Thema für einen anderen Beitrag.</p><p>Dieser Beitrag verwendet Code aus den beiden folgenden Quellen, schauen Sie sich diese an, sie sind ebenfalls interessant:</p><ul><li><a href=https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/ title=https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/>https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/</a></li><li><a href=https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution title=https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution>https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution</a></li></ul><h1 id=grundlegende-verwendung-von-mtcnn>Grundlegende Verwendung von MTCNN</h1><p>Zögern Sie nicht, auf das gesamte Notebook zuzugreifen:</p><p><a href=https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up title=https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up>https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up</a></p><pre><code>git clone https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up
</code></pre><p>Glücklicherweise ist MTCNN als Pip-Paket erhältlich, was bedeutet, dass wir es leicht installieren können mit</p><pre><code>pip install mtcnn
</code></pre><p>Wenn wir jetzt zu Python/Jupyter Notebook wechseln, können wir die Installation mit einem Import und einer schnellen Überprüfung überprüfen:</p><pre><code>import mtcnn
# print version
print(mtcnn.__version__)
</code></pre><p>Danach sind wir bereit, das Testbild mit der Matplotlib [imread-Funktion] (<a href=https://bit.ly/2vo3INw>https://bit.ly/2vo3INw</a>) auszuladen.</p><pre><code>import matplotlib.pyplot as plt
# load image from file
filename = &quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&quot;
pixels = plt.imread(filename)
print(&quot;Shape of image/array:&quot;,pixels.shape)
imgplot = plt.imshow(pixels)
plt.show()
</code></pre><p>Nun wird Ihre Ausgabe in etwa so aussehen:</p><pre><code>{'box': [1942, 716, 334, 415], 'Vertrauen': 0,999999997615814209, 'Schlüsselpunkte': {'linkes_Auge': (2053, 901), &quot;rechtes_Auge&quot;: (2205, 897), &quot;Nase&quot;: (2139, 976), &quot;Mund_links&quot;: (2139, 976), &quot;Mund_links&quot;: (2058, 1029), 'Mund_rechts': (2058, 1029), 'Mund_rechts': (2206, 1023)}}
{&quot;Kiste&quot;: [2084, 396, 37, 46], 'Vertrauen': 0,9999206066131592, 'Schlüsselpunkte': {'linkes_Auge': [2084, 396, 37, 46], 'Vertrauen': [2084, 396, 37, 46], 'Vertrauen': 0,99999206066131592, 'Schlüsselpunkte': [0,9999206066131592], 'Vertrauen (2094, 414), &quot;rechtes_Auge&quot;: (2094, 414), &quot;rechtes_Auge&quot;: (2112, 414), &quot;Nase&quot;: (2094, 414), &quot;Nase&quot;: (2102, 426), &quot;Mund_links&quot;: (2095, 432), &quot;Mund_rechts&quot;: (2112, 431)}}
{&quot;Kiste&quot;: [1980, 381, 44, 59], 'Vertrauen': 0,9998701810836792, 'Schlüsselpunkte': {'linkes_Auge': [1980, 381, 44, 59], 'Vertrauen': 0,9998701810836792, 'Schlüsselpunkte': [1980, 381, 44, 59]: (1997, 404), &quot;rechtes_Auge&quot;: (2019, 407), &quot;Nase&quot;: (1997, 404), &quot;Nase&quot;: (2010, 417), &quot;Mund_links&quot;: (2010, 417), &quot;Mund_links&quot;: (1995, 425), &quot;Mund_rechts&quot;: (1995, 425), &quot;Mund_rechts&quot;: (2015, 427)}}
{&quot;Kiste&quot;: [2039, 395, 39, 46], 'Vertrauen': 0,9993435740470886, 'Schlüsselpunkte': {'linkes_Auge': [2039, 395, 39, 46], 'Vertrauen': 0,9993435740470886, 'Vertrauen': 0,9993435740470886, 'Schlüsselpunkte': [2039, 395, 39, 46]: (2054, 409), &quot;rechtes_Auge&quot;: (2054, 409), &quot;rechtes_Auge&quot;: (2071, 415), &quot;Nase&quot;: (2054, 409), &quot;Nase&quot;: (2058, 422), &quot;Mund_links&quot;: (2048, 425), 'Mund_rechts': (2048, 425), 'Mund_rechts': (2065, 431)}}
</code></pre><p>Was sagt uns das? Vieles davon ist selbsterklärend, aber im Grunde liefert es Koordinaten oder die Pixelwerte eines Rechtecks, in dem der MTCNN-Algorithmus Gesichter erkannt hat. Der obige &ldquo;Kasten&rdquo;-Wert gibt die Position des gesamten Gesichts zurück, gefolgt von einem &ldquo;Vertrauens&rdquo;-Level.</p><p>Wenn Sie fortgeschrittenere Extraktionen oder Algorithmen durchführen möchten, haben Sie auch Zugang zu anderen Landmarken des Gesichts, die als &ldquo;Schlüsselpunkte&rdquo; bezeichnet werden. Das MTCNN-Modell lokalisierte nämlich auch die Augen, den Mund und die Nase!</p><h2 id=zeichnen-eines-kastens-um-gesichter>Zeichnen eines Kastens um Gesichter</h2><p>Um dies noch besser zu demonstrieren, zeichnen wir mit matplotlib einen Kasten um das Gesicht:</p><pre><code># draw an image with detected objects
def draw_facebox(filename, result_list):
# load the image
data = plt.imread(filename)
# plot the image
plt.imshow(data)
# get the context for drawing boxes
ax = plt.gca()
# plot each box
for result in result_list:
# get coordinates
x, y, width, height = result['box']
# create the shape
rect = plt.Rectangle((x, y), width, height, fill=False, color='green')
# draw the box
ax.add_patch(rect)
# show the plot
plt.show()

# filename = 'test1.webp' # filename is defined above, otherwise uncomment
# load image from file
# pixels = plt.imread(filename) # defined above, otherwise uncomment
# detector is defined above, otherwise uncomment
#detector = mtcnn.MTCNN()
# detect faces in the image
faces = detector.detect_faces(pixels)
# display faces on the original image
draw_facebox(filename, faces)
</code></pre><p><img src=/images/index-1-150x150.webp alt></p><h2 id=darstellung-von-augen-mund-und-nase-um-gesichter>Darstellung von Augen, Mund und Nase um Gesichter</h2><p>Werfen wir nun einen Blick auf die oben erwähnten &ldquo;Schlüsselpunkte&rdquo;, die das MTCNN-Modell zurückgebracht hat.</p><p>Wir werden diese nun auch für die Darstellung von Nase, Mund und Augen verwenden.<br>Wir werden den folgenden Codeschnipsel zu unserem obigen Code hinzufügen:</p><pre><code># draw the dots
for key, value in result['keypoints'].items():
# create and draw dot
dot = plt.Circle(value, radius=20, color='orange')
ax.add_patch(dot)
</code></pre><p>Mit dem vollständigen Code von oben, der wie folgt aussieht:</p><pre><code># draw an image with detected objects
def draw_facebox(filename, result_list):
# load the image
data = plt.imread(filename)
# plot the image
plt.imshow(data)
# get the context for drawing boxes
ax = plt.gca()
# plot each box
for result in result_list:
# get coordinates
x, y, width, height = result['box']
# create the shape
rect = plt.Rectangle((x, y), width, height,fill=False, color='orange')
# draw the box
ax.add_patch(rect)
# draw the dots
for key, value in result['keypoints'].items():
# create and draw dot
dot = plt.Circle(value, radius=20, color='red')
ax.add_patch(dot)
# show the plot
plt.show()

# filename = 'test1.webp' # filename is defined above, otherwise uncomment
# load image from file
# pixels = plt.imread(filename) # defined above, otherwise uncomment
# detector is defined above, otherwise uncomment
#detector = mtcnn.MTCNN()
# detect faces in the image
faces = detector.detect_faces(pixels)
# display faces on the original image
draw_facebox(filename, faces)
</code></pre><p><img src=/images/index2-150x150.webp alt></p><h2 id=erweitertes-mtcnn-beschleunigen-sie-es-x100>Erweitertes MTCNN: Beschleunigen Sie es (\\~x100)!</h2><p>Kommen wir nun zum interessanten Teil. Wenn Sie Millionen von Bildern verarbeiten wollen, müssen Sie MTCNN beschleunigen, sonst werden Sie entweder einschlafen oder Ihre CPU wird verbrennen, bevor sie fertig ist.</p><p>Aber worüber genau reden wir hier? Wenn Sie den obigen Code ausführen, dauert es etwa eine Sekunde, d.h. wir werden etwa ein Bild pro Sekunde verarbeiten. Wenn Sie MTCNN auf einer GPU ausführen und die beschleunigte Version verwenden, werden etwa 60-100 Bilder pro Sekunde erreicht. Das ist eine Steigerung von bis zu <strong>100 Mal</strong>!</p><p>Wenn Sie z.B. alle Gesichter eines Films extrahieren wollen, wobei Sie 10 Gesichter pro Sekunde extrahieren (eine Sekunde des Films hat im Durchschnitt etwa 24 Bilder, also jedes zweite Bild), dann sind es 10 * 60 (Sekunden) * 120 (Minuten) = 72.000 Bilder.</p><p>Das heißt, wenn die Verarbeitung eines Einzelbildes eine Sekunde dauert, dauert sie 72.000 * 1 (Sekunden) = 72.000s / 60s = 1.200m = <strong>20 Stunden</strong>.</p><p>Mit der Beschleunigungsversion von MTCNN wird diese Aufgabe 72.000 (Frames) / 100 (Frames/sec) = 720 Sekunden = <strong>12 Minuten</strong> dauern!</p><p>Um MTCNN auf einer GPU zu verwenden, müssen Sie CUDA, cudnn, pytorch usw. einrichten. <a href=https://pytorch.org/get-started/locally/>Pytorch hat ein gutes Tutorial zu diesem Teil geschrieben</a>.</p><p>Nach der Installation werden wir die notwendigen Importe wie folgt durchführen:</p><pre><code>from facenet_pytorch import MTCNN
from PIL import Image
import torch
from imutils.video import FileVideoStream
import cv2
import time
import glob
from tqdm.notebook import tqdm

device = 'cuda' if torch.cuda.is_available() else 'cpu'

filenames = [&quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&quot;,&quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&quot;]
</code></pre><p>Sehen Sie, wie wir das Gerät im obigen Code definiert haben. Sie können alles auch auf einer CPU laufen lassen, wenn Sie CUDA nicht einrichten wollen oder können.</p><p>Als nächstes werden wir den Extraktor definieren:</p><pre><code># define our extractor
fast_mtcnn = FastMTCNN(
stride=4,
resize=0.5,
margin=14,
factor=0.6,
keep_all=True,
device=device
)
</code></pre><p>In diesem Schnipsel geben wir einige Parameter weiter, wobei wir zum Beispiel nur die halbe Bildgröße verwenden, was einer der Haupteinflussfaktoren für die Beschleunigung ist.</p><p>Und schließlich lassen wir das Skript zur Gesichtsextraktion laufen:</p><pre><code>def run_detection(fast_mtcnn, filenames):
frames = []
frames_processed = 0
faces_detected = 0
batch_size = 60
start = time.time()

for filename in tqdm(filenames):

v_cap = FileVideoStream(filename).start()
v_len = int(v_cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))

for j in range(v_len):

frame = v_cap.read()
frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
frames.append(frame)

if len(frames) &gt;= batch_size or j == v_len - 1:

faces = fast_mtcnn(frames)

frames_processed += len(frames)
faces_detected += len(faces)
frames = []

print(
f'Frames per second: {frames_processed / (time.time() - start):.3f},',
f'faces detected: {faces_detected}\r',
end=''
)

v_cap.stop()

run_detection(fast_mtcnn, filenames)
</code></pre><p><img src=/images/teslap100frames.webp alt></p><p>Das obige Bild zeigt die Ausgabe des Codes, der auf einem NVIDIA Tesla P100 läuft. Je nach Quellmaterial, Grafikprozessor und Prozessor kann die Leistung also besser oder schlechter ausfallen.</p><p><a href=https://www.datafortress.cloud/de/contact/>Sie haben eine ähnliche Idee oder wir haben Ihr Interesse geweckt? Kontaktieren Sie uns jetzt für eine gratis 15-minütige Beratung!</a></p></section></div></div></article><aside class="columns is-centered"><div class="column max-800px"><div class=content><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//datafortess-cloud.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></aside></main><footer class=footer><div class="columns has-text-centered"><div class="column is-one-third is-narrow"><p>Social media</p></div><div class="column is-one-third is-narrow"><i class='fab fa-creative-commons' aria-hidden=true></i> This work is licensed under a <a rel=license href=https://creativecommons.org/licenses/by-sa/4.0/ target=_blank>Creative Commons Attribution-ShareAlike 4.0 International</a> License.</div><div class="column is-one-third is-narrow"><p>Powered by</p><a href=https://gohugo.io/ target=_blank><img src=https://datafortress.cloud/images/hugo-logo.png alt=Hugo width=64 height=12 title="Powered by Hugo"></a> &nbsp; &nbsp;
<a href=https://bulma.io/ target=_blank><img src=https://datafortress.cloud/images/made-with-bulma.png alt=Bulma width=64 height=16 title="Powered by Bulma CSS"></a>&nbsp; &nbsp;
<a href=https://www.gnu.org/software/emacs/ target=_blank><img src=https://datafortress.cloud/images/emacs-logo.png alt=Emacs width=16 height=16 title="Written in Emacs"></a></div></div></footer></body></html>