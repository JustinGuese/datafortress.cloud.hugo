<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Datafortress.cloud</title><link>https://datafortress.cloud/de/tags/machine-learning/</link><description>Recent content in machine learning on Datafortress.cloud</description><generator>Hugo -- gohugo.io</generator><language>de-de</language><managingEditor/><webMaster/><lastBuildDate>Wed, 08 Feb 2023 07:10:46 +0200</lastBuildDate><atom:link href="https://datafortress.cloud/de/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Entfaltung des Potenzials des maschinellen Lernens mit privaten Cloud-Diensten: Fallstudien aus der Praxis</title><link>https://datafortress.cloud/de/blog/case-study-real-world-applications-private-cloud/</link><pubDate>Wed, 08 Feb 2023 07:10:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/case-study-real-world-applications-private-cloud/</guid><description>
&lt;h1 id="unlocking-the-potential-of-machine-learning-with-private-cloud-services-real-world-fallstudien">Unlocking the Potential of Machine Learning with Private Cloud Services: Real-World Fallstudien&lt;/h1>
&lt;p>Willkommen in der Welt des datengesteuerten Gesch√§ftserfolgs! In der heutigen schnelllebigen und sich st√§ndig ver√§ndernden Gesch√§ftswelt, die Unternehmen suchen st√§ndig nach neuen Wegen, um ihre Arbeitsabl√§ufe zu verbessern und der Konkurrenz voraus zu sein. Maschinelles Lernen und private Cloud-Dienste haben sich als Wegbereiter erwiesen, Bereitstellung von Werkzeugen f√ºr Unternehmen, die das volle Potenzial ihrer Daten aussch√∂pfen wollen. In diesem Artikel, werfen wir einen Blick auf reale Beispiele von Unternehmen, die sich die Kraft dieser Spitzentechnologien zunutze gemacht haben, um ihr Wachstum zu f√∂rdern, den Betrieb rationalisieren, und sch√ºtzen sensible Informationen. Also anschnallen, und machen Sie sich bereit, die vielen Vorteile von maschinellem Lernen und privaten Cloud-Diensten zu entdecken!&lt;/p>
&lt;h2 id="fallstudie-1-automatisierte-betrugserkennung-f√ºr-ein-finanzdienstleistungsunternehmen">Fallstudie 1: Automatisierte Betrugserkennung f√ºr ein Finanzdienstleistungsunternehmen&lt;/h2>
&lt;p>Finanzdienstleister verarbeiten t√§glich gro√üe Mengen sensibler Daten, die Aufdeckung von Betrug zu einer entscheidenden Komponente ihrer T√§tigkeit machen. Leider, manuelle Verfahren zur Betrugserkennung sind zeitaufw√§ndig, kostspielig, und sind oft nicht in der Lage, komplexe Betrugsf√§lle aufzudecken. An dieser Stelle kommt die Integration von maschinellem Lernen und privaten Cloud-Diensten ins Spiel.&lt;/p>
&lt;p>In dieser Fallstudie, werfen wir einen Blick auf ein Finanzdienstleistungsunternehmen, das mit seinen manuellen Betrugserkennungsverfahren Probleme hatte. Das Unternehmen wandte sich an DataFortress.Cloud UG nach einer L√∂sung, die eine genaue und effiziente Betrugserkennung erm√∂glicht, bei gleichzeitigem Schutz sensibler Kundeninformationen.&lt;/p>
&lt;p>DataFortress.cloud UG implementierte maschinelle Lernalgorithmen in einer sicheren privaten Cloud-Umgebung, den Prozess der Betrugserkennung zu automatisieren. Die Ergebnisse waren beeindruckend, Das Finanzdienstleistungsunternehmen konnte eine erhebliche Steigerung der Genauigkeit im Vergleich zu manuellen Prozessen verzeichnen.. Dies erm√∂glichte es dem Unternehmen, Betrugsversuche schneller und wirksamer aufzudecken., Verringerung des Risikos von finanziellen Verlusten und Schutz sensibler Kundeninformationen.&lt;/p>
&lt;p>Zusammenfassend, Die Integration von maschinellem Lernen und privaten Cloud-Diensten bietet Finanzdienstleistern ein leistungsf√§higes Instrument zur Automatisierung der Betrugserkennung und zum Schutz sensibler Daten. Wenn Sie Probleme mit manuellen Betrugserkennungsprozessen haben, Kontakt zu DataFortress.cloud UG, um mehr √ºber unsere L√∂sungen zu erfahren.&lt;/p>
&lt;h2 id="fallstudie-2-vorausschauende-wartung-f√ºr-ein-fertigungsunternehmen">Fallstudie 2: Vorausschauende Wartung f√ºr ein Fertigungsunternehmen&lt;/h2>
&lt;p>In der verarbeitenden Industrie, Ausfallzeiten k√∂nnen kostspielig sein und sich auf das Endergebnis auswirken. Traditionelle Wartungsprozesse sind reaktiv, was bedeutet, dass die Ger√§te erst gewartet werden, wenn sie ausgefallen sind. Dies f√ºhrt zu unerwarteten Ausfallzeiten, erh√∂hte Wartungskosten, und verringerte Produktivit√§t.&lt;/p>
&lt;p>Einstieg in die vorausschauende Wartung, ein proaktiver Ansatz, bei dem Algorithmen des maschinellen Lernens eingesetzt werden, um vorherzusagen, wann Ger√§te ausfallen werden, und die Wartung entsprechend zu planen. In dieser Fallstudie, werfen wir einen Blick auf ein Fertigungsunternehmen, das mit ineffizienten Wartungsprozessen und Ausfallzeiten zu k√§mpfen hatte.&lt;/p>
&lt;p>Das Produktionsunternehmen arbeitet mit DataFortress zusammen.cloud UG zur Umsetzung der vorausschauenden Wartung in einer sicheren privaten Cloud-Umgebung. DataFortress.cloud UG nutzte Algorithmen des maschinellen Lernens, um Ger√§tedaten zu analysieren und vorherzusagen, wann eine Wartung erforderlich sein w√ºrde. Dies erm√∂glichte es dem Unternehmen, Wartungsarbeiten proaktiv zu planen., Verringerung der Ausfallzeiten und Verbesserung der Effizienz.&lt;/p>
&lt;p>Die Ergebnisse waren bemerkenswert, Das Fertigungsunternehmen konnte die Ausfallzeiten erheblich reduzieren und die Produktivit√§t steigern.. Dar√ºber hinaus, das Unternehmen konnte seine Wartungsprozesse optimieren und die Kosten senken, was zu einer verbesserten Rentabilit√§t f√ºhrt.&lt;/p>
&lt;p>Zusammenfassend, Vorausschauende Instandhaltung ist ein entscheidender Faktor f√ºr die Fertigungsindustrie. Durch den Einsatz von maschinellem Lernen und privaten Cloud-Diensten, Unternehmen k√∂nnen die Wartung proaktiv planen, Verringerung der Ausfallzeiten und Verbesserung der Effizienz. Wenn Sie Probleme mit reaktiven Wartungsprozessen haben, Kontakt zu DataFortress.cloud UG, um mehr √ºber unsere L√∂sungen zu erfahren.&lt;/p>
&lt;h2 id="fallstudie-3-kundensegmentierung-und-personalisierung-f√ºr-ein-einzelhandelsunternehmen">Fallstudie 3: Kundensegmentierung und Personalisierung f√ºr ein Einzelhandelsunternehmen&lt;/h2>
&lt;p>In der wettbewerbsorientierten Einzelhandelslandschaft von heute, ein personalisiertes Einkaufserlebnis ist der Schl√ºssel zur Gewinnung und Bindung von Kunden. Kundensegmentierung, der Prozess der Einteilung von Kunden in Gruppen auf der Grundlage gemeinsamer Merkmale, ist ein wesentlicher Bestandteil der Personalisierung. Die manuelle Segmentierung von Kunden kann jedoch zeitaufw√§ndig sein und durch menschliche Voreingenommenheit eingeschr√§nkt werden..&lt;/p>
&lt;p>Hier kommen das maschinelle Lernen und private Cloud-Dienste ins Spiel. In dieser Fallstudie, werfen wir einen Blick auf ein Einzelhandelsunternehmen, das Schwierigkeiten hatte, seinen Kunden personalisierte Erlebnisse zu bieten. Das Unternehmen wandte sich an DataFortress.Cloud UG f√ºr eine L√∂sung, die Kunden genau segmentieren und personalisierte Erfahrungen in einer sicheren Umgebung bieten kann.&lt;/p>
&lt;p>DataFortress.cloud UG implementierte Algorithmen f√ºr maschinelles Lernen in einer privaten Cloud-Umgebung, um Kundendaten zu analysieren und Kunden anhand gemeinsamer Merkmale in Gruppen einzuteilen. Dies erm√∂glichte dem Einzelhandelsunternehmen, seinen Kunden personalisierte Erfahrungen zu bieten., einschlie√ülich ma√ügeschneiderter Produktempfehlungen und gezielter Marketingkampagnen.&lt;/p>
&lt;p>Die Ergebnisse waren beeindruckend, Das Einzelhandelsunternehmen verzeichnete einen Anstieg der Kundenbindung und des Umsatzes.. Das Unternehmen konnte au√üerdem wertvolle Erkenntnisse √ºber das Verhalten und die Vorlieben seiner Kunden gewinnen, was eine kontinuierliche Optimierung und Verbesserung der Personalisierungsbem√ºhungen erm√∂glichte.&lt;/p>
&lt;p>Zusammenfassend, Kundensegmentierung und Personalisierung sind entscheidende Komponenten einer erfolgreichen Einzelhandelsstrategie. Durch den Einsatz von maschinellem Lernen und privaten Cloud-Diensten, Einzelh√§ndler k√∂nnen Kunden genau segmentieren und personalisierte Erfahrungen anbieten, was zu mehr Engagement und Umsatz f√ºhrt. Wenn Sie mit Herausforderungen bei der Kundensegmentierung und Personalisierung konfrontiert sind, Kontakt zu DataFortress.cloud UG, um mehr √ºber unsere L√∂sungen zu erfahren.&lt;/p>
&lt;h2 id="schlussfolgerung">Schlussfolgerung&lt;/h2>
&lt;p>Zusammenfassend, maschinelles Lernen und private Cloud-Dienste sind leistungsstarke Werkzeuge f√ºr Unternehmen, die ihre Abl√§ufe verbessern und sensible Daten sch√ºtzen wollen. Die Fallstudien, die wir in diesem Artikel besprochen haben, zeigen nur einige der vielen M√∂glichkeiten auf, wie Unternehmen diese Technologien nutzen, um sich einen Wettbewerbsvorteil zu verschaffen.&lt;/p>
&lt;p>Von der automatischen Betrugserkennung in der Finanzdienstleistungsbranche √ºber die vorausschauende Wartung in der Fertigungsindustrie bis hin zur Kundensegmentierung und Personalisierung im Einzelhandel, die Vorteile von maschinellem Lernen und privaten Cloud-Diensten liegen auf der Hand. Die Unternehmen k√∂nnen ihre Effizienz verbessern, Kosten senken, und personalisierte Erfahrungen f√ºr ihre Kunden zu bieten, und das alles unter Wahrung der Sicherheit sensibler Daten.&lt;/p>
&lt;p>Bei DataFortress.Wolke UG, Wir unterst√ºtzen Unternehmen dabei, die Leistung von maschinellem Lernen und privaten Cloud-Services zu nutzen, um ihre Ziele zu erreichen.. Ob Sie mit Herausforderungen bei der Betrugserkennung konfrontiert sind, Wartungsprozesse, oder Kundensegmentierung und Personalisierung, wir haben das Fachwissen und die Erfahrung, um zu helfen. Kontaktieren Sie uns noch heute, um mehr √ºber unsere L√∂sungen zu erfahren und wie wir Ihrem Unternehmen zum Erfolg verhelfen k√∂nnen..&lt;/p></description></item><item><title>Erschlie√üung des Potenzials des maschinellen Lernens mit privaten Cloud-Diensten: Fallstudien aus der Praxis</title><link>https://datafortress.cloud/de/blog/fallstudie-real-world-anwendungen-private-cloud/</link><pubDate>Wed, 08 Feb 2023 07:10:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/fallstudie-real-world-anwendungen-private-cloud/</guid><description>
&lt;h1 id="erschlie√üung-des-potenzials-des-maschinellen-lernens-mit-privaten-cloud-diensten-fallstudien-aus-der-praxis">Erschlie√üung des Potenzials des maschinellen Lernens mit privaten Cloud-Diensten: Fallstudien aus der Praxis&lt;/h1>
&lt;p>Willkommen in der Welt des datengesteuerten Gesch√§ftserfolgs! In der heutigen schnelllebigen und sich st√§ndig ver√§ndernden Gesch√§ftswelt suchen Unternehmen st√§ndig nach neuen M√∂glichkeiten, ihre Abl√§ufe zu verbessern und der Konkurrenz einen Schritt voraus zu sein. Maschinelles Lernen und private Cloud-Services haben sich als bahnbrechend erwiesen und bieten Unternehmen die Tools, die sie ben√∂tigen, um das volle Potenzial ihrer Daten auszusch√∂pfen. In diesem Artikel werfen wir einen Blick auf Beispiele aus der Praxis von Unternehmen, die sich diese Spitzentechnologien zunutze gemacht haben, um ihr Wachstum voranzutreiben, ihre Abl√§ufe zu optimieren und sensible Daten zu sch√ºtzen. Schnallen Sie sich also an und machen Sie sich bereit, die vielen Vorteile von maschinellem Lernen und privaten Cloud-Diensten zu entdecken!&lt;/p>
&lt;h2 id="fallstudie-1-automatisierte-betrugserkennung-f√ºr-ein-finanzdienstleistungsunternehmen">Fallstudie 1: Automatisierte Betrugserkennung f√ºr ein Finanzdienstleistungsunternehmen&lt;/h2>
&lt;p>Finanzdienstleister verarbeiten t√§glich riesige Mengen an sensiblen Daten, was die Betrugserkennung zu einem kritischen Bestandteil ihres Gesch√§ftsbetriebs macht. Leider sind manuelle Betrugserkennungsprozesse zeitaufw√§ndig, kostspielig und reichen oft nicht aus, um komplexe Betrugsversuche aufzudecken. An dieser Stelle kommt die Integration von maschinellem Lernen und privaten Cloud-Diensten ins Spiel.&lt;/p>
&lt;p>In dieser Fallstudie werfen wir einen Blick auf ein Finanzdienstleistungsunternehmen, das mit seinen manuellen Betrugserkennungsprozessen Probleme hatte. Das Unternehmen wandte sich an DataFortress.cloud UG, um eine L√∂sung zu finden, die eine genaue und effiziente Betrugserkennung erm√∂glicht und gleichzeitig sensible Kundendaten sch√ºtzt.&lt;/p>
&lt;p>DataFortress.cloud UG implementierte maschinelle Lernalgorithmen innerhalb einer sicheren privaten Cloud-Umgebung, um den Betrugserkennungsprozess zu automatisieren. Die Ergebnisse waren beeindruckend: Das Finanzdienstleistungsunternehmen verzeichnete eine signifikante Steigerung der Genauigkeit im Vergleich zu manuellen Prozessen. Dadurch konnte das Unternehmen Betrugsversuche schneller und effektiver aufdecken, das Risiko finanzieller Verluste verringern und sensible Kundendaten sch√ºtzen.&lt;/p>
&lt;p>Zusammenfassend l√§sst sich sagen, dass die Integration von maschinellem Lernen und privaten Cloud-Diensten Finanzdienstleistern ein leistungsstarkes Tool zur Automatisierung der Betrugserkennung und zum Schutz sensibler Daten bietet. Wenn Sie mit manuellen Betrugserkennungsprozessen konfrontiert sind, kontaktieren Sie DataFortress.cloud UG, um mehr √ºber unsere L√∂sungen zu erfahren.&lt;/p>
&lt;h2 id="fallstudie-2-vorausschauende-wartung-f√ºr-ein-fertigungsunternehmen">Fallstudie 2: Vorausschauende Wartung f√ºr ein Fertigungsunternehmen&lt;/h2>
&lt;p>In der Fertigungsindustrie k√∂nnen Ausfallzeiten kostspielig sein und sich auf das Endergebnis auswirken. Herk√∂mmliche Wartungsprozesse sind reaktiv, was bedeutet, dass die Anlagen erst gewartet werden, wenn sie ausgefallen sind. Dies f√ºhrt zu unerwarteten Ausfallzeiten, h√∂heren Wartungskosten und geringerer Produktivit√§t.&lt;/p>
&lt;p>Hier kommt die vorausschauende Wartung ins Spiel, ein proaktiver Ansatz, bei dem Algorithmen des maschinellen Lernens eingesetzt werden, um vorherzusagen, wann Ger√§te ausfallen werden, und die Wartung entsprechend zu planen. In dieser Fallstudie werfen wir einen Blick auf ein Fertigungsunternehmen, das mit ineffizienten Wartungsprozessen und Ausfallzeiten zu k√§mpfen hatte.&lt;/p>
&lt;p>Das Unternehmen ging eine Partnerschaft mit DataFortress.cloud UG ein, um die vorausschauende Wartung in einer sicheren privaten Cloud-Umgebung zu implementieren. DataFortress.cloud UG nutzte Algorithmen des maschinellen Lernens, um Anlagendaten zu analysieren und vorherzusagen, wann eine Wartung erforderlich sein w√ºrde. Dies erm√∂glichte es dem Unternehmen, die Wartung proaktiv zu planen, Ausfallzeiten zu reduzieren und die Effizienz zu verbessern.&lt;/p>
&lt;p>Die Ergebnisse waren bemerkenswert: Das Fertigungsunternehmen konnte die Ausfallzeiten erheblich reduzieren und die Produktivit√§t steigern. Dar√ºber hinaus konnte das Unternehmen seine Wartungsprozesse optimieren und die Kosten senken, was zu einer verbesserten Rentabilit√§t f√ºhrte.&lt;/p>
&lt;p>Zusammenfassend l√§sst sich sagen, dass die vorausschauende Wartung f√ºr die Fertigungsindustrie einen entscheidenden Wandel darstellt. Durch den Einsatz von maschinellem Lernen und privaten Cloud-Diensten k√∂nnen Unternehmen die Wartung proaktiv planen, Ausfallzeiten reduzieren und die Effizienz verbessern. Wenn Sie mit reaktiven Wartungsprozessen konfrontiert sind, kontaktieren Sie DataFortress.cloud UG, um mehr √ºber unsere L√∂sungen zu erfahren.&lt;/p>
&lt;h2 id="fallstudie-3-kundensegmentierung-und-personalisierung-f√ºr-ein-einzelhandelsunternehmen">Fallstudie 3: Kundensegmentierung und Personalisierung f√ºr ein Einzelhandelsunternehmen&lt;/h2>
&lt;p>In der heutigen wettbewerbsintensiven Einzelhandelslandschaft ist ein personalisiertes Einkaufserlebnis der Schl√ºssel zur Gewinnung und Bindung von Kunden. Die Kundensegmentierung, d. h. die Einteilung von Kunden in Gruppen auf der Grundlage gemeinsamer Merkmale, ist ein wesentlicher Bestandteil der Personalisierung. Die manuelle Segmentierung von Kunden kann jedoch zeitaufw√§ndig sein und durch menschliche Voreingenommenheit eingeschr√§nkt werden.&lt;/p>
&lt;p>An dieser Stelle kommen maschinelles Lernen und private Cloud-Services ins Spiel. In dieser Fallstudie werfen wir einen Blick auf ein Einzelhandelsunternehmen, das Schwierigkeiten hatte, personalisierte Erfahrungen f√ºr seine Kunden zu bieten. Das Unternehmen wandte sich an DataFortress.cloud UG, um eine L√∂sung zu finden, die Kunden genau segmentieren und personalisierte Erfahrungen in einer sicheren Umgebung bieten konnte.&lt;/p>
&lt;p>DataFortress.cloud UG implementierte Algorithmen des maschinellen Lernens in einer privaten Cloud-Umgebung, um Kundendaten zu analysieren und Kunden anhand gemeinsamer Merkmale in Gruppen einzuteilen. Dies erm√∂glichte es dem Einzelhandelsunternehmen, seinen Kunden personalisierte Erfahrungen zu bieten, einschlie√ülich ma√ügeschneiderter Produktempfehlungen und gezielter Marketingkampagnen.&lt;/p>
&lt;p>Die Ergebnisse waren beeindruckend: Das Einzelhandelsunternehmen verzeichnete eine Steigerung der Kundenbindung und des Umsatzes. Dar√ºber hinaus konnte das Unternehmen wertvolle Erkenntnisse √ºber das Kundenverhalten und die Pr√§ferenzen seiner Kunden gewinnen, was eine kontinuierliche Optimierung und Verbesserung der Personalisierungsma√ünahmen erm√∂glichte.&lt;/p>
&lt;p>Zusammenfassend l√§sst sich sagen, dass Kundensegmentierung und Personalisierung entscheidende Komponenten einer erfolgreichen Einzelhandelsstrategie sind. Durch den Einsatz von maschinellem Lernen und privaten Cloud-Diensten k√∂nnen Einzelh√§ndler Kunden genau segmentieren und personalisierte Erlebnisse bieten, was zu mehr Engagement und Umsatz f√ºhrt. Wenn Sie mit Herausforderungen bei der Kundensegmentierung und Personalisierung konfrontiert sind, kontaktieren Sie DataFortress.cloud UG, um mehr √ºber unsere L√∂sungen zu erfahren.&lt;/p>
&lt;h2 id="fazit">Fazit&lt;/h2>
&lt;p>Zusammenfassend l√§sst sich sagen, dass maschinelles Lernen und private Cloud-Dienste leistungsstarke Werkzeuge f√ºr Unternehmen sind, die ihre Abl√§ufe verbessern und sensible Daten sch√ºtzen m√∂chten. Die Fallstudien, die wir in diesem Artikel besprochen haben, zeigen nur einige der vielen M√∂glichkeiten auf, wie Unternehmen diese Technologien nutzen, um sich einen Wettbewerbsvorteil zu verschaffen.&lt;/p>
&lt;p>Von der automatisierten Betrugserkennung in der Finanzdienstleistungsbranche √ºber die vorausschauende Wartung in der Fertigungsindustrie bis hin zur Kundensegmentierung und Personalisierung im Einzelhandel liegen die Vorteile des maschinellen Lernens und der Private Cloud Services auf der Hand. Unternehmen sind in der Lage, ihre Effizienz zu steigern, Kosten zu senken und ihren Kunden personalisierte Erlebnisse zu bieten - und das alles unter Wahrung der Sicherheit sensibler Daten.&lt;/p>
&lt;p>Die DataFortress.cloud UG unterst√ºtzt Unternehmen dabei, die M√∂glichkeiten des maschinellen Lernens und privater Cloud-Services zu nutzen, um ihre Ziele zu erreichen. Ganz gleich, ob Sie vor Herausforderungen bei der Betrugserkennung, bei Wartungsprozessen oder bei der Kundensegmentierung und -personalisierung stehen, wir haben das Know-how und die Erfahrung, um Ihnen zu helfen. Kontaktieren Sie uns noch heute, um mehr √ºber unsere L√∂sungen zu erfahren und wie wir Ihrem Unternehmen zum Erfolg verhelfen k√∂nnen.&lt;/p></description></item><item><title>Techniken der Datenwissenschaft: Wie man mit maschinellem Lernen anf√§ngt</title><link>https://datafortress.cloud/de/blog/datenwissenschaftliche-techniken-wie-man-mit-maschinenlernen-einsteigt/</link><pubDate>Thu, 02 Feb 2023 04:32:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/datenwissenschaftliche-techniken-wie-man-mit-maschinenlernen-einsteigt/</guid><description>
&lt;h1 id="techniken-der-datenwissenschaft-wie-f√§ngt-man-mit-maschinellem-lernen-an">Techniken der Datenwissenschaft: Wie f√§ngt man mit maschinellem Lernen an?&lt;/h1>
&lt;p>In der datengesteuerten Welt von heute ist die Beherrschung von Data-Science-Techniken wie maschinelles Lernen wichtiger denn je. Von der Verbesserung der Unternehmensleistung bis hin zur F√∂rderung der wissenschaftlichen Forschung - die Anwendungsm√∂glichkeiten des maschinellen Lernens sind praktisch grenzenlos. Bei der gro√üen Auswahl an Tools und Techniken kann es jedoch schwierig sein zu wissen, wo man anfangen soll. In diesem Artikel finden Sie einen umfassenden Leitfaden f√ºr den Einstieg in das maschinelle Lernen, einschlie√ülich praktischer Ratschl√§ge f√ºr die Auswahl der richtigen Tools, die Erstellung effektiver Modelle und die Erschlie√üung des vollen Potenzials Ihrer Daten. Egal, ob Sie ein erfahrener Datenwissenschaftler sind oder gerade erst anfangen, dieser Leitfaden enth√§lt alles, was Sie brauchen, um Ihre F√§higkeiten im maschinellen Lernen auf die n√§chste Stufe zu bringen.&lt;/p>
&lt;h2 id="unlock-the-power-of-machine-learning-ein-einsteigerhandbuch-f√ºr-data-science-techniken">Unlock the Power of Machine Learning: Ein Einsteigerhandbuch f√ºr Data Science-Techniken&amp;quot;&lt;/h2>
&lt;p>Sind Sie neugierig, wie Sie die M√∂glichkeiten des maschinellen Lernens und der Data-Science-Techniken nutzen k√∂nnen? Wenn ja, dann sind Sie nicht allein. In der heutigen datengesteuerten Welt ist es wichtiger denn je, zu verstehen, wie man sich die Leistungsf√§higkeit dieser Technologien zunutze machen kann.&lt;/p>
&lt;p>Im Kern geht es beim maschinellen Lernen darum, Algorithmen zu trainieren, um Muster in Daten zu erkennen und auf der Grundlage dieser Muster Vorhersagen zu treffen. Von der Identifizierung potenzieller Kunden bis hin zur Aufdeckung von Betrug wird das maschinelle Lernen zu einem unverzichtbaren Werkzeug f√ºr Unternehmen jeder Gr√∂√üe. Datenwissenschaftliche Techniken gehen Hand in Hand mit maschinellem Lernen und bilden den Rahmen f√ºr das Verst√§ndnis, wie Daten genutzt werden k√∂nnen, um Entscheidungen zu treffen, die das Unternehmenswachstum f√∂rdern.&lt;/p>
&lt;p>Wenn Sie diese Tools beherrschen, k√∂nnen Sie Einblicke in Ihre Daten gewinnen, die auf den ersten Blick vielleicht nicht sichtbar sind. Sie werden in der Lage sein, Modelle zu erstellen, mit denen Sie zuk√ºnftige Trends vorhersagen und fundierte Gesch√§ftsentscheidungen treffen k√∂nnen. Und, was vielleicht am wichtigsten ist, Sie k√∂nnen der Konkurrenz einen Schritt voraus sein, indem Sie verstehen, wie Sie Daten auf neue und innovative Weise nutzen k√∂nnen.&lt;/p>
&lt;p>Nat√ºrlich kann der Einstieg in das maschinelle Lernen und die Datenwissenschaft einsch√ºchternd sein, vor allem, wenn Sie neu auf diesem Gebiet sind. Aber mit der richtigen Anleitung und den richtigen Ressourcen kann jeder lernen, wie man diese Tools einsetzt, um das Potenzial seiner Daten voll auszusch√∂pfen.&lt;/p>
&lt;h2 id="master-the-basics-of-machine-learning-verstehen-der-grundlagen-der-datenwissenschaft">Master the Basics of Machine Learning: Verstehen der Grundlagen der Datenwissenschaft&lt;/h2>
&lt;p>Maschinelles Lernen ist ein leistungsf√§higes Werkzeug, das Ihnen helfen kann, Muster und Erkenntnisse in Ihren Daten zu entdecken, die vielleicht nicht sofort ersichtlich sind. Um das Beste aus dieser Technologie herauszuholen, ist es jedoch wichtig, die wichtigsten Konzepte zu verstehen, die ihr zugrunde liegen.&lt;/p>
&lt;p>Im Kern geht es beim maschinellen Lernen darum, Algorithmen zu trainieren, um Muster in Ihren Daten zu erkennen und diese Muster zu nutzen, um Vorhersagen √ºber zuk√ºnftige Ereignisse zu treffen. Diese Algorithmen k√∂nnen in einer Vielzahl von realen Szenarien eingesetzt werden, von der Vorhersage, welche Kunden am ehesten Ihr Produkt kaufen werden, bis hin zur Erkennung von Betrug bei Finanztransaktionen.&lt;/p>
&lt;p>Eines der Schl√ºsselkonzepte des maschinellen Lernens ist die Idee eines Modells. Ein Modell ist eine mathematische Darstellung der Beziehungen zwischen verschiedenen Variablen in Ihren Daten. Wenn Sie beispielsweise versuchen, den Preis eines Hauses auf der Grundlage seiner Gr√∂√üe und Lage vorherzusagen, k√∂nnten Sie ein Modell erstellen, das diese beiden Variablen ber√ºcksichtigt.&lt;/p>
&lt;p>Ein weiteres wichtiges Konzept ist die Idee des Trainings und der Tests. Um ein effektives Modell f√ºr maschinelles Lernen zu erstellen, m√ºssen Sie es anhand eines gro√üen Datensatzes mit Beispielen trainieren. Dieser Trainingsprozess hilft dem Algorithmus, Muster in den Daten zu erkennen, die er zur Erstellung von Vorhersagen verwenden kann. Sobald das Modell trainiert wurde, m√ºssen Sie es an einem separaten Datensatz testen, um sicherzustellen, dass es genau ist.&lt;/p>
&lt;p>Nat√ºrlich gibt es noch viele andere Konzepte, die f√ºr das Verst√§ndnis des maschinellen Lernens wichtig sind, von den verschiedenen Arten von Algorithmen bis hin zur Bedeutung der Merkmalsauswahl. Aber wenn Sie die Grundlagen beherrschen, sind Sie auf dem besten Weg, effektive maschinelle Lernmodelle zu erstellen, die Ihnen helfen, bessere Gesch√§ftsentscheidungen zu treffen.&lt;/p>
&lt;blockquote>
&lt;p>Fragen? Lassen Sie sich von unserem Team erfahrener &lt;a href="https://datafortress.cloud/de/contact">Machine Learning Engineers&lt;/a> helfen.&lt;/p>
&lt;/blockquote>
&lt;h2 id="fortgeschrittene-tools-und-techniken-f√ºr-maschinelles-lernen-wie-sie-sie-auf-ihre-daten-anwenden">Fortgeschrittene Tools und Techniken f√ºr maschinelles Lernen: Wie Sie sie auf Ihre Daten anwenden&lt;/h2>
&lt;p>Wenn Sie bereits mit den Grundlagen des maschinellen Lernens vertraut sind, fragen Sie sich vielleicht, was der n√§chste Schritt ist. Zum Gl√ºck gibt es viele fortgeschrittene Tools und Techniken, die Ihnen helfen k√∂nnen, Ihre F√§higkeiten beim maschinellen Lernen auf die n√§chste Stufe zu bringen.&lt;/p>
&lt;p>Eines der neuesten Tools f√ºr maschinelles Lernen ist AutoML, oder automatisiertes maschinelles Lernen. AutoML ist eine Reihe von Tools und Techniken, die viele der Aufgaben automatisieren, die bei der Erstellung effektiver Modelle f√ºr maschinelles Lernen anfallen. Dies kann eine enorme Zeitersparnis bedeuten, insbesondere wenn Sie mit gro√üen Datens√§tzen oder komplexen Modellen arbeiten.&lt;/p>
&lt;p>Eine weitere fortschrittliche Technik f√ºr maschinelles Lernen ist Deep Learning. Deep Learning ist eine Art des maschinellen Lernens, bei dem k√ºnstliche neuronale Netze zur Analyse von Daten eingesetzt werden. Dieser Ansatz ist besonders effektiv f√ºr Aufgaben wie Bilderkennung und Verarbeitung nat√ºrlicher Sprache.&lt;/p>
&lt;p>Neben diesen Werkzeugen und Techniken gibt es noch viele andere fortgeschrittene Konzepte, die man bei der Arbeit mit maschinellem Lernen verstehen muss. Wenn Sie beispielsweise wissen, wie man Modellgruppen verwendet, k√∂nnen Sie genauere Vorhersagen treffen, und wenn Sie menschliches Fachwissen in Ihre maschinellen Lernmodelle einbeziehen, k√∂nnen Sie Faktoren ber√ºcksichtigen, die in Ihren Daten m√∂glicherweise nicht sichtbar sind.&lt;/p>
&lt;p>Nat√ºrlich kann die Anwendung dieser Tools und Techniken auf Ihre eigenen Daten eine Herausforderung sein, vor allem, wenn Sie nicht mit den neuesten Best Practices vertraut sind. Aber mit der richtigen Anleitung und den richtigen Ressourcen kann jeder lernen, wie man diese fortschrittlichen Tools und Techniken einsetzt, um effektivere Modelle f√ºr maschinelles Lernen zu erstellen.&lt;/p>
&lt;h2 id="beginnen-sie-noch-heute-mit-maschinellem-lernen-ein-umfassender-leitfaden-f√ºr-datenwissenschaftler">Beginnen Sie noch heute mit maschinellem Lernen: Ein umfassender Leitfaden f√ºr Datenwissenschaftler&lt;/h2>
&lt;p>Wenn Sie bereit sind, in die Welt des maschinellen Lernens einzutauchen, ist es eine gute Nachricht, dass es viele Ressourcen gibt, die Ihnen den Einstieg erleichtern. Bei der gro√üen Auswahl an Tools und Techniken kann es jedoch schwierig sein zu wissen, wo man anfangen soll.&lt;/p>
&lt;p>Der erste Schritt beim Einstieg in das maschinelle Lernen besteht in der Auswahl der richtigen Tools f√ºr diese Aufgabe. Es gibt viele Open-Source- und kommerzielle Tools f√ºr maschinelles Lernen, die alle ihre eigenen St√§rken und Schw√§chen haben. Zu den beliebtesten Tools geh√∂ren Python-basierte Bibliotheken wie scikit-learn und TensorFlow sowie Cloud-basierte Dienste wie Google Cloud AI und Amazon SageMaker.&lt;/p>
&lt;p>Wenn Sie Ihre Tools ausgew√§hlt haben, m√ºssen Sie als N√§chstes mit Ihren Daten arbeiten. Effektive Modelle f√ºr maschinelles Lernen erfordern qualitativ hochwertige Daten, die sauber, gut strukturiert und f√ºr die jeweilige Aufgabe relevant sind. Dazu geh√∂rt h√§ufig ein Prozess der Datenbereinigung und -vorverarbeitung, bei dem Sie doppelte oder irrelevante Daten entfernen und Ihre Daten so formatieren m√ºssen, dass sie von Ihren Algorithmen f√ºr maschinelles Lernen problemlos analysiert werden k√∂nnen.&lt;/p>
&lt;p>Wenn Sie Ihre Daten in der Hand haben, k√∂nnen Sie im n√§chsten Schritt mit der Erstellung Ihrer maschinellen Lernmodelle beginnen. Dazu geh√∂ren die Auswahl der richtigen Algorithmen f√ºr Ihre Daten, die Abstimmung der Parameter Ihrer Modelle und die Bewertung ihrer Leistung anhand von Kennzahlen wie Genauigkeit, Pr√§zision und Wiedererkennung.&lt;/p>
&lt;p>Bei der Erstellung effektiver maschineller Lernmodelle geht es jedoch nicht nur um die technischen Details. Es ist auch wichtig, sich kritisch mit dem breiteren Kontext Ihrer Daten und dem Problem, das Sie zu l√∂sen versuchen, auseinanderzusetzen. Dazu geh√∂rt oft die Einbeziehung von Fachwissen in Ihre Modelle sowie die Ber√ºcksichtigung der ethischen und sozialen Auswirkungen Ihrer Arbeit.&lt;/p>
&lt;p>Bei DataFortress.cloud helfen wir Ihnen, mit maschinellem Lernen zu beginnen und Ihre Data-Science-F√§higkeiten auf die n√§chste Stufe zu heben. Unser Expertenteam verf√ºgt √ºber fundierte technische Kenntnisse in den Bereichen Kubernetes, Private Cloud, Data Engineering und Datenpipelines und steht Ihnen jederzeit mit Rat und Tat zur Seite, wenn es darum geht, das Beste aus Ihren Daten herauszuholen.&lt;/p>
&lt;p>Wenn Sie also bereit sind, mit dem maschinellen Lernen zu beginnen, z√∂gern Sie nicht, uns unter &lt;a href="https://datafortress.cloud/contact">https://datafortress.cloud/contact&lt;/a> zu kontaktieren. Wir freuen uns darauf, Ihnen zu helfen, das volle Potenzial Ihrer Daten zu erschlie√üen!&lt;/p></description></item><item><title>Howto: Einen automatisierten Machine-Learning Aktienhandels-Roboter mittels AWS Lambda serverlos betreiben</title><link>https://datafortress.cloud/de/blog/howto-einen-automatisierten-machine-learning-aktienhandels-roboter-mittels-aws-lambda-serverlos-betreiben/</link><pubDate>Mon, 23 May 2022 22:00:00 +0000</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/howto-einen-automatisierten-machine-learning-aktienhandels-roboter-mittels-aws-lambda-serverlos-betreiben/</guid><description>
&lt;p>In diesem Beitrag werde ich meinen Algorithmus f√ºr serverloses Investieren mit AWS Lambda, Facebook Prophet als ML-Modell und meiner benutzerdefinierten Lambda-Schicht vorstellen.&lt;/p>
&lt;p>Ich habe diesen Beitrag in die Abschnitte &amp;ldquo;Warum habe ich das gemacht&amp;rdquo; und &amp;ldquo;Technisches How To&amp;rdquo; unterteilt. Wenn Sie den &amp;ldquo;Warum&amp;rdquo;-Teil √ºberspringen m√∂chten, k√∂nnen Sie direkt zum technischen Teil springen.&lt;/p>
&lt;h2 id="warum-sollte-ich-ein-maschinelles-lernmodell-in-aws-lambda-einsetzen">Warum sollte ich ein maschinelles Lernmodell in AWS Lambda einsetzen?&lt;/h2>
&lt;ol>
&lt;li>&lt;strong>Die Zuverl√§ssigkeit&lt;/strong>: Der Algorithmus wird unabh√§ngig von anderen Systemen, Updates, &amp;hellip;&lt;/li>
&lt;li>&lt;strong>Leistungseffizienz&lt;/strong>: Ich kann mehrere Algorithmen auf einem (kleinen) System unabh√§ngig voneinander ausf√ºhren.&lt;/li>
&lt;li>&lt;strong>Kosteneinsparungen&lt;/strong>: AWS erm√∂glicht &lt;a href="https://aws.amazon.com/lambda/?did=ft_card&amp;amp;trk=ft_card">3,2 Millionen Rechensekunden pro Monat&lt;/a>, so dass ich im Grunde alle meine Algorithmen kostenlos ausf√ºhren kann.&lt;/li>
&lt;/ol>
&lt;p>Ich habe nach einer M√∂glichkeit gesucht, zun√§chst sicherzustellen, dass mein Investitions-Bot sicher ausgef√ºhrt wird, denn eine fehlgeschlagene Ausf√ºhrung kann viel Geld kosten, wenn ein Handel nicht umgehend abgebrochen wird, wenn er in die falsche Richtung geht. Au√üerdem wollte ich vermeiden, meinen Computer die ganze Zeit laufen zu lassen, und sicherstellen, dass mehrere Algorithmen nebeneinander laufen k√∂nnen, ohne ihre Ausf√ºhrung zu beeinflussen oder zu verz√∂gern.&lt;/p>
&lt;p>Dar√ºber hinaus ist es ein sch√∂ner Gedanke, einen investierenden Algorithmus laufen zu lassen, ohne sich um Betriebssystem-Updates, Hardware-Ausf√§lle und Stromausf√§lle usw. zu k√ºmmern, was der allgemeine Vorteil serverloser Technologien ist.&lt;/p>
&lt;p>Im Moment kann ich mehrere Variationen des Algorithmus laufen lassen, um √Ñnderungen des Algorithmus zu testen, und kann sicher sein, dass er l√§uft. Noch eine nette Sache? AWS bietet etwa 1 Million kostenlose Lambda-Aufrufe an, so dass ich die gesamte Architektur in ihrem Free Tier-Kontingent laufen lassen kann.&lt;/p>
&lt;h2 id="der-investitionsalgorithmus">Der Investitionsalgorithmus&lt;/h2>
&lt;p>Ich werde den Algorithmus in einem anderen Beitrag auf meiner Website &lt;a href="">www.datafortress.cloud&lt;/a> ausf√ºhrlicher erl√§utern, aber mein typischer Aufbau eines Investitionsalgorithmus besteht aus:&lt;/p>
&lt;ol>
&lt;li>Testen des Algorithmus mit &lt;a href="https://www.backtrader.com/">Backtrader&lt;/a>, einem Open-Source-Backtesting-Framework, das in Python geschrieben wurde&lt;/li>
&lt;li>Konvertieren des erfolgreichen Algorithmus in eine einzelne Python-Datei, die eine run()-Methode enth√§lt, die zur√ºckgibt, welche Investitionen get√§tigt wurden&lt;/li>
&lt;li>√úbertragen der Python-Datei zu AWS Lambda, wo ich die run()-Funktion mit der lambda_handler-Funktion von AWS Lambda aufrufe&lt;/li>
&lt;/ol>
&lt;p>In diesem Beispielalgorithmus treffe ich Investitionsentscheidungen in Abh√§ngigkeit davon, ob der aktuelle Kurs √ºber oder unter der Trendlinie liegt, die vom &lt;a href="https://facebook.github.io/prophet/">Prophetenmodell von Facebook&lt;/a> vorhergesagt wird. Ich habe Ideen von &lt;a href="http://seangtkelley.me/blog/2018/08/15/algo-trading-pt2">Sean Kelley √ºbernommen&lt;/a>, der ein Backtrader-Setup geschrieben hat, wie man Prophet mit Backtrader einsetzen kann.&lt;/p>
&lt;p>Mein Aktienuniversum in diesem Setup wird berechnet, indem ich die 20 besten Aktien aus dem SPY500-Index ausw√§hle, der in den vergangenen X Zeitschritten die h√∂chste Rendite erzielte.&lt;/p>
&lt;p>Die Datenquelle ist Yahoo Finance, unter Verwendung der kostenlosen &lt;a href="">Yfinance-Bibliothek&lt;/a>, und als mein bevorzugter algorithmischer Broker habe ich &lt;a href="https://alpaca.markets/">Alpaca.markets&lt;/a> gew√§hlt.&lt;/p>
&lt;p>In meinem Setup wird der Algorithmus einmal pro Tag um 15 Uhr oder alle 15 Minuten w√§hrend der Handelszeiten ausgef√ºhrt.&lt;/p>
&lt;h2 id="die-probleme-beim-einsatz-des-facebook-propheten-bei-aws-lambda">Die Probleme beim Einsatz des Facebook-Propheten bei AWS Lambda&lt;/h2>
&lt;p>AWS Lambda wird mit einigen Python-Bibliotheken vorinstalliert geliefert, aber wie viele von Ihnen vielleicht wissen, ist dies standardm√§√üig recht begrenzt (was f√ºr Lambda&amp;rsquo;s Versprechen angemessen ist). Dennoch erlaubt Lambda die Installation privater Pakete, was f√ºr kleinere Pakete recht einfach ist (siehe die&lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/python-package.html"> offizielle Dokumentation&lt;/a>), aber etwas komplizierter wird, wenn es sich um Pakete handelt, die gr√∂√üer als 250 Mb sind. Ungl√ºcklicherweise √ºberschreitet das Prophetenmodell von Facebook diese Grenze, aber gl√ºcklicherweise hat &lt;a href="https://towardsdatascience.com/how-to-get-fbprophet-work-on-aws-lambda-c3a33a081aaf">Alexandr Matsenov dieses Problem gel√∂st&lt;/a>, indem er die Paketgr√∂√üe reduziert hat, und &lt;a href="https://github.com/marcmetz/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda">Marc Metz hat sich um Kompilierungsprobleme gek√ºmmert, damit es auf AWS Lambda l√§uft.&lt;/a>&lt;/p>
&lt;p>Nicht standardm√§√üige Bibliotheken k√∂nnen zu AWS Lambda hinzugef√ºgt werden, indem man Layer verwendet, die alle ben√∂tigten Pakete enthalten. Wenn ein Layer importiert wird, k√∂nnen Sie die Pakete einfach in Ihrer Python-Funktion importieren, wie Sie es in Ihrem lokalen Setup tun w√ºrden.&lt;/p>
&lt;h1 id="die-technische-anleitung">Die technische Anleitung&lt;/h1>
&lt;p>Lassen Sie mich abschlie√üend erkl√§ren, wie genau Sie dies erreichen k√∂nnen. Siehe dieses TLDR f√ºr die ungeduldigen Typen oder die detailliertere Version unten.&lt;/p>
&lt;p>&lt;strong>TLDR;&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>Sie ben√∂tigen ein Lambda-Layer, laden Sie meine (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">Download&lt;/a>) mit Prophet, yfinance, &amp;hellip; auf einen S3-Bucket (privater Zugang)&lt;/li>
&lt;li>W√§hlen Sie AWS Lambda, erstellen Sie eine Funktion, f√ºgen Sie ein Layer hinzu und f√ºgen Sie in Ihre S3-Objekt-URL ein&lt;/li>
&lt;li>F√ºgen Sie Ihre lambda_function.py in den Lambda-Editor ein (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">oder verwenden Sie meine&lt;/a>)&lt;/li>
&lt;li>Richten Sie Ihre Umgebungsvariablen ein (optional)&lt;/li>
&lt;li>F√ºhren Sie es entweder manuell aus, indem Sie auf &amp;ldquo;Test&amp;rdquo; klicken, oder gehen Sie zu CloudWatch -&amp;gt; Regeln -&amp;gt; Regel erstellen und richten Sie &amp;ldquo;Ausf√ºhrung planen&amp;rdquo; ein, um es in einem bestimmten Zeitintervall auszuf√ºhren&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Ausf√ºhrliche Erl√§uterung:&lt;/strong>&lt;/p>
&lt;h2 id="1-erstellen-eines-benutzerdefinierten-layers-f√ºr-aws-lambda">1. Erstellen eines benutzerdefinierten Layers f√ºr AWS Lambda&lt;/h2>
&lt;p>Sie k√∂nnen entweder mein Lambda-Layer verwenden, die Facebook Prophet, NumPy, Pandas, Alpaka-Handels-API, yfinance (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda">GitHub&lt;/a>) enth√§lt, oder Sie k√∂nnen Ihre eigene unter Verwendung der &lt;a href="https://medium.com/@marc.a.metz/docker-run-rm-it-v-pwd-var-task-lambci-lambda-build-python3-7-bash-c7d53f3b7eb2">von Marc gegebenen Erkl√§rung zusammenstellen.&lt;/a>&lt;/p>
&lt;p>&lt;strong>Meine Lambda-Schicht verwenden&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>Laden Sie die Zip-Datei von meinem &lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">Github-Repo&lt;/a> herunter, die alle Pakete enth√§lt (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">Link&lt;/a>)&lt;/li>
&lt;li>Da Sie Layer nur bis zu einer Gr√∂√üe von 50 Mb direkt auf Lambda hochladen k√∂nnen, m√ºssen wir die Datei zun√§chst auf AWS S3 hochladen.&lt;/li>
&lt;li>Erstellen Sie einen Bucket und legen Sie die heruntergeladene Zip-Datei in diesen Eimer. Der Zugang kann privat bleiben und muss NICHT √∂ffentlich sein! Kopieren Sie die URL in Ihre Datei (z.B. &lt;a href="https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip" title="https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip">https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip&lt;/a>)&lt;/li>
&lt;li>Loggen Sie sich in AWS ein und gehen Sie zu Lambda -&amp;gt; Layers (&lt;a href="https://eu-central-1.console.aws.amazon.com/lambda/home?region=eu-central-1#/layers">EU central Link&lt;/a>)&lt;/li>
&lt;li>Klicken Sie auf &amp;ldquo;Layer erstellen&amp;rdquo;, geben Sie ihr einen passenden Namen und w√§hlen Sie &amp;ldquo;Eine Datei von Amazon S3 hochladen&amp;rdquo;, und kopieren Sie den Code von Schritt 3 hinein. W√§hlen Sie als Runtimes Python 3.7. Klicken Sie auf &amp;ldquo;Erstellen&amp;rdquo;.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Kompilieren Sie Ihre eigenes Lambda-Layer&lt;/strong>&lt;/p>
&lt;p>Bitte folgen Sie den &lt;a href="https://medium.com/@marc.a.metz/docker-run-rm-it-v-pwd-var-task-lambci-lambda-build-python3-7-bash-c7d53f3b7eb2">Anweisungen von Marc&lt;/a>.&lt;/p>
&lt;h2 id="2-erstellen-einer-lambda-funktion">2. Erstellen einer Lambda Funktion&lt;/h2>
&lt;ol>
&lt;li>√ñffnen Sie das Dashboard der Lambda-Funktion (&lt;a href="https://eu-central-1.console.aws.amazon.com/lambda/home?region=eu-central-1#/functions">EU central Link&lt;/a>) und klicken Sie auf &amp;ldquo;Funktion erstellen&amp;rdquo;.&lt;/li>
&lt;li>Lassen Sie das Kontrollk√§stchen &amp;ldquo;Von Grund auf neu&amp;rdquo; unver√§ndert und geben Sie ihm einen passenden Namen.&lt;/li>
&lt;li>W√§hlen Sie in &amp;ldquo;Runtime&amp;rdquo; Python 3.7, lassen Sie den Rest unver√§ndert und klicken Sie auf &amp;ldquo;Funktion erstellen&amp;rdquo;.&lt;/li>
&lt;li>In der √úbersicht der Registerkarte &amp;ldquo;Designer&amp;rdquo; sehen Sie eine grafische Darstellung Ihrer Lambda-Funktion. Klicken Sie auf das Feld &amp;ldquo;Schichten&amp;rdquo; darunter und klicken Sie auf &amp;ldquo;Eine Schicht hinzuf√ºgen&amp;rdquo;. Wenn Sie den Layer korrekt eingerichtet haben, k√∂nnen Sie ihn im folgenden Dialog ausw√§hlen. Klicken Sie schliesslich auf &amp;ldquo;Hinzuf√ºgen&amp;rdquo;.&lt;/li>
&lt;li>In der Registerkarte &amp;ldquo;Designer&amp;rdquo; w√§hlen Sie Ihre Lambda-Funktion aus. Wenn Sie nach unten scrollen, sehen Sie ein Standard-Python-Code-Snippet in einer Datei namens &amp;ldquo;lambda_function.py&amp;rdquo;. Wenn Sie Ihren Code genauso strukturiert haben wie meinen (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">Link&lt;/a>), k√∂nnen Sie Ihre Funktion mit der run()-Funktion ausf√ºhren. Wenn eine Lambda-Funktion aufgerufen wird, wird sie die lambda_handler(event, context)-Funktion ausf√ºhren, von der aus Sie z.B. die run()-Funktion aufrufen k√∂nnen. Nat√ºrlich k√∂nnen Sie alle Dateien und Funktionen umbenennen, aber der Einfachheit halber habe ich dieses Projekt so belassen, wie es ist.&lt;/li>
&lt;li>F√ºhlen Sie sich frei, &lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">meine Funktion&lt;/a> einfach einzuf√ºgen und zu testen.&lt;/li>
&lt;li>Ein Klick auf &amp;ldquo;Test&amp;rdquo; sollte zu einer erfolgreichen Ausf√ºhrung f√ºhren, andernfalls werden die Fehler im Dialog angezeigt.&lt;/li>
&lt;/ol>
&lt;h2 id="3-umgebungsvariabeln-in-aws-lambda-hinzuf√ºgen-und-nutzen">3. Umgebungsvariabeln in AWS Lambda hinzuf√ºgen und nutzen&lt;/h2>
&lt;p>Sie sollten Ihren Benutzer und Ihr Passwort niemals als Klartext in Ihrem Code hinterlassen, weshalb Sie immer Umgebungsvariablen verwenden sollten! Gl√ºcklicherweise verwendet auch Lambda diese, und sie k√∂nnen leicht mit dem Python-OS-Paket aufgerufen werden. In meinem Skript rufe ich z.B. die Benutzervariable mit os.environ[&amp;lsquo;ALPACAUSER&amp;rsquo;] auf. Die Umgebungsvariablen k√∂nnen im Hauptfunktionsbildschirm von Lambda eingerichtet werden, wenn Sie unter Ihrem Code-Editor nach unten scrollen.&lt;/p>
&lt;h2 id="4-aws-lambda-funktionen-in-einem-bestimmten-zeitintervall-ausl√∂sen">4. AWS Lambda Funktionen in einem bestimmten Zeitintervall ausl√∂sen&lt;/h2>
&lt;p>Das Konzept von Serverless und AWS Lambda basiert auf der Idee, dass eine Funktion ausgef√ºhrt wird, wenn ein Trigger-Ereignis eintritt. In meinem Setup wollte ich, dass die Funktion z.B. alle 15 Minuten w√§hrend der Handelszeiten, Montag bis Freitag, aufgerufen wird. Gl√ºcklicherweise bietet AWS eine M√∂glichkeit, ein Ereignis auszul√∂sen, ohne dass ein Server laufen muss, indem der CloudWatch-Dienst genutzt wird.&lt;/p>
&lt;ol>
&lt;li>Gehen Sie zu CloudWatch (&lt;a href="https://eu-central-1.console.aws.amazon.com/cloudwatch/home?region=eu-central-1">EU central Link&lt;/a>).&lt;/li>
&lt;li>W√§hlen Sie in der linken Leiste &amp;ldquo;Events&amp;rdquo; und &amp;ldquo;Rule&amp;rdquo;.&lt;/li>
&lt;li>Klicken Sie auf &amp;ldquo;Create Rule&amp;rdquo;, und w√§hlen Sie &amp;ldquo;Schedule&amp;rdquo; anstelle von &amp;ldquo;Event pattern&amp;rdquo;. Hier k√∂nnen Sie den einfachen &amp;ldquo;Fixed-rate&amp;rdquo;-Dialog verwenden oder einen Cron-Ausdruck erstellen. Ich benutze &lt;a href="https://crontab.guru/" title="https://crontab.guru/">https://crontab.guru/&lt;/a> (kostenlos), um Cron-Ausdr√ºcke zu erstellen. Mein Cron-Ausdruck f√ºr den oben erw√§hnten Anwendungsfall lautet &amp;ldquo;0/15 13-21 ? * MON-FRI *&amp;rdquo;.&lt;/li>
&lt;li>W√§hlen Sie in der rechten Tafel &amp;ldquo;Add Target&amp;rdquo; und w√§hlen Sie Ihre Lambda-Funktion. Sie wird automatisch zu Lambda hinzugef√ºgt.&lt;/li>
&lt;li>Klicken Sie schlie√ülich auf &amp;ldquo;Details konfigurieren&amp;rdquo;, geben Sie ihr einen Namen und klicken Sie auf &amp;ldquo;Regel erstellen&amp;rdquo;.&lt;/li>
&lt;/ol>
&lt;h2 id="5-optional-log-analysen-errorsuche">5. (optional) Log Analysen, Errorsuche&lt;/h2>
&lt;p>Wenn Sie es bis zu diesem Teil geschafft haben, sollten Sie fertig sein! Wenn Sie aber √ºberpr√ºfen wollen, ob alles funktioniert hat, k√∂nnen Sie mit CloudWatch einen Blick auf die Ausgaben der Lambda-Funktionen werfen. Gehen Sie zu CloudWatch -&amp;gt; Logs -&amp;gt; Log-Gruppen (&lt;a href="https://eu-central-1.console.aws.amazon.com/cloudwatch/home?region=eu-central-1#logsV2:log-groups">EU central Link&lt;/a>) und w√§hlen Sie Ihre Lambda-Funktion aus. In dieser √úbersicht sollten Sie die Ausgaben Ihrer Funktionen sehen k√∂nnen.&lt;/p>
&lt;p>Wenn Ihnen dieser Beitrag gefallen hat, hinterlassen Sie einen Kommentar oder schauen Sie sich andere Beitr√§ge an, um mich weiterhin zum Schreiben zu motivieren üòä.&lt;/p></description></item><item><title>Gesichtserkennung mittels MTCNN</title><link>https://datafortress.cloud/de/blog/face-detection-using-mtcnn/</link><pubDate>Sun, 08 May 2022 07:10:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/face-detection-using-mtcnn/</guid><description>
&lt;h1 id="was-ist-mtcnn">Was ist MTCNN&lt;/h1>
&lt;!-- raw HTML omitted -->
&lt;p>MTCNN ist eine Python (pip)-Bibliothek, die von [Github-Benutzer ipacz] (&lt;a href="https://github.com/ipazc/mtcnn">https://github.com/ipazc/mtcnn&lt;/a>) geschrieben wurde und die [das Papier Zhang, Kaipeng et al. &amp;ldquo;Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks&amp;rdquo; implementiert. IEEE Signal Processing Letters 23.10 (2016): 1499-1503. Querverweis. Web](&lt;a href="https://arxiv.org/abs/1604.02878%5D(https://arxiv.org/abs/1604.02878%20%22https://arxiv.org/abs/1604.02878)">https://arxiv.org/abs/1604.02878%5D(https://arxiv.org/abs/1604.02878%20%22https://arxiv.org/abs/1604.02878)&lt;/a>.&lt;/p>
&lt;p>In diesem Papier schlagen sie einen tief kaskadierten Multi-Task-Rahmen vor, der verschiedene Merkmale von &amp;ldquo;Untermodellen&amp;rdquo; verwendet, um jeweils ihre korrelierenden St√§rken zu verst√§rken.&lt;/p>
&lt;p>MTCNN ist auf einer CPU recht schnell, obwohl S3FD auf einer GPU immer noch schneller l√§uft - aber das ist ein Thema f√ºr einen anderen Beitrag.&lt;/p>
&lt;p>Dieser Beitrag verwendet Code aus den beiden folgenden Quellen, schauen Sie sich diese an, sie sind ebenfalls interessant:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/" title="https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/">https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution" title="https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution">https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;h1 id="grundlegende-verwendung-von-mtcnn">Grundlegende Verwendung von MTCNN&lt;/h1>
&lt;!-- raw HTML omitted -->
&lt;p>Z√∂gern Sie nicht, auf das gesamte Notebook zuzugreifen:&lt;/p>
&lt;p>&lt;a href="https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up" title="https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up">https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up&lt;/a>&lt;/p>
&lt;pre>&lt;code>git clone https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up
&lt;/code>&lt;/pre>
&lt;p>Gl√ºcklicherweise ist MTCNN als Pip-Paket erh√§ltlich, was bedeutet, dass wir es leicht installieren k√∂nnen mit&lt;/p>
&lt;pre>&lt;code>pip install mtcnn
&lt;/code>&lt;/pre>
&lt;p>Wenn wir jetzt zu Python/Jupyter Notebook wechseln, k√∂nnen wir die Installation mit einem Import und einer schnellen √úberpr√ºfung √ºberpr√ºfen:&lt;/p>
&lt;pre>&lt;code>import mtcnn
# print version
print(mtcnn.__version__)
&lt;/code>&lt;/pre>
&lt;p>Danach sind wir bereit, das Testbild mit der Matplotlib [imread-Funktion] (&lt;a href="https://bit.ly/2vo3INw">https://bit.ly/2vo3INw&lt;/a>) auszuladen.&lt;/p>
&lt;pre>&lt;code>import matplotlib.pyplot as plt
# load image from file
filename = &amp;quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&amp;quot;
pixels = plt.imread(filename)
print(&amp;quot;Shape of image/array:&amp;quot;,pixels.shape)
imgplot = plt.imshow(pixels)
plt.show()
&lt;/code>&lt;/pre>
&lt;p>Nun wird Ihre Ausgabe in etwa so aussehen:&lt;/p>
&lt;pre>&lt;code>{'box': [1942, 716, 334, 415], 'Vertrauen': 0,999999997615814209, 'Schl√ºsselpunkte': {'linkes_Auge': (2053, 901), &amp;quot;rechtes_Auge&amp;quot;: (2205, 897), &amp;quot;Nase&amp;quot;: (2139, 976), &amp;quot;Mund_links&amp;quot;: (2139, 976), &amp;quot;Mund_links&amp;quot;: (2058, 1029), 'Mund_rechts': (2058, 1029), 'Mund_rechts': (2206, 1023)}}
{&amp;quot;Kiste&amp;quot;: [2084, 396, 37, 46], 'Vertrauen': 0,9999206066131592, 'Schl√ºsselpunkte': {'linkes_Auge': [2084, 396, 37, 46], 'Vertrauen': [2084, 396, 37, 46], 'Vertrauen': 0,99999206066131592, 'Schl√ºsselpunkte': [0,9999206066131592], 'Vertrauen (2094, 414), &amp;quot;rechtes_Auge&amp;quot;: (2094, 414), &amp;quot;rechtes_Auge&amp;quot;: (2112, 414), &amp;quot;Nase&amp;quot;: (2094, 414), &amp;quot;Nase&amp;quot;: (2102, 426), &amp;quot;Mund_links&amp;quot;: (2095, 432), &amp;quot;Mund_rechts&amp;quot;: (2112, 431)}}
{&amp;quot;Kiste&amp;quot;: [1980, 381, 44, 59], 'Vertrauen': 0,9998701810836792, 'Schl√ºsselpunkte': {'linkes_Auge': [1980, 381, 44, 59], 'Vertrauen': 0,9998701810836792, 'Schl√ºsselpunkte': [1980, 381, 44, 59]: (1997, 404), &amp;quot;rechtes_Auge&amp;quot;: (2019, 407), &amp;quot;Nase&amp;quot;: (1997, 404), &amp;quot;Nase&amp;quot;: (2010, 417), &amp;quot;Mund_links&amp;quot;: (2010, 417), &amp;quot;Mund_links&amp;quot;: (1995, 425), &amp;quot;Mund_rechts&amp;quot;: (1995, 425), &amp;quot;Mund_rechts&amp;quot;: (2015, 427)}}
{&amp;quot;Kiste&amp;quot;: [2039, 395, 39, 46], 'Vertrauen': 0,9993435740470886, 'Schl√ºsselpunkte': {'linkes_Auge': [2039, 395, 39, 46], 'Vertrauen': 0,9993435740470886, 'Vertrauen': 0,9993435740470886, 'Schl√ºsselpunkte': [2039, 395, 39, 46]: (2054, 409), &amp;quot;rechtes_Auge&amp;quot;: (2054, 409), &amp;quot;rechtes_Auge&amp;quot;: (2071, 415), &amp;quot;Nase&amp;quot;: (2054, 409), &amp;quot;Nase&amp;quot;: (2058, 422), &amp;quot;Mund_links&amp;quot;: (2048, 425), 'Mund_rechts': (2048, 425), 'Mund_rechts': (2065, 431)}}
&lt;/code>&lt;/pre>
&lt;p>Was sagt uns das? Vieles davon ist selbsterkl√§rend, aber im Grunde liefert es Koordinaten oder die Pixelwerte eines Rechtecks, in dem der MTCNN-Algorithmus Gesichter erkannt hat. Der obige &amp;ldquo;Kasten&amp;rdquo;-Wert gibt die Position des gesamten Gesichts zur√ºck, gefolgt von einem &amp;ldquo;Vertrauens&amp;rdquo;-Level.&lt;/p>
&lt;p>Wenn Sie fortgeschrittenere Extraktionen oder Algorithmen durchf√ºhren m√∂chten, haben Sie auch Zugang zu anderen Landmarken des Gesichts, die als &amp;ldquo;Schl√ºsselpunkte&amp;rdquo; bezeichnet werden. Das MTCNN-Modell lokalisierte n√§mlich auch die Augen, den Mund und die Nase!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="zeichnen-eines-kastens-um-gesichter">Zeichnen eines Kastens um Gesichter&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;p>Um dies noch besser zu demonstrieren, zeichnen wir mit matplotlib einen Kasten um das Gesicht:&lt;/p>
&lt;pre>&lt;code># draw an image with detected objects
def draw_facebox(filename, result_list):
# load the image
data = plt.imread(filename)
# plot the image
plt.imshow(data)
# get the context for drawing boxes
ax = plt.gca()
# plot each box
for result in result_list:
# get coordinates
x, y, width, height = result['box']
# create the shape
rect = plt.Rectangle((x, y), width, height, fill=False, color='green')
# draw the box
ax.add_patch(rect)
# show the plot
plt.show()
# filename = 'test1.webp' # filename is defined above, otherwise uncomment
# load image from file
# pixels = plt.imread(filename) # defined above, otherwise uncomment
# detector is defined above, otherwise uncomment
#detector = mtcnn.MTCNN()
# detect faces in the image
faces = detector.detect_faces(pixels)
# display faces on the original image
draw_facebox(filename, faces)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://datafortress.cloud/images/index-1-150x150.webp" alt="">&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="darstellung-von-augen-mund-und-nase-um-gesichter">Darstellung von Augen, Mund und Nase um Gesichter&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;p>Werfen wir nun einen Blick auf die oben erw√§hnten &amp;ldquo;Schl√ºsselpunkte&amp;rdquo;, die das MTCNN-Modell zur√ºckgebracht hat.&lt;/p>
&lt;p>Wir werden diese nun auch f√ºr die Darstellung von Nase, Mund und Augen verwenden.&lt;br>
Wir werden den folgenden Codeschnipsel zu unserem obigen Code hinzuf√ºgen:&lt;/p>
&lt;pre>&lt;code># draw the dots
for key, value in result['keypoints'].items():
# create and draw dot
dot = plt.Circle(value, radius=20, color='orange')
ax.add_patch(dot)
&lt;/code>&lt;/pre>
&lt;p>Mit dem vollst√§ndigen Code von oben, der wie folgt aussieht:&lt;/p>
&lt;pre>&lt;code># draw an image with detected objects
def draw_facebox(filename, result_list):
# load the image
data = plt.imread(filename)
# plot the image
plt.imshow(data)
# get the context for drawing boxes
ax = plt.gca()
# plot each box
for result in result_list:
# get coordinates
x, y, width, height = result['box']
# create the shape
rect = plt.Rectangle((x, y), width, height,fill=False, color='orange')
# draw the box
ax.add_patch(rect)
# draw the dots
for key, value in result['keypoints'].items():
# create and draw dot
dot = plt.Circle(value, radius=20, color='red')
ax.add_patch(dot)
# show the plot
plt.show()
# filename = 'test1.webp' # filename is defined above, otherwise uncomment
# load image from file
# pixels = plt.imread(filename) # defined above, otherwise uncomment
# detector is defined above, otherwise uncomment
#detector = mtcnn.MTCNN()
# detect faces in the image
faces = detector.detect_faces(pixels)
# display faces on the original image
draw_facebox(filename, faces)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://datafortress.cloud/images/index2-150x150.webp" alt="">&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="erweitertes-mtcnn-beschleunigen-sie-es-x100">Erweitertes MTCNN: Beschleunigen Sie es (\\~x100)!&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;p>Kommen wir nun zum interessanten Teil. Wenn Sie Millionen von Bildern verarbeiten wollen, m√ºssen Sie MTCNN beschleunigen, sonst werden Sie entweder einschlafen oder Ihre CPU wird verbrennen, bevor sie fertig ist.&lt;/p>
&lt;p>Aber wor√ºber genau reden wir hier? Wenn Sie den obigen Code ausf√ºhren, dauert es etwa eine Sekunde, d.h. wir werden etwa ein Bild pro Sekunde verarbeiten. Wenn Sie MTCNN auf einer GPU ausf√ºhren und die beschleunigte Version verwenden, werden etwa 60-100 Bilder pro Sekunde erreicht. Das ist eine Steigerung von bis zu &lt;strong>100 Mal&lt;/strong>!&lt;/p>
&lt;p>Wenn Sie z.B. alle Gesichter eines Films extrahieren wollen, wobei Sie 10 Gesichter pro Sekunde extrahieren (eine Sekunde des Films hat im Durchschnitt etwa 24 Bilder, also jedes zweite Bild), dann sind es 10 * 60 (Sekunden) * 120 (Minuten) = 72.000 Bilder.&lt;/p>
&lt;p>Das hei√üt, wenn die Verarbeitung eines Einzelbildes eine Sekunde dauert, dauert sie 72.000 * 1 (Sekunden) = 72.000s / 60s = 1.200m = &lt;strong>20 Stunden&lt;/strong>.&lt;/p>
&lt;p>Mit der Beschleunigungsversion von MTCNN wird diese Aufgabe 72.000 (Frames) / 100 (Frames/sec) = 720 Sekunden = &lt;strong>12 Minuten&lt;/strong> dauern!&lt;/p>
&lt;p>Um MTCNN auf einer GPU zu verwenden, m√ºssen Sie CUDA, cudnn, pytorch usw. einrichten. &lt;a href="https://pytorch.org/get-started/locally/">Pytorch hat ein gutes Tutorial zu diesem Teil geschrieben&lt;/a>.&lt;/p>
&lt;p>Nach der Installation werden wir die notwendigen Importe wie folgt durchf√ºhren:&lt;/p>
&lt;pre>&lt;code>from facenet_pytorch import MTCNN
from PIL import Image
import torch
from imutils.video import FileVideoStream
import cv2
import time
import glob
from tqdm.notebook import tqdm
device = 'cuda' if torch.cuda.is_available() else 'cpu'
filenames = [&amp;quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&amp;quot;,&amp;quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&amp;quot;]
&lt;/code>&lt;/pre>
&lt;p>Sehen Sie, wie wir das Ger√§t im obigen Code definiert haben. Sie k√∂nnen alles auch auf einer CPU laufen lassen, wenn Sie CUDA nicht einrichten wollen oder k√∂nnen.&lt;/p>
&lt;p>Als n√§chstes werden wir den Extraktor definieren:&lt;/p>
&lt;pre>&lt;code># define our extractor
fast_mtcnn = FastMTCNN(
stride=4,
resize=0.5,
margin=14,
factor=0.6,
keep_all=True,
device=device
)
&lt;/code>&lt;/pre>
&lt;p>In diesem Schnipsel geben wir einige Parameter weiter, wobei wir zum Beispiel nur die halbe Bildgr√∂√üe verwenden, was einer der Haupteinflussfaktoren f√ºr die Beschleunigung ist.&lt;/p>
&lt;p>Und schlie√ülich lassen wir das Skript zur Gesichtsextraktion laufen:&lt;/p>
&lt;pre>&lt;code>def run_detection(fast_mtcnn, filenames):
frames = []
frames_processed = 0
faces_detected = 0
batch_size = 60
start = time.time()
for filename in tqdm(filenames):
v_cap = FileVideoStream(filename).start()
v_len = int(v_cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))
for j in range(v_len):
frame = v_cap.read()
frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
frames.append(frame)
if len(frames) &amp;gt;= batch_size or j == v_len - 1:
faces = fast_mtcnn(frames)
frames_processed += len(frames)
faces_detected += len(faces)
frames = []
print(
f'Frames per second: {frames_processed / (time.time() - start):.3f},',
f'faces detected: {faces_detected}\r',
end=''
)
v_cap.stop()
run_detection(fast_mtcnn, filenames)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://datafortress.cloud/images/teslap100frames.webp" alt="">&lt;/p>
&lt;p>Das obige Bild zeigt die Ausgabe des Codes, der auf einem NVIDIA Tesla P100 l√§uft. Je nach Quellmaterial, Grafikprozessor und Prozessor kann die Leistung also besser oder schlechter ausfallen.&lt;/p>
&lt;p>&lt;a href="https://www.datafortress.cloud/de/contact/">Sie haben eine √§hnliche Idee oder wir haben Ihr Interesse geweckt? Kontaktieren Sie uns jetzt f√ºr eine gratis 15-min√ºtige Beratung!&lt;/a>&lt;/p></description></item><item><title>How To - Weg mit Ubuntu zugunsten von Arch Linux f√ºr eine Deep Learning-optimierte Arbeitsumgebung</title><link>https://datafortress.cloud/de/blog/anleitung-wie-bauche-ich-eine-arch-linux-machine-learning-workstation/</link><pubDate>Fri, 29 Apr 2022 07:10:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/anleitung-wie-bauche-ich-eine-arch-linux-machine-learning-workstation/</guid><description>
&lt;h1 id="how-to---weg-mit-ubuntu-zugunsten-von-arch-linux-f√ºr-eine-machine-learning-optimierte-arbeitsumgebung">How To - Weg mit Ubuntu zugunsten von Arch Linux f√ºr eine Machine Learning-optimierte Arbeitsumgebung&lt;/h1>
&lt;h2 id="warum-sollte-ich-ubuntu-ersetzen">Warum sollte ich Ubuntu ersetzen?&lt;/h2>
&lt;p>Die meisten von Ihnen verwenden vielleicht Ubuntu f√ºr ihre Workstations, und das ist f√ºr die unerfahreneren Benutzer in Ordnung. Eines der Probleme, die ich jedoch mit Ubuntu und Tensorflow/CUDA hatte, war, dass der Umgang mit den verschiedenen Treibern und Versionen von CUDA, cudnn, TensorFlow und so weiter ein ziemlicher Kampf war. Bei Ihnen bin ich mir nicht sicher, aber sobald ich eine funktionierende Tensorflow 1.15 oder 2.0-Umgebung hatte, habe ich sie normalerweise nicht mehr angefasst, weil ich Angst hatte, diese heilige Konfiguration durcheinander zu bringen.&lt;/p>
&lt;p>Wenn man mit verschiedenen Programmen arbeitet, w√§re es sch√∂n, eine M√∂glichkeit zu haben, zwischen den beiden meistgenutzten TensorFlow Versionen 1.15 und 2.0 zu wechseln, wie man es mit Google Colab mit einem einzigen Befehl tun kann, aber die Installation einer anderen TensorFlow Version hat mein System normalerweise wieder durcheinander gebracht.&lt;/p>
&lt;p>Au√üerdem stand Arch schon immer auf meiner To-Do-Liste, da es die beste &amp;ldquo;Barebone&amp;rdquo;-Linux-Distribution ist, die man bekommen kann, was bedeutet, dass man im Vergleich zu &amp;ldquo;h√∂heren Abstraktionen&amp;rdquo; wie Ubuntu viel n√§her an der Hardware arbeitet. Nach ihren eigenen Worten ist Ubuntu daf√ºr gebaut, &amp;ldquo;out of the box zu arbeiten und den Installationsprozess f√ºr neue Benutzer so einfach wie m√∂glich zu machen&amp;rdquo;, w√§hrend das Motto von Arch Linux &amp;ldquo;alles anpassen&amp;rdquo; lautet.
Da Arch viel n√§her an der Hardware ist, ist es im Vergleich zu Ubuntu wahnsinnig schneller (und Windows meilenweit voraus), und das bei den Kosten f√ºr mehr Terminal-Nutzung.&lt;/p>
&lt;p>Wenn ich Arch in den letzten Wochen benutzt habe, hat sich die RAM-Nutzung normalerweise im Vergleich zu Ubuntu halbiert, und die Installation von Machine-Learning-Paketen ist ein Kinderspiel. Ich kann sowohl TensorFlow 1.15 als auch 2.0 zusammenarbeiten lassen, indem ich die Versionen mit Anaconda-Umgebungen austausche. Au√üerdem arbeitet das System recht stabil, da ich die LTS-Kernel (Long Term Support) von Linux verwende und Aktualisierungen der ber√ºhmten AUR-Pakete (User Made Packages in Arch) normalerweise einen Monat vor den Debian-Paketen (Ubuntu) herauskommen.&lt;/p>
&lt;p>Alles in allem kann ich nur empfehlen, eine Arch-Linux-Deep-Learning-Station so einzurichten, wie sie ist:&lt;/p>
&lt;ol>
&lt;li>Schneller, so wie sich Pakete superschnell installieren lassen, ist tiefes Lernen aufgeladen, &amp;hellip;&lt;/li>
&lt;li>Stabiler&lt;/li>
&lt;li>Einfacherer Wechsel zwischen TensorFlow Versionen
im Vergleich zu Ubuntu.&lt;/li>
&lt;/ol>
&lt;p>Ich werde die Anleitung in zwei Teile aufteilen, wobei der erste Teil &amp;ldquo;&lt;a href="//www.datafortress.cloud/blog/howto-install-arch-linux-the-easy-way/">Wie installiere ich Arch Linux&lt;/a>&amp;rdquo; und der zweite Teil &amp;ldquo;&lt;a href="//www.datafortress.cloud/blog/howto-arch-linux-deeplearning-workstation/">Wie installiere ich die Deep-Learning-Workstation-Pakete&lt;/a>&amp;rdquo; lautet.&lt;/p>
&lt;p>F√ºr das allgemeine &lt;a href="//www.datafortress.cloud/blog/howto-install-arch-linux-the-easy-way/">&amp;ldquo;Wie man Arch Linux installiert&amp;rdquo;, gehen Sie zu diesem Artikel&lt;/a>.&lt;/p>
&lt;p>Wenn Arch f√ºr den Moment zu komplex ist, k√∂nnten Sie &lt;a href="//manjaro.org/">Manjaro&lt;/a> ausprobieren, eine benutzerfreundliche Version von Arch, auch wenn ich nicht garantieren kann, dass alle Pakete gleich funktionieren, da sie leicht unterschiedlich sind. Alles in allem sollte es aber gleich funktionieren.&lt;/p>
&lt;p>Ich habe dar√ºber nachgedacht, ein installationsfertiges Image (iso oder img) zu erstellen, wenn gen√ºgend Leute daran interessiert sind, hinterlassen Sie einen Kommentar unten oder schreiben Sie mir eine Nachricht!&lt;/p>
&lt;h2 id="installation-des-deep-learning-tensorflow-cuda-cudnn-anaconda-setups-auf-einer-frischen-arch-linux-installation">Installation des Deep Learning (TensorFlow, CUDA, CUDNN, Anaconda) Setups auf einer frischen Arch-Linux-Installation&lt;/h2>
&lt;p>Wenn Sie &lt;a href="//www.datafortress.cloud/blog/howto-install-arch-linux-the-easy-way/">mit der Installation von Arch (puh!)&lt;/a> fertig sind, lassen Sie uns zun√§chst einige Einstellungen so √§ndern, dass unser System stabiler arbeitet.&lt;/p>
&lt;h3 id="1-umschalten-auf-die-schnellsten-spiegel">1. Umschalten auf die schnellsten Spiegel&lt;/h3>
&lt;p>Software wird von so genannten &amp;ldquo;Mirrors&amp;rdquo; heruntergeladen, das sind Server, die alle Arch-Bibliotheken enthalten. Wenn dies nicht automatisch geschieht, kann es passieren, dass Ihre Server noch nicht optimiert sind. Deshalb werden wir ein kleines Tool installieren, das die schnellsten Server findet und speichert, den sogenannten &amp;ldquo;Spiegel&amp;rdquo;.&lt;/p>
&lt;p>Installieren Sie den Reflektor mit&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S reflector&lt;/p>
&lt;/blockquote>
&lt;p>Finden Sie die besten Server und laden Sie sie herunter&lt;/p>
&lt;blockquote>
&lt;p>reflector &amp;ndash;verbose -l 20 -n 20 &amp;ndash;sort rate &amp;ndash;save /etc/pacman.d/mirrorlist&lt;/p>
&lt;/blockquote>
&lt;p>Pr√ºfen Sie die Ausgabe, ob sie sinnvoll ist, z.B. wenn die Domains in der N√§he Ihres Standortes liegen. Wenn nicht, k√∂nnen Sie das L√§nderkennzeichen hinzuf√ºgen, um genauere Ergebnisse zu erhalten, z.B. f√ºr Deutschland und √ñsterreich:&lt;/p>
&lt;blockquote>
&lt;p>reflector -c ‚ÄúAT,DE‚Äù &amp;ndash;verbose -l 20 -n 20 &amp;ndash;sort rate &amp;ndash;save /etc/pacman.d/mirrorlist&lt;/p>
&lt;/blockquote>
&lt;p>Aktualisieren Sie Ihre Installation&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -Syyu&lt;/p>
&lt;/blockquote>
&lt;h3 id="2-√§ndern-der-desktop-umgebung">2. √Ñndern der Desktop-Umgebung&lt;/h3>
&lt;p>Wenn Sie Manjaro verwenden oder die &amp;ldquo;Gnome&amp;rdquo;-Desktop-Umgebung w√§hlen, wie Sie sie von Ubuntu her kennen, k√∂nnte es sich lohnen, dar√ºber nachzudenken, sie zu √§ndern, da Gnome bekannterma√üen mehr RAM als Chrome frisst, und wir in unserem Deep Learning-Setup sicherlich RAM ben√∂tigen.&lt;/p>
&lt;p>Wenn Ihnen Gnome gef√§llt, k√∂nnen Sie diesen Schritt gerne √ºberspringen. Ansonsten kann ich den Xfce-Desktop empfehlen, da er eine gute Kombination aus geringem Gewicht und vielen Funktionen ist.&lt;/p>
&lt;p>Xfce herunterladen&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S xfce4 xfce4-goodies lxdm&lt;/p>
&lt;/blockquote>
&lt;p>Lxdm ist ein Displaymanager, mit dem Sie mehrere Desktops verwenden k√∂nnen.&lt;/p>
&lt;p>Melden Sie sich von Ihrer aktuellen Sitzung ab und dr√ºcken Sie Alt + F2 (oder Alt + F3, wenn es nicht funktioniert), um ein Terminal zu erhalten. Deaktivieren Sie zuerst Gnome und &amp;ldquo;aktivieren&amp;rdquo; Sie danach Xfce:&lt;/p>
&lt;blockquote>
&lt;p>sudo systemctl disable gdm &lt;br>
sudo pacman -R gnome gnome-extras&lt;/p>
&lt;/blockquote>
&lt;p>Aktiviere Xfce&lt;/p>
&lt;blockquote>
&lt;p>sudo systemctl enable lxdm &lt;br>
sudo systemctl start lxdm&lt;/p>
&lt;/blockquote>
&lt;p>Wenn die neue Xfce-Arbeitsoberfl√§che ge√∂ffnet wird, melden Sie sich einfach an und erkunden Sie sie, wenn nicht, versuchen Sie einen Neustart (sudo reboot). Wenn das nicht hilft, fahren Sie fort zu weinen und sich auf dem Boden zu w√§lzen, und senden Sie mir danach eine Nachricht oder einen Kommentar.&lt;/p>
&lt;h3 id="3-installation-der-lts-langzeit-unterst√ºtzung-linux-kernel-f√ºr-bessere-stabilit√§t">3. Installation der LTS (Langzeit-Unterst√ºtzung) Linux-Kernel f√ºr bessere Stabilit√§t&lt;/h3>
&lt;p>Arch ist ber√ºhmt daf√ºr, dass er den aktuellen Linux-Kerneln sehr nahe kommt, was gut ist, wenn Sie immer die neuesten Pakete und Linux-Funktionen wollen, aber eine schlechte Idee, wenn Sie eine Deep Learning Workstation bauen.&lt;/p>
&lt;p>Deshalb bin ich auf die LTS-Kernel umgestiegen, die im Grunde Kernel sind, die mehr Unterst√ºtzung erhalten und stabiler sind als die neueren Versionen des Linux-Kernels.&lt;/p>
&lt;p>Zum Gl√ºck ist der Wechsel des Kernels in Arch. Zuerst werden wir die Kernel herunterladen und danach unserem Bootmanager mitteilen, welchen Kernel er w√§hlen soll.&lt;/p>
&lt;p>Zuerst laden wir die LTS-Kernel herunter:&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S linux-lts linux-lts-headers&lt;/p>
&lt;/blockquote>
&lt;p>Werfen Sie einen Blick auf Ihre aktuellen Kernel-Versionen:&lt;/p>
&lt;blockquote>
&lt;p>ls -lsha /boot&lt;/p>
&lt;/blockquote>
&lt;p>Ein Kernel sollte vmlinuz-linux.img und initramfs-linux.img (Ihre aktuellen Versionen) hei√üen und die LTS-Kernel die gleichen mit -lts am Ende.&lt;/p>
&lt;p>Wenn Sie zwei Kernel sehen, k√∂nnen Sie nun damit fortfahren, die alten Kernel zu l√∂schen:&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -R linux&lt;/p>
&lt;/blockquote>
&lt;p>Ein fortgeschrittener Teil ist nun, dass Sie Ihrem Bootloader mitteilen m√ºssen, welchen Kernel er w√§hlen soll. Die Frage ist, welchen Bootloader Sie verwenden, aber in den meisten F√§llen ist es Grub. Wenn Sie &lt;a href="//www.datafortress.cloud/blog/howto-install-arch-linux-the-easy-way/">meinem Arch-Installations-Tutorial gefolgt sind&lt;/a>, ist Ihr Bootloader systemd-boot.&lt;/p>
&lt;p>Meine Empfehlung ist, die Grub-Anweisungen auszuprobieren, und wenn das nicht funktioniert, fahren Sie mit den anderen fort.&lt;/p>
&lt;h4 id="√§ndern-des-grub-bootloaders-f√ºr-die-lts-linux-kernel">√Ñndern des Grub-Bootloaders f√ºr die LTS-Linux-Kernel&lt;/h4>
&lt;blockquote>
&lt;p>grub-mkconfig -o /boot/grub/grub.cfg&lt;/p>
&lt;/blockquote>
&lt;p>Wenn Sie einen Fehler sehen, fahren Sie mit dem n√§chsten Bootloader fort, andernfalls f√ºhren Sie einen Neustart (sudo reboot) durch.&lt;/p>
&lt;h4 id="√§ndern-des-syslinux-bootloaders-f√ºr-die-lts-linux-kernel">√Ñndern des syslinux-Bootloaders f√ºr die LTS-Linux-Kernel&lt;/h4>
&lt;p>Bearbeiten Sie die Konfigurationsdatei:&lt;/p>
&lt;blockquote>
&lt;p>sudo nano /boot/syslinux/syslinux.cfg&lt;/p>
&lt;/blockquote>
&lt;p>F√ºgen Sie einfach &amp;ldquo;-lts&amp;rdquo; in die vmlinuz-linux.img und initramfs-linux.img ein, so dass sie vmlinuz-linux-lts.img und initramfs-linux-lts.img sind.&lt;/p>
&lt;h4 id="changing-the-systemd-boot-bootloader-for-the-lts-linux-kernels">Changing the systemd-boot bootloader for the LTS linux kernels&lt;/h4>
&lt;p>Wenn Sie aus meiner Arch-Installationsanleitung kommen, ist dies Ihr Bootloader.&lt;/p>
&lt;p>Bearbeiten Sie die Konfigurationsdatei:&lt;/p>
&lt;blockquote>
&lt;p>sudo nano /boot/loader/entries/arch.conf&lt;/p>
&lt;/blockquote>
&lt;p>F√ºgen Sie einfach &amp;ldquo;-lts&amp;rdquo; in die vmlinuz-linux.img und initramfs-linux.img ein, so dass sie vmlinuz-linux-lts.img und initramfs-linux-lts.img sind&lt;/p>
&lt;h3 id="4-installieren-von-yay-ein-einfacher-weg-aur-pakete-zu-installieren">4. Installieren von yay, ein einfacher Weg, AUR-Pakete zu installieren&lt;/h3>
&lt;p>Sie sollten es vorziehen, den ultraschnellen Pacman zur Installation der meisten Pakete zu verwenden, aber das Erstaunliche an Arch ist, dass Benutzer Millionen von benutzerdefinierten Paketen erstellen, die superleicht zu installieren sind. Sie k√∂nnen im Grunde jedes Programm, das Ihnen einf√§llt, in diesem Repo finden.&lt;/p>
&lt;p>git SVC installieren&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S git &lt;br>
mkdir ~/tmp &lt;br>
git-clone &lt;a href="https://aur.archlinux.org/yay-git.git">https://aur.archlinux.org/yay-git.git&lt;/a> ~/tmp/yay &lt;br>
cd ~/tmp/yay &lt;br>
makepkg -si&lt;/p>
&lt;/blockquote>
&lt;p>Jetzt k√∂nnen Sie all die sch√∂nen AUR-Pakete unter &lt;a href="https://aur.archlinux.org/packages/">https://aur.archlinux.org/packages/&lt;/a> durchst√∂bern oder einfach loslegen und tippen:&lt;/p>
&lt;blockquote>
&lt;p>yay -S [PAKET]&lt;/p>
&lt;/blockquote>
&lt;p>Um es zu installieren.&lt;/p>
&lt;h3 id="5-schlie√ülich-die-eigentliche-cuda-cudnn-anaconda-installation-auf-der-sowohl-tensorflow-115-als-auch-20-l√§uft">5. Schlie√ülich die eigentliche cuda, cudnn, anaconda-Installation, auf der sowohl TensorFlow 1.15 als auch 2.0 l√§uft&lt;/h3>
&lt;p>Installieren Sie Nvidia-Treiber, cuda, cudnn mit einem einfachen Befehl&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S nvidia nvidia-utils cuda cudnn&lt;/p>
&lt;/blockquote>
&lt;p>Dies dauert einige Zeit, also holen Sie sich einen Kaffee oder fahren Sie mit den n√§chsten Schritten fort&lt;/p>
&lt;p>Anakonda herunterladen, ich mag Miniconda:&lt;/p>
&lt;blockquote>
&lt;p>wget &lt;a href="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh">https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh&lt;/a> ~/&lt;/p>
&lt;/blockquote>
&lt;p>Ausf√ºhrbar machen und installieren&lt;/p>
&lt;blockquote>
&lt;p>cd ~/ &lt;br>
chmod +x ./Miniconda*.sh &lt;br>
./Miniconda*.sh&lt;/p>
&lt;/blockquote>
&lt;p>Lassen Sie einfach alles auf Standard.&lt;/p>
&lt;blockquote>
&lt;p>source ./bash_profile&lt;/p>
&lt;/blockquote>
&lt;p>Starten Sie Ihr System neu&lt;/p>
&lt;blockquote>
&lt;p>sudo reboot&lt;/p>
&lt;/blockquote>
&lt;p>Tensorflow installieren&lt;/p>
&lt;p>Jetzt ist es an der Zeit, sich zwischen TensorFlow f√ºr CPU oder GPU zu entscheiden. Ich werde mit der GPU-Option fortfahren, aber wenn Sie die CPU-Version laufen lassen wollen, entfernen Sie einfach das &amp;ldquo;-gpu&amp;rdquo; aus dem Paketnamen.&lt;/p>
&lt;h5 id="erstellen-sie-eine-anakonda-umgebung-f√ºr-tensorflow-20">Erstellen Sie eine Anakonda-Umgebung f√ºr Tensorflow 2.0&lt;/h5>
&lt;blockquote>
&lt;p>conda create &amp;ndash;name tf2.0 &lt;br>
conda activate tf2.0 &lt;br>
conda pip install &lt;br>
conda install tensorflow-gpu pandas numpy&lt;/p>
&lt;/blockquote>
&lt;p>Erledigt! √úberpr√ºfen Sie nun das Ergebnis mit:&lt;/p>
&lt;blockquote>
&lt;p>python &lt;br>
from tensorflow.python.client import device_lib &lt;br>
device_lib.list_local_devices()&lt;/p>
&lt;/blockquote>
&lt;p>Wenn das Ergebnis einen Ger√§tenamen wie diesen zeigt, sind Sie fertig!&lt;/p>
&lt;p>2018-05-01 05:25:25.929575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Ger√§t 0 mit Eigenschaften gefunden:
Name: GeForce GTX 3080 10GB Dur: &amp;hellip;&lt;/p>
&lt;h5 id="erstellen-sie-eine-anakonda-umgebung-f√ºr-tensorflow-115">Erstellen Sie eine Anakonda-Umgebung f√ºr Tensorflow 1.15&lt;/h5>
&lt;blockquote>
&lt;p>conda deactivate &lt;br>
conda create &amp;ndash;name tf1.15 &lt;br>
conda activate tf1.15 &lt;br>
conda install pip python==3.7 &lt;br>
conda install tensorflow-gpu===1.15&lt;/p>
&lt;/blockquote>
&lt;p>Und √ºberpr√ºfen Sie nochmals, ob alles funktioniert und Ihre gpu erkannt wird:&lt;/p>
&lt;blockquote>
&lt;p>python &lt;br>
from tensorflow.python.client import device_lib &lt;br>
device_lib.list_local_devices()&lt;/p>
&lt;/blockquote>
&lt;h3 id="6-umschalten-zwischen-tensorflow-115-und-tensorflow-20-auf-einem-ger√§t">6. Umschalten zwischen TensorFlow 1.15 und TensorFlow 2.0 auf einem Ger√§t!&lt;/h3>
&lt;p>Meiner Meinung nach ein Traum der wahr wird, w√§hlen Sie einfach die Version 1.15 mit&lt;/p>
&lt;blockquote>
&lt;p>conda activate tf1.15&lt;/p>
&lt;/blockquote>
&lt;p>Und die TensorFlow 2.0 Version mit&lt;/p>
&lt;blockquote>
&lt;p>conda activate tf2.0&lt;/p>
&lt;/blockquote></description></item></channel></rss>