<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Datafortress.cloud</title><link>https://datafortress.cloud/de/tags/machine-learning/</link><description>Recent content in machine learning on Datafortress.cloud</description><generator>Hugo -- gohugo.io</generator><language>de-de</language><managingEditor/><webMaster/><lastBuildDate>Wed, 08 Feb 2023 07:10:46 +0200</lastBuildDate><atom:link href="https://datafortress.cloud/de/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Entfaltung des Potenzials des maschinellen Lernens mit privaten Cloud-Diensten: Fallstudien aus der Praxis</title><link>https://datafortress.cloud/de/blog/case-study-real-world-applications-private-cloud/</link><pubDate>Wed, 08 Feb 2023 07:10:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/case-study-real-world-applications-private-cloud/</guid><description>
&lt;h1 id="unlocking-the-potential-of-machine-learning-with-private-cloud-services-real-world-fallstudien">Unlocking the Potential of Machine Learning with Private Cloud Services: Real-World Fallstudien&lt;/h1>
&lt;p>Willkommen in der Welt des datengesteuerten Geschäftserfolgs! In der heutigen schnelllebigen und sich ständig verändernden Geschäftswelt, die Unternehmen suchen ständig nach neuen Wegen, um ihre Arbeitsabläufe zu verbessern und der Konkurrenz voraus zu sein. Maschinelles Lernen und private Cloud-Dienste haben sich als Wegbereiter erwiesen, Bereitstellung von Werkzeugen für Unternehmen, die das volle Potenzial ihrer Daten ausschöpfen wollen. In diesem Artikel, werfen wir einen Blick auf reale Beispiele von Unternehmen, die sich die Kraft dieser Spitzentechnologien zunutze gemacht haben, um ihr Wachstum zu fördern, den Betrieb rationalisieren, und schützen sensible Informationen. Also anschnallen, und machen Sie sich bereit, die vielen Vorteile von maschinellem Lernen und privaten Cloud-Diensten zu entdecken!&lt;/p>
&lt;h2 id="fallstudie-1-automatisierte-betrugserkennung-für-ein-finanzdienstleistungsunternehmen">Fallstudie 1: Automatisierte Betrugserkennung für ein Finanzdienstleistungsunternehmen&lt;/h2>
&lt;p>Finanzdienstleister verarbeiten täglich große Mengen sensibler Daten, die Aufdeckung von Betrug zu einer entscheidenden Komponente ihrer Tätigkeit machen. Leider, manuelle Verfahren zur Betrugserkennung sind zeitaufwändig, kostspielig, und sind oft nicht in der Lage, komplexe Betrugsfälle aufzudecken. An dieser Stelle kommt die Integration von maschinellem Lernen und privaten Cloud-Diensten ins Spiel.&lt;/p>
&lt;p>In dieser Fallstudie, werfen wir einen Blick auf ein Finanzdienstleistungsunternehmen, das mit seinen manuellen Betrugserkennungsverfahren Probleme hatte. Das Unternehmen wandte sich an DataFortress.Cloud UG nach einer Lösung, die eine genaue und effiziente Betrugserkennung ermöglicht, bei gleichzeitigem Schutz sensibler Kundeninformationen.&lt;/p>
&lt;p>DataFortress.cloud UG implementierte maschinelle Lernalgorithmen in einer sicheren privaten Cloud-Umgebung, den Prozess der Betrugserkennung zu automatisieren. Die Ergebnisse waren beeindruckend, Das Finanzdienstleistungsunternehmen konnte eine erhebliche Steigerung der Genauigkeit im Vergleich zu manuellen Prozessen verzeichnen.. Dies ermöglichte es dem Unternehmen, Betrugsversuche schneller und wirksamer aufzudecken., Verringerung des Risikos von finanziellen Verlusten und Schutz sensibler Kundeninformationen.&lt;/p>
&lt;p>Zusammenfassend, Die Integration von maschinellem Lernen und privaten Cloud-Diensten bietet Finanzdienstleistern ein leistungsfähiges Instrument zur Automatisierung der Betrugserkennung und zum Schutz sensibler Daten. Wenn Sie Probleme mit manuellen Betrugserkennungsprozessen haben, Kontakt zu DataFortress.cloud UG, um mehr über unsere Lösungen zu erfahren.&lt;/p>
&lt;h2 id="fallstudie-2-vorausschauende-wartung-für-ein-fertigungsunternehmen">Fallstudie 2: Vorausschauende Wartung für ein Fertigungsunternehmen&lt;/h2>
&lt;p>In der verarbeitenden Industrie, Ausfallzeiten können kostspielig sein und sich auf das Endergebnis auswirken. Traditionelle Wartungsprozesse sind reaktiv, was bedeutet, dass die Geräte erst gewartet werden, wenn sie ausgefallen sind. Dies führt zu unerwarteten Ausfallzeiten, erhöhte Wartungskosten, und verringerte Produktivität.&lt;/p>
&lt;p>Einstieg in die vorausschauende Wartung, ein proaktiver Ansatz, bei dem Algorithmen des maschinellen Lernens eingesetzt werden, um vorherzusagen, wann Geräte ausfallen werden, und die Wartung entsprechend zu planen. In dieser Fallstudie, werfen wir einen Blick auf ein Fertigungsunternehmen, das mit ineffizienten Wartungsprozessen und Ausfallzeiten zu kämpfen hatte.&lt;/p>
&lt;p>Das Produktionsunternehmen arbeitet mit DataFortress zusammen.cloud UG zur Umsetzung der vorausschauenden Wartung in einer sicheren privaten Cloud-Umgebung. DataFortress.cloud UG nutzte Algorithmen des maschinellen Lernens, um Gerätedaten zu analysieren und vorherzusagen, wann eine Wartung erforderlich sein würde. Dies ermöglichte es dem Unternehmen, Wartungsarbeiten proaktiv zu planen., Verringerung der Ausfallzeiten und Verbesserung der Effizienz.&lt;/p>
&lt;p>Die Ergebnisse waren bemerkenswert, Das Fertigungsunternehmen konnte die Ausfallzeiten erheblich reduzieren und die Produktivität steigern.. Darüber hinaus, das Unternehmen konnte seine Wartungsprozesse optimieren und die Kosten senken, was zu einer verbesserten Rentabilität führt.&lt;/p>
&lt;p>Zusammenfassend, Vorausschauende Instandhaltung ist ein entscheidender Faktor für die Fertigungsindustrie. Durch den Einsatz von maschinellem Lernen und privaten Cloud-Diensten, Unternehmen können die Wartung proaktiv planen, Verringerung der Ausfallzeiten und Verbesserung der Effizienz. Wenn Sie Probleme mit reaktiven Wartungsprozessen haben, Kontakt zu DataFortress.cloud UG, um mehr über unsere Lösungen zu erfahren.&lt;/p>
&lt;h2 id="fallstudie-3-kundensegmentierung-und-personalisierung-für-ein-einzelhandelsunternehmen">Fallstudie 3: Kundensegmentierung und Personalisierung für ein Einzelhandelsunternehmen&lt;/h2>
&lt;p>In der wettbewerbsorientierten Einzelhandelslandschaft von heute, ein personalisiertes Einkaufserlebnis ist der Schlüssel zur Gewinnung und Bindung von Kunden. Kundensegmentierung, der Prozess der Einteilung von Kunden in Gruppen auf der Grundlage gemeinsamer Merkmale, ist ein wesentlicher Bestandteil der Personalisierung. Die manuelle Segmentierung von Kunden kann jedoch zeitaufwändig sein und durch menschliche Voreingenommenheit eingeschränkt werden..&lt;/p>
&lt;p>Hier kommen das maschinelle Lernen und private Cloud-Dienste ins Spiel. In dieser Fallstudie, werfen wir einen Blick auf ein Einzelhandelsunternehmen, das Schwierigkeiten hatte, seinen Kunden personalisierte Erlebnisse zu bieten. Das Unternehmen wandte sich an DataFortress.Cloud UG für eine Lösung, die Kunden genau segmentieren und personalisierte Erfahrungen in einer sicheren Umgebung bieten kann.&lt;/p>
&lt;p>DataFortress.cloud UG implementierte Algorithmen für maschinelles Lernen in einer privaten Cloud-Umgebung, um Kundendaten zu analysieren und Kunden anhand gemeinsamer Merkmale in Gruppen einzuteilen. Dies ermöglichte dem Einzelhandelsunternehmen, seinen Kunden personalisierte Erfahrungen zu bieten., einschließlich maßgeschneiderter Produktempfehlungen und gezielter Marketingkampagnen.&lt;/p>
&lt;p>Die Ergebnisse waren beeindruckend, Das Einzelhandelsunternehmen verzeichnete einen Anstieg der Kundenbindung und des Umsatzes.. Das Unternehmen konnte außerdem wertvolle Erkenntnisse über das Verhalten und die Vorlieben seiner Kunden gewinnen, was eine kontinuierliche Optimierung und Verbesserung der Personalisierungsbemühungen ermöglichte.&lt;/p>
&lt;p>Zusammenfassend, Kundensegmentierung und Personalisierung sind entscheidende Komponenten einer erfolgreichen Einzelhandelsstrategie. Durch den Einsatz von maschinellem Lernen und privaten Cloud-Diensten, Einzelhändler können Kunden genau segmentieren und personalisierte Erfahrungen anbieten, was zu mehr Engagement und Umsatz führt. Wenn Sie mit Herausforderungen bei der Kundensegmentierung und Personalisierung konfrontiert sind, Kontakt zu DataFortress.cloud UG, um mehr über unsere Lösungen zu erfahren.&lt;/p>
&lt;h2 id="schlussfolgerung">Schlussfolgerung&lt;/h2>
&lt;p>Zusammenfassend, maschinelles Lernen und private Cloud-Dienste sind leistungsstarke Werkzeuge für Unternehmen, die ihre Abläufe verbessern und sensible Daten schützen wollen. Die Fallstudien, die wir in diesem Artikel besprochen haben, zeigen nur einige der vielen Möglichkeiten auf, wie Unternehmen diese Technologien nutzen, um sich einen Wettbewerbsvorteil zu verschaffen.&lt;/p>
&lt;p>Von der automatischen Betrugserkennung in der Finanzdienstleistungsbranche über die vorausschauende Wartung in der Fertigungsindustrie bis hin zur Kundensegmentierung und Personalisierung im Einzelhandel, die Vorteile von maschinellem Lernen und privaten Cloud-Diensten liegen auf der Hand. Die Unternehmen können ihre Effizienz verbessern, Kosten senken, und personalisierte Erfahrungen für ihre Kunden zu bieten, und das alles unter Wahrung der Sicherheit sensibler Daten.&lt;/p>
&lt;p>Bei DataFortress.Wolke UG, Wir unterstützen Unternehmen dabei, die Leistung von maschinellem Lernen und privaten Cloud-Services zu nutzen, um ihre Ziele zu erreichen.. Ob Sie mit Herausforderungen bei der Betrugserkennung konfrontiert sind, Wartungsprozesse, oder Kundensegmentierung und Personalisierung, wir haben das Fachwissen und die Erfahrung, um zu helfen. Kontaktieren Sie uns noch heute, um mehr über unsere Lösungen zu erfahren und wie wir Ihrem Unternehmen zum Erfolg verhelfen können..&lt;/p></description></item><item><title>Erschließung des Potenzials des maschinellen Lernens mit privaten Cloud-Diensten: Fallstudien aus der Praxis</title><link>https://datafortress.cloud/de/blog/fallstudie-real-world-anwendungen-private-cloud/</link><pubDate>Wed, 08 Feb 2023 07:10:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/fallstudie-real-world-anwendungen-private-cloud/</guid><description>
&lt;h1 id="erschließung-des-potenzials-des-maschinellen-lernens-mit-privaten-cloud-diensten-fallstudien-aus-der-praxis">Erschließung des Potenzials des maschinellen Lernens mit privaten Cloud-Diensten: Fallstudien aus der Praxis&lt;/h1>
&lt;p>Willkommen in der Welt des datengesteuerten Geschäftserfolgs! In der heutigen schnelllebigen und sich ständig verändernden Geschäftswelt suchen Unternehmen ständig nach neuen Möglichkeiten, ihre Abläufe zu verbessern und der Konkurrenz einen Schritt voraus zu sein. Maschinelles Lernen und private Cloud-Services haben sich als bahnbrechend erwiesen und bieten Unternehmen die Tools, die sie benötigen, um das volle Potenzial ihrer Daten auszuschöpfen. In diesem Artikel werfen wir einen Blick auf Beispiele aus der Praxis von Unternehmen, die sich diese Spitzentechnologien zunutze gemacht haben, um ihr Wachstum voranzutreiben, ihre Abläufe zu optimieren und sensible Daten zu schützen. Schnallen Sie sich also an und machen Sie sich bereit, die vielen Vorteile von maschinellem Lernen und privaten Cloud-Diensten zu entdecken!&lt;/p>
&lt;h2 id="fallstudie-1-automatisierte-betrugserkennung-für-ein-finanzdienstleistungsunternehmen">Fallstudie 1: Automatisierte Betrugserkennung für ein Finanzdienstleistungsunternehmen&lt;/h2>
&lt;p>Finanzdienstleister verarbeiten täglich riesige Mengen an sensiblen Daten, was die Betrugserkennung zu einem kritischen Bestandteil ihres Geschäftsbetriebs macht. Leider sind manuelle Betrugserkennungsprozesse zeitaufwändig, kostspielig und reichen oft nicht aus, um komplexe Betrugsversuche aufzudecken. An dieser Stelle kommt die Integration von maschinellem Lernen und privaten Cloud-Diensten ins Spiel.&lt;/p>
&lt;p>In dieser Fallstudie werfen wir einen Blick auf ein Finanzdienstleistungsunternehmen, das mit seinen manuellen Betrugserkennungsprozessen Probleme hatte. Das Unternehmen wandte sich an DataFortress.cloud UG, um eine Lösung zu finden, die eine genaue und effiziente Betrugserkennung ermöglicht und gleichzeitig sensible Kundendaten schützt.&lt;/p>
&lt;p>DataFortress.cloud UG implementierte maschinelle Lernalgorithmen innerhalb einer sicheren privaten Cloud-Umgebung, um den Betrugserkennungsprozess zu automatisieren. Die Ergebnisse waren beeindruckend: Das Finanzdienstleistungsunternehmen verzeichnete eine signifikante Steigerung der Genauigkeit im Vergleich zu manuellen Prozessen. Dadurch konnte das Unternehmen Betrugsversuche schneller und effektiver aufdecken, das Risiko finanzieller Verluste verringern und sensible Kundendaten schützen.&lt;/p>
&lt;p>Zusammenfassend lässt sich sagen, dass die Integration von maschinellem Lernen und privaten Cloud-Diensten Finanzdienstleistern ein leistungsstarkes Tool zur Automatisierung der Betrugserkennung und zum Schutz sensibler Daten bietet. Wenn Sie mit manuellen Betrugserkennungsprozessen konfrontiert sind, kontaktieren Sie DataFortress.cloud UG, um mehr über unsere Lösungen zu erfahren.&lt;/p>
&lt;h2 id="fallstudie-2-vorausschauende-wartung-für-ein-fertigungsunternehmen">Fallstudie 2: Vorausschauende Wartung für ein Fertigungsunternehmen&lt;/h2>
&lt;p>In der Fertigungsindustrie können Ausfallzeiten kostspielig sein und sich auf das Endergebnis auswirken. Herkömmliche Wartungsprozesse sind reaktiv, was bedeutet, dass die Anlagen erst gewartet werden, wenn sie ausgefallen sind. Dies führt zu unerwarteten Ausfallzeiten, höheren Wartungskosten und geringerer Produktivität.&lt;/p>
&lt;p>Hier kommt die vorausschauende Wartung ins Spiel, ein proaktiver Ansatz, bei dem Algorithmen des maschinellen Lernens eingesetzt werden, um vorherzusagen, wann Geräte ausfallen werden, und die Wartung entsprechend zu planen. In dieser Fallstudie werfen wir einen Blick auf ein Fertigungsunternehmen, das mit ineffizienten Wartungsprozessen und Ausfallzeiten zu kämpfen hatte.&lt;/p>
&lt;p>Das Unternehmen ging eine Partnerschaft mit DataFortress.cloud UG ein, um die vorausschauende Wartung in einer sicheren privaten Cloud-Umgebung zu implementieren. DataFortress.cloud UG nutzte Algorithmen des maschinellen Lernens, um Anlagendaten zu analysieren und vorherzusagen, wann eine Wartung erforderlich sein würde. Dies ermöglichte es dem Unternehmen, die Wartung proaktiv zu planen, Ausfallzeiten zu reduzieren und die Effizienz zu verbessern.&lt;/p>
&lt;p>Die Ergebnisse waren bemerkenswert: Das Fertigungsunternehmen konnte die Ausfallzeiten erheblich reduzieren und die Produktivität steigern. Darüber hinaus konnte das Unternehmen seine Wartungsprozesse optimieren und die Kosten senken, was zu einer verbesserten Rentabilität führte.&lt;/p>
&lt;p>Zusammenfassend lässt sich sagen, dass die vorausschauende Wartung für die Fertigungsindustrie einen entscheidenden Wandel darstellt. Durch den Einsatz von maschinellem Lernen und privaten Cloud-Diensten können Unternehmen die Wartung proaktiv planen, Ausfallzeiten reduzieren und die Effizienz verbessern. Wenn Sie mit reaktiven Wartungsprozessen konfrontiert sind, kontaktieren Sie DataFortress.cloud UG, um mehr über unsere Lösungen zu erfahren.&lt;/p>
&lt;h2 id="fallstudie-3-kundensegmentierung-und-personalisierung-für-ein-einzelhandelsunternehmen">Fallstudie 3: Kundensegmentierung und Personalisierung für ein Einzelhandelsunternehmen&lt;/h2>
&lt;p>In der heutigen wettbewerbsintensiven Einzelhandelslandschaft ist ein personalisiertes Einkaufserlebnis der Schlüssel zur Gewinnung und Bindung von Kunden. Die Kundensegmentierung, d. h. die Einteilung von Kunden in Gruppen auf der Grundlage gemeinsamer Merkmale, ist ein wesentlicher Bestandteil der Personalisierung. Die manuelle Segmentierung von Kunden kann jedoch zeitaufwändig sein und durch menschliche Voreingenommenheit eingeschränkt werden.&lt;/p>
&lt;p>An dieser Stelle kommen maschinelles Lernen und private Cloud-Services ins Spiel. In dieser Fallstudie werfen wir einen Blick auf ein Einzelhandelsunternehmen, das Schwierigkeiten hatte, personalisierte Erfahrungen für seine Kunden zu bieten. Das Unternehmen wandte sich an DataFortress.cloud UG, um eine Lösung zu finden, die Kunden genau segmentieren und personalisierte Erfahrungen in einer sicheren Umgebung bieten konnte.&lt;/p>
&lt;p>DataFortress.cloud UG implementierte Algorithmen des maschinellen Lernens in einer privaten Cloud-Umgebung, um Kundendaten zu analysieren und Kunden anhand gemeinsamer Merkmale in Gruppen einzuteilen. Dies ermöglichte es dem Einzelhandelsunternehmen, seinen Kunden personalisierte Erfahrungen zu bieten, einschließlich maßgeschneiderter Produktempfehlungen und gezielter Marketingkampagnen.&lt;/p>
&lt;p>Die Ergebnisse waren beeindruckend: Das Einzelhandelsunternehmen verzeichnete eine Steigerung der Kundenbindung und des Umsatzes. Darüber hinaus konnte das Unternehmen wertvolle Erkenntnisse über das Kundenverhalten und die Präferenzen seiner Kunden gewinnen, was eine kontinuierliche Optimierung und Verbesserung der Personalisierungsmaßnahmen ermöglichte.&lt;/p>
&lt;p>Zusammenfassend lässt sich sagen, dass Kundensegmentierung und Personalisierung entscheidende Komponenten einer erfolgreichen Einzelhandelsstrategie sind. Durch den Einsatz von maschinellem Lernen und privaten Cloud-Diensten können Einzelhändler Kunden genau segmentieren und personalisierte Erlebnisse bieten, was zu mehr Engagement und Umsatz führt. Wenn Sie mit Herausforderungen bei der Kundensegmentierung und Personalisierung konfrontiert sind, kontaktieren Sie DataFortress.cloud UG, um mehr über unsere Lösungen zu erfahren.&lt;/p>
&lt;h2 id="fazit">Fazit&lt;/h2>
&lt;p>Zusammenfassend lässt sich sagen, dass maschinelles Lernen und private Cloud-Dienste leistungsstarke Werkzeuge für Unternehmen sind, die ihre Abläufe verbessern und sensible Daten schützen möchten. Die Fallstudien, die wir in diesem Artikel besprochen haben, zeigen nur einige der vielen Möglichkeiten auf, wie Unternehmen diese Technologien nutzen, um sich einen Wettbewerbsvorteil zu verschaffen.&lt;/p>
&lt;p>Von der automatisierten Betrugserkennung in der Finanzdienstleistungsbranche über die vorausschauende Wartung in der Fertigungsindustrie bis hin zur Kundensegmentierung und Personalisierung im Einzelhandel liegen die Vorteile des maschinellen Lernens und der Private Cloud Services auf der Hand. Unternehmen sind in der Lage, ihre Effizienz zu steigern, Kosten zu senken und ihren Kunden personalisierte Erlebnisse zu bieten - und das alles unter Wahrung der Sicherheit sensibler Daten.&lt;/p>
&lt;p>Die DataFortress.cloud UG unterstützt Unternehmen dabei, die Möglichkeiten des maschinellen Lernens und privater Cloud-Services zu nutzen, um ihre Ziele zu erreichen. Ganz gleich, ob Sie vor Herausforderungen bei der Betrugserkennung, bei Wartungsprozessen oder bei der Kundensegmentierung und -personalisierung stehen, wir haben das Know-how und die Erfahrung, um Ihnen zu helfen. Kontaktieren Sie uns noch heute, um mehr über unsere Lösungen zu erfahren und wie wir Ihrem Unternehmen zum Erfolg verhelfen können.&lt;/p></description></item><item><title>Techniken der Datenwissenschaft: Wie man mit maschinellem Lernen anfängt</title><link>https://datafortress.cloud/de/blog/datenwissenschaftliche-techniken-wie-man-mit-maschinenlernen-einsteigt/</link><pubDate>Thu, 02 Feb 2023 04:32:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/datenwissenschaftliche-techniken-wie-man-mit-maschinenlernen-einsteigt/</guid><description>
&lt;h1 id="techniken-der-datenwissenschaft-wie-fängt-man-mit-maschinellem-lernen-an">Techniken der Datenwissenschaft: Wie fängt man mit maschinellem Lernen an?&lt;/h1>
&lt;p>In der datengesteuerten Welt von heute ist die Beherrschung von Data-Science-Techniken wie maschinelles Lernen wichtiger denn je. Von der Verbesserung der Unternehmensleistung bis hin zur Förderung der wissenschaftlichen Forschung - die Anwendungsmöglichkeiten des maschinellen Lernens sind praktisch grenzenlos. Bei der großen Auswahl an Tools und Techniken kann es jedoch schwierig sein zu wissen, wo man anfangen soll. In diesem Artikel finden Sie einen umfassenden Leitfaden für den Einstieg in das maschinelle Lernen, einschließlich praktischer Ratschläge für die Auswahl der richtigen Tools, die Erstellung effektiver Modelle und die Erschließung des vollen Potenzials Ihrer Daten. Egal, ob Sie ein erfahrener Datenwissenschaftler sind oder gerade erst anfangen, dieser Leitfaden enthält alles, was Sie brauchen, um Ihre Fähigkeiten im maschinellen Lernen auf die nächste Stufe zu bringen.&lt;/p>
&lt;h2 id="unlock-the-power-of-machine-learning-ein-einsteigerhandbuch-für-data-science-techniken">Unlock the Power of Machine Learning: Ein Einsteigerhandbuch für Data Science-Techniken&amp;quot;&lt;/h2>
&lt;p>Sind Sie neugierig, wie Sie die Möglichkeiten des maschinellen Lernens und der Data-Science-Techniken nutzen können? Wenn ja, dann sind Sie nicht allein. In der heutigen datengesteuerten Welt ist es wichtiger denn je, zu verstehen, wie man sich die Leistungsfähigkeit dieser Technologien zunutze machen kann.&lt;/p>
&lt;p>Im Kern geht es beim maschinellen Lernen darum, Algorithmen zu trainieren, um Muster in Daten zu erkennen und auf der Grundlage dieser Muster Vorhersagen zu treffen. Von der Identifizierung potenzieller Kunden bis hin zur Aufdeckung von Betrug wird das maschinelle Lernen zu einem unverzichtbaren Werkzeug für Unternehmen jeder Größe. Datenwissenschaftliche Techniken gehen Hand in Hand mit maschinellem Lernen und bilden den Rahmen für das Verständnis, wie Daten genutzt werden können, um Entscheidungen zu treffen, die das Unternehmenswachstum fördern.&lt;/p>
&lt;p>Wenn Sie diese Tools beherrschen, können Sie Einblicke in Ihre Daten gewinnen, die auf den ersten Blick vielleicht nicht sichtbar sind. Sie werden in der Lage sein, Modelle zu erstellen, mit denen Sie zukünftige Trends vorhersagen und fundierte Geschäftsentscheidungen treffen können. Und, was vielleicht am wichtigsten ist, Sie können der Konkurrenz einen Schritt voraus sein, indem Sie verstehen, wie Sie Daten auf neue und innovative Weise nutzen können.&lt;/p>
&lt;p>Natürlich kann der Einstieg in das maschinelle Lernen und die Datenwissenschaft einschüchternd sein, vor allem, wenn Sie neu auf diesem Gebiet sind. Aber mit der richtigen Anleitung und den richtigen Ressourcen kann jeder lernen, wie man diese Tools einsetzt, um das Potenzial seiner Daten voll auszuschöpfen.&lt;/p>
&lt;h2 id="master-the-basics-of-machine-learning-verstehen-der-grundlagen-der-datenwissenschaft">Master the Basics of Machine Learning: Verstehen der Grundlagen der Datenwissenschaft&lt;/h2>
&lt;p>Maschinelles Lernen ist ein leistungsfähiges Werkzeug, das Ihnen helfen kann, Muster und Erkenntnisse in Ihren Daten zu entdecken, die vielleicht nicht sofort ersichtlich sind. Um das Beste aus dieser Technologie herauszuholen, ist es jedoch wichtig, die wichtigsten Konzepte zu verstehen, die ihr zugrunde liegen.&lt;/p>
&lt;p>Im Kern geht es beim maschinellen Lernen darum, Algorithmen zu trainieren, um Muster in Ihren Daten zu erkennen und diese Muster zu nutzen, um Vorhersagen über zukünftige Ereignisse zu treffen. Diese Algorithmen können in einer Vielzahl von realen Szenarien eingesetzt werden, von der Vorhersage, welche Kunden am ehesten Ihr Produkt kaufen werden, bis hin zur Erkennung von Betrug bei Finanztransaktionen.&lt;/p>
&lt;p>Eines der Schlüsselkonzepte des maschinellen Lernens ist die Idee eines Modells. Ein Modell ist eine mathematische Darstellung der Beziehungen zwischen verschiedenen Variablen in Ihren Daten. Wenn Sie beispielsweise versuchen, den Preis eines Hauses auf der Grundlage seiner Größe und Lage vorherzusagen, könnten Sie ein Modell erstellen, das diese beiden Variablen berücksichtigt.&lt;/p>
&lt;p>Ein weiteres wichtiges Konzept ist die Idee des Trainings und der Tests. Um ein effektives Modell für maschinelles Lernen zu erstellen, müssen Sie es anhand eines großen Datensatzes mit Beispielen trainieren. Dieser Trainingsprozess hilft dem Algorithmus, Muster in den Daten zu erkennen, die er zur Erstellung von Vorhersagen verwenden kann. Sobald das Modell trainiert wurde, müssen Sie es an einem separaten Datensatz testen, um sicherzustellen, dass es genau ist.&lt;/p>
&lt;p>Natürlich gibt es noch viele andere Konzepte, die für das Verständnis des maschinellen Lernens wichtig sind, von den verschiedenen Arten von Algorithmen bis hin zur Bedeutung der Merkmalsauswahl. Aber wenn Sie die Grundlagen beherrschen, sind Sie auf dem besten Weg, effektive maschinelle Lernmodelle zu erstellen, die Ihnen helfen, bessere Geschäftsentscheidungen zu treffen.&lt;/p>
&lt;blockquote>
&lt;p>Fragen? Lassen Sie sich von unserem Team erfahrener &lt;a href="https://datafortress.cloud/de/contact">Machine Learning Engineers&lt;/a> helfen.&lt;/p>
&lt;/blockquote>
&lt;h2 id="fortgeschrittene-tools-und-techniken-für-maschinelles-lernen-wie-sie-sie-auf-ihre-daten-anwenden">Fortgeschrittene Tools und Techniken für maschinelles Lernen: Wie Sie sie auf Ihre Daten anwenden&lt;/h2>
&lt;p>Wenn Sie bereits mit den Grundlagen des maschinellen Lernens vertraut sind, fragen Sie sich vielleicht, was der nächste Schritt ist. Zum Glück gibt es viele fortgeschrittene Tools und Techniken, die Ihnen helfen können, Ihre Fähigkeiten beim maschinellen Lernen auf die nächste Stufe zu bringen.&lt;/p>
&lt;p>Eines der neuesten Tools für maschinelles Lernen ist AutoML, oder automatisiertes maschinelles Lernen. AutoML ist eine Reihe von Tools und Techniken, die viele der Aufgaben automatisieren, die bei der Erstellung effektiver Modelle für maschinelles Lernen anfallen. Dies kann eine enorme Zeitersparnis bedeuten, insbesondere wenn Sie mit großen Datensätzen oder komplexen Modellen arbeiten.&lt;/p>
&lt;p>Eine weitere fortschrittliche Technik für maschinelles Lernen ist Deep Learning. Deep Learning ist eine Art des maschinellen Lernens, bei dem künstliche neuronale Netze zur Analyse von Daten eingesetzt werden. Dieser Ansatz ist besonders effektiv für Aufgaben wie Bilderkennung und Verarbeitung natürlicher Sprache.&lt;/p>
&lt;p>Neben diesen Werkzeugen und Techniken gibt es noch viele andere fortgeschrittene Konzepte, die man bei der Arbeit mit maschinellem Lernen verstehen muss. Wenn Sie beispielsweise wissen, wie man Modellgruppen verwendet, können Sie genauere Vorhersagen treffen, und wenn Sie menschliches Fachwissen in Ihre maschinellen Lernmodelle einbeziehen, können Sie Faktoren berücksichtigen, die in Ihren Daten möglicherweise nicht sichtbar sind.&lt;/p>
&lt;p>Natürlich kann die Anwendung dieser Tools und Techniken auf Ihre eigenen Daten eine Herausforderung sein, vor allem, wenn Sie nicht mit den neuesten Best Practices vertraut sind. Aber mit der richtigen Anleitung und den richtigen Ressourcen kann jeder lernen, wie man diese fortschrittlichen Tools und Techniken einsetzt, um effektivere Modelle für maschinelles Lernen zu erstellen.&lt;/p>
&lt;h2 id="beginnen-sie-noch-heute-mit-maschinellem-lernen-ein-umfassender-leitfaden-für-datenwissenschaftler">Beginnen Sie noch heute mit maschinellem Lernen: Ein umfassender Leitfaden für Datenwissenschaftler&lt;/h2>
&lt;p>Wenn Sie bereit sind, in die Welt des maschinellen Lernens einzutauchen, ist es eine gute Nachricht, dass es viele Ressourcen gibt, die Ihnen den Einstieg erleichtern. Bei der großen Auswahl an Tools und Techniken kann es jedoch schwierig sein zu wissen, wo man anfangen soll.&lt;/p>
&lt;p>Der erste Schritt beim Einstieg in das maschinelle Lernen besteht in der Auswahl der richtigen Tools für diese Aufgabe. Es gibt viele Open-Source- und kommerzielle Tools für maschinelles Lernen, die alle ihre eigenen Stärken und Schwächen haben. Zu den beliebtesten Tools gehören Python-basierte Bibliotheken wie scikit-learn und TensorFlow sowie Cloud-basierte Dienste wie Google Cloud AI und Amazon SageMaker.&lt;/p>
&lt;p>Wenn Sie Ihre Tools ausgewählt haben, müssen Sie als Nächstes mit Ihren Daten arbeiten. Effektive Modelle für maschinelles Lernen erfordern qualitativ hochwertige Daten, die sauber, gut strukturiert und für die jeweilige Aufgabe relevant sind. Dazu gehört häufig ein Prozess der Datenbereinigung und -vorverarbeitung, bei dem Sie doppelte oder irrelevante Daten entfernen und Ihre Daten so formatieren müssen, dass sie von Ihren Algorithmen für maschinelles Lernen problemlos analysiert werden können.&lt;/p>
&lt;p>Wenn Sie Ihre Daten in der Hand haben, können Sie im nächsten Schritt mit der Erstellung Ihrer maschinellen Lernmodelle beginnen. Dazu gehören die Auswahl der richtigen Algorithmen für Ihre Daten, die Abstimmung der Parameter Ihrer Modelle und die Bewertung ihrer Leistung anhand von Kennzahlen wie Genauigkeit, Präzision und Wiedererkennung.&lt;/p>
&lt;p>Bei der Erstellung effektiver maschineller Lernmodelle geht es jedoch nicht nur um die technischen Details. Es ist auch wichtig, sich kritisch mit dem breiteren Kontext Ihrer Daten und dem Problem, das Sie zu lösen versuchen, auseinanderzusetzen. Dazu gehört oft die Einbeziehung von Fachwissen in Ihre Modelle sowie die Berücksichtigung der ethischen und sozialen Auswirkungen Ihrer Arbeit.&lt;/p>
&lt;p>Bei DataFortress.cloud helfen wir Ihnen, mit maschinellem Lernen zu beginnen und Ihre Data-Science-Fähigkeiten auf die nächste Stufe zu heben. Unser Expertenteam verfügt über fundierte technische Kenntnisse in den Bereichen Kubernetes, Private Cloud, Data Engineering und Datenpipelines und steht Ihnen jederzeit mit Rat und Tat zur Seite, wenn es darum geht, das Beste aus Ihren Daten herauszuholen.&lt;/p>
&lt;p>Wenn Sie also bereit sind, mit dem maschinellen Lernen zu beginnen, zögern Sie nicht, uns unter &lt;a href="https://datafortress.cloud/contact">https://datafortress.cloud/contact&lt;/a> zu kontaktieren. Wir freuen uns darauf, Ihnen zu helfen, das volle Potenzial Ihrer Daten zu erschließen!&lt;/p></description></item><item><title>Howto: Einen automatisierten Machine-Learning Aktienhandels-Roboter mittels AWS Lambda serverlos betreiben</title><link>https://datafortress.cloud/de/blog/howto-einen-automatisierten-machine-learning-aktienhandels-roboter-mittels-aws-lambda-serverlos-betreiben/</link><pubDate>Mon, 23 May 2022 22:00:00 +0000</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/howto-einen-automatisierten-machine-learning-aktienhandels-roboter-mittels-aws-lambda-serverlos-betreiben/</guid><description>
&lt;p>In diesem Beitrag werde ich meinen Algorithmus für serverloses Investieren mit AWS Lambda, Facebook Prophet als ML-Modell und meiner benutzerdefinierten Lambda-Schicht vorstellen.&lt;/p>
&lt;p>Ich habe diesen Beitrag in die Abschnitte &amp;ldquo;Warum habe ich das gemacht&amp;rdquo; und &amp;ldquo;Technisches How To&amp;rdquo; unterteilt. Wenn Sie den &amp;ldquo;Warum&amp;rdquo;-Teil überspringen möchten, können Sie direkt zum technischen Teil springen.&lt;/p>
&lt;h2 id="warum-sollte-ich-ein-maschinelles-lernmodell-in-aws-lambda-einsetzen">Warum sollte ich ein maschinelles Lernmodell in AWS Lambda einsetzen?&lt;/h2>
&lt;ol>
&lt;li>&lt;strong>Die Zuverlässigkeit&lt;/strong>: Der Algorithmus wird unabhängig von anderen Systemen, Updates, &amp;hellip;&lt;/li>
&lt;li>&lt;strong>Leistungseffizienz&lt;/strong>: Ich kann mehrere Algorithmen auf einem (kleinen) System unabhängig voneinander ausführen.&lt;/li>
&lt;li>&lt;strong>Kosteneinsparungen&lt;/strong>: AWS ermöglicht &lt;a href="https://aws.amazon.com/lambda/?did=ft_card&amp;amp;trk=ft_card">3,2 Millionen Rechensekunden pro Monat&lt;/a>, so dass ich im Grunde alle meine Algorithmen kostenlos ausführen kann.&lt;/li>
&lt;/ol>
&lt;p>Ich habe nach einer Möglichkeit gesucht, zunächst sicherzustellen, dass mein Investitions-Bot sicher ausgeführt wird, denn eine fehlgeschlagene Ausführung kann viel Geld kosten, wenn ein Handel nicht umgehend abgebrochen wird, wenn er in die falsche Richtung geht. Außerdem wollte ich vermeiden, meinen Computer die ganze Zeit laufen zu lassen, und sicherstellen, dass mehrere Algorithmen nebeneinander laufen können, ohne ihre Ausführung zu beeinflussen oder zu verzögern.&lt;/p>
&lt;p>Darüber hinaus ist es ein schöner Gedanke, einen investierenden Algorithmus laufen zu lassen, ohne sich um Betriebssystem-Updates, Hardware-Ausfälle und Stromausfälle usw. zu kümmern, was der allgemeine Vorteil serverloser Technologien ist.&lt;/p>
&lt;p>Im Moment kann ich mehrere Variationen des Algorithmus laufen lassen, um Änderungen des Algorithmus zu testen, und kann sicher sein, dass er läuft. Noch eine nette Sache? AWS bietet etwa 1 Million kostenlose Lambda-Aufrufe an, so dass ich die gesamte Architektur in ihrem Free Tier-Kontingent laufen lassen kann.&lt;/p>
&lt;h2 id="der-investitionsalgorithmus">Der Investitionsalgorithmus&lt;/h2>
&lt;p>Ich werde den Algorithmus in einem anderen Beitrag auf meiner Website &lt;a href="">www.datafortress.cloud&lt;/a> ausführlicher erläutern, aber mein typischer Aufbau eines Investitionsalgorithmus besteht aus:&lt;/p>
&lt;ol>
&lt;li>Testen des Algorithmus mit &lt;a href="https://www.backtrader.com/">Backtrader&lt;/a>, einem Open-Source-Backtesting-Framework, das in Python geschrieben wurde&lt;/li>
&lt;li>Konvertieren des erfolgreichen Algorithmus in eine einzelne Python-Datei, die eine run()-Methode enthält, die zurückgibt, welche Investitionen getätigt wurden&lt;/li>
&lt;li>Übertragen der Python-Datei zu AWS Lambda, wo ich die run()-Funktion mit der lambda_handler-Funktion von AWS Lambda aufrufe&lt;/li>
&lt;/ol>
&lt;p>In diesem Beispielalgorithmus treffe ich Investitionsentscheidungen in Abhängigkeit davon, ob der aktuelle Kurs über oder unter der Trendlinie liegt, die vom &lt;a href="https://facebook.github.io/prophet/">Prophetenmodell von Facebook&lt;/a> vorhergesagt wird. Ich habe Ideen von &lt;a href="http://seangtkelley.me/blog/2018/08/15/algo-trading-pt2">Sean Kelley übernommen&lt;/a>, der ein Backtrader-Setup geschrieben hat, wie man Prophet mit Backtrader einsetzen kann.&lt;/p>
&lt;p>Mein Aktienuniversum in diesem Setup wird berechnet, indem ich die 20 besten Aktien aus dem SPY500-Index auswähle, der in den vergangenen X Zeitschritten die höchste Rendite erzielte.&lt;/p>
&lt;p>Die Datenquelle ist Yahoo Finance, unter Verwendung der kostenlosen &lt;a href="">Yfinance-Bibliothek&lt;/a>, und als mein bevorzugter algorithmischer Broker habe ich &lt;a href="https://alpaca.markets/">Alpaca.markets&lt;/a> gewählt.&lt;/p>
&lt;p>In meinem Setup wird der Algorithmus einmal pro Tag um 15 Uhr oder alle 15 Minuten während der Handelszeiten ausgeführt.&lt;/p>
&lt;h2 id="die-probleme-beim-einsatz-des-facebook-propheten-bei-aws-lambda">Die Probleme beim Einsatz des Facebook-Propheten bei AWS Lambda&lt;/h2>
&lt;p>AWS Lambda wird mit einigen Python-Bibliotheken vorinstalliert geliefert, aber wie viele von Ihnen vielleicht wissen, ist dies standardmäßig recht begrenzt (was für Lambda&amp;rsquo;s Versprechen angemessen ist). Dennoch erlaubt Lambda die Installation privater Pakete, was für kleinere Pakete recht einfach ist (siehe die&lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/python-package.html"> offizielle Dokumentation&lt;/a>), aber etwas komplizierter wird, wenn es sich um Pakete handelt, die größer als 250 Mb sind. Unglücklicherweise überschreitet das Prophetenmodell von Facebook diese Grenze, aber glücklicherweise hat &lt;a href="https://towardsdatascience.com/how-to-get-fbprophet-work-on-aws-lambda-c3a33a081aaf">Alexandr Matsenov dieses Problem gelöst&lt;/a>, indem er die Paketgröße reduziert hat, und &lt;a href="https://github.com/marcmetz/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda">Marc Metz hat sich um Kompilierungsprobleme gekümmert, damit es auf AWS Lambda läuft.&lt;/a>&lt;/p>
&lt;p>Nicht standardmäßige Bibliotheken können zu AWS Lambda hinzugefügt werden, indem man Layer verwendet, die alle benötigten Pakete enthalten. Wenn ein Layer importiert wird, können Sie die Pakete einfach in Ihrer Python-Funktion importieren, wie Sie es in Ihrem lokalen Setup tun würden.&lt;/p>
&lt;h1 id="die-technische-anleitung">Die technische Anleitung&lt;/h1>
&lt;p>Lassen Sie mich abschließend erklären, wie genau Sie dies erreichen können. Siehe dieses TLDR für die ungeduldigen Typen oder die detailliertere Version unten.&lt;/p>
&lt;p>&lt;strong>TLDR;&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>Sie benötigen ein Lambda-Layer, laden Sie meine (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">Download&lt;/a>) mit Prophet, yfinance, &amp;hellip; auf einen S3-Bucket (privater Zugang)&lt;/li>
&lt;li>Wählen Sie AWS Lambda, erstellen Sie eine Funktion, fügen Sie ein Layer hinzu und fügen Sie in Ihre S3-Objekt-URL ein&lt;/li>
&lt;li>Fügen Sie Ihre lambda_function.py in den Lambda-Editor ein (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">oder verwenden Sie meine&lt;/a>)&lt;/li>
&lt;li>Richten Sie Ihre Umgebungsvariablen ein (optional)&lt;/li>
&lt;li>Führen Sie es entweder manuell aus, indem Sie auf &amp;ldquo;Test&amp;rdquo; klicken, oder gehen Sie zu CloudWatch -&amp;gt; Regeln -&amp;gt; Regel erstellen und richten Sie &amp;ldquo;Ausführung planen&amp;rdquo; ein, um es in einem bestimmten Zeitintervall auszuführen&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Ausführliche Erläuterung:&lt;/strong>&lt;/p>
&lt;h2 id="1-erstellen-eines-benutzerdefinierten-layers-für-aws-lambda">1. Erstellen eines benutzerdefinierten Layers für AWS Lambda&lt;/h2>
&lt;p>Sie können entweder mein Lambda-Layer verwenden, die Facebook Prophet, NumPy, Pandas, Alpaka-Handels-API, yfinance (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda">GitHub&lt;/a>) enthält, oder Sie können Ihre eigene unter Verwendung der &lt;a href="https://medium.com/@marc.a.metz/docker-run-rm-it-v-pwd-var-task-lambci-lambda-build-python3-7-bash-c7d53f3b7eb2">von Marc gegebenen Erklärung zusammenstellen.&lt;/a>&lt;/p>
&lt;p>&lt;strong>Meine Lambda-Schicht verwenden&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>Laden Sie die Zip-Datei von meinem &lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">Github-Repo&lt;/a> herunter, die alle Pakete enthält (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/raw/master/python.zip">Link&lt;/a>)&lt;/li>
&lt;li>Da Sie Layer nur bis zu einer Größe von 50 Mb direkt auf Lambda hochladen können, müssen wir die Datei zunächst auf AWS S3 hochladen.&lt;/li>
&lt;li>Erstellen Sie einen Bucket und legen Sie die heruntergeladene Zip-Datei in diesen Eimer. Der Zugang kann privat bleiben und muss NICHT öffentlich sein! Kopieren Sie die URL in Ihre Datei (z.B. &lt;a href="https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip" title="https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip">https://BUCKETNAME.s3.REGION.amazonaws.com/python.zip&lt;/a>)&lt;/li>
&lt;li>Loggen Sie sich in AWS ein und gehen Sie zu Lambda -&amp;gt; Layers (&lt;a href="https://eu-central-1.console.aws.amazon.com/lambda/home?region=eu-central-1#/layers">EU central Link&lt;/a>)&lt;/li>
&lt;li>Klicken Sie auf &amp;ldquo;Layer erstellen&amp;rdquo;, geben Sie ihr einen passenden Namen und wählen Sie &amp;ldquo;Eine Datei von Amazon S3 hochladen&amp;rdquo;, und kopieren Sie den Code von Schritt 3 hinein. Wählen Sie als Runtimes Python 3.7. Klicken Sie auf &amp;ldquo;Erstellen&amp;rdquo;.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Kompilieren Sie Ihre eigenes Lambda-Layer&lt;/strong>&lt;/p>
&lt;p>Bitte folgen Sie den &lt;a href="https://medium.com/@marc.a.metz/docker-run-rm-it-v-pwd-var-task-lambci-lambda-build-python3-7-bash-c7d53f3b7eb2">Anweisungen von Marc&lt;/a>.&lt;/p>
&lt;h2 id="2-erstellen-einer-lambda-funktion">2. Erstellen einer Lambda Funktion&lt;/h2>
&lt;ol>
&lt;li>Öffnen Sie das Dashboard der Lambda-Funktion (&lt;a href="https://eu-central-1.console.aws.amazon.com/lambda/home?region=eu-central-1#/functions">EU central Link&lt;/a>) und klicken Sie auf &amp;ldquo;Funktion erstellen&amp;rdquo;.&lt;/li>
&lt;li>Lassen Sie das Kontrollkästchen &amp;ldquo;Von Grund auf neu&amp;rdquo; unverändert und geben Sie ihm einen passenden Namen.&lt;/li>
&lt;li>Wählen Sie in &amp;ldquo;Runtime&amp;rdquo; Python 3.7, lassen Sie den Rest unverändert und klicken Sie auf &amp;ldquo;Funktion erstellen&amp;rdquo;.&lt;/li>
&lt;li>In der Übersicht der Registerkarte &amp;ldquo;Designer&amp;rdquo; sehen Sie eine grafische Darstellung Ihrer Lambda-Funktion. Klicken Sie auf das Feld &amp;ldquo;Schichten&amp;rdquo; darunter und klicken Sie auf &amp;ldquo;Eine Schicht hinzufügen&amp;rdquo;. Wenn Sie den Layer korrekt eingerichtet haben, können Sie ihn im folgenden Dialog auswählen. Klicken Sie schliesslich auf &amp;ldquo;Hinzufügen&amp;rdquo;.&lt;/li>
&lt;li>In der Registerkarte &amp;ldquo;Designer&amp;rdquo; wählen Sie Ihre Lambda-Funktion aus. Wenn Sie nach unten scrollen, sehen Sie ein Standard-Python-Code-Snippet in einer Datei namens &amp;ldquo;lambda_function.py&amp;rdquo;. Wenn Sie Ihren Code genauso strukturiert haben wie meinen (&lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">Link&lt;/a>), können Sie Ihre Funktion mit der run()-Funktion ausführen. Wenn eine Lambda-Funktion aufgerufen wird, wird sie die lambda_handler(event, context)-Funktion ausführen, von der aus Sie z.B. die run()-Funktion aufrufen können. Natürlich können Sie alle Dateien und Funktionen umbenennen, aber der Einfachheit halber habe ich dieses Projekt so belassen, wie es ist.&lt;/li>
&lt;li>Fühlen Sie sich frei, &lt;a href="https://github.com/JustinGuese/How-To-Deploy-Facebook-Prophet-on-AWS-Lambda/blob/master/lambda_function.py">meine Funktion&lt;/a> einfach einzufügen und zu testen.&lt;/li>
&lt;li>Ein Klick auf &amp;ldquo;Test&amp;rdquo; sollte zu einer erfolgreichen Ausführung führen, andernfalls werden die Fehler im Dialog angezeigt.&lt;/li>
&lt;/ol>
&lt;h2 id="3-umgebungsvariabeln-in-aws-lambda-hinzufügen-und-nutzen">3. Umgebungsvariabeln in AWS Lambda hinzufügen und nutzen&lt;/h2>
&lt;p>Sie sollten Ihren Benutzer und Ihr Passwort niemals als Klartext in Ihrem Code hinterlassen, weshalb Sie immer Umgebungsvariablen verwenden sollten! Glücklicherweise verwendet auch Lambda diese, und sie können leicht mit dem Python-OS-Paket aufgerufen werden. In meinem Skript rufe ich z.B. die Benutzervariable mit os.environ[&amp;lsquo;ALPACAUSER&amp;rsquo;] auf. Die Umgebungsvariablen können im Hauptfunktionsbildschirm von Lambda eingerichtet werden, wenn Sie unter Ihrem Code-Editor nach unten scrollen.&lt;/p>
&lt;h2 id="4-aws-lambda-funktionen-in-einem-bestimmten-zeitintervall-auslösen">4. AWS Lambda Funktionen in einem bestimmten Zeitintervall auslösen&lt;/h2>
&lt;p>Das Konzept von Serverless und AWS Lambda basiert auf der Idee, dass eine Funktion ausgeführt wird, wenn ein Trigger-Ereignis eintritt. In meinem Setup wollte ich, dass die Funktion z.B. alle 15 Minuten während der Handelszeiten, Montag bis Freitag, aufgerufen wird. Glücklicherweise bietet AWS eine Möglichkeit, ein Ereignis auszulösen, ohne dass ein Server laufen muss, indem der CloudWatch-Dienst genutzt wird.&lt;/p>
&lt;ol>
&lt;li>Gehen Sie zu CloudWatch (&lt;a href="https://eu-central-1.console.aws.amazon.com/cloudwatch/home?region=eu-central-1">EU central Link&lt;/a>).&lt;/li>
&lt;li>Wählen Sie in der linken Leiste &amp;ldquo;Events&amp;rdquo; und &amp;ldquo;Rule&amp;rdquo;.&lt;/li>
&lt;li>Klicken Sie auf &amp;ldquo;Create Rule&amp;rdquo;, und wählen Sie &amp;ldquo;Schedule&amp;rdquo; anstelle von &amp;ldquo;Event pattern&amp;rdquo;. Hier können Sie den einfachen &amp;ldquo;Fixed-rate&amp;rdquo;-Dialog verwenden oder einen Cron-Ausdruck erstellen. Ich benutze &lt;a href="https://crontab.guru/" title="https://crontab.guru/">https://crontab.guru/&lt;/a> (kostenlos), um Cron-Ausdrücke zu erstellen. Mein Cron-Ausdruck für den oben erwähnten Anwendungsfall lautet &amp;ldquo;0/15 13-21 ? * MON-FRI *&amp;rdquo;.&lt;/li>
&lt;li>Wählen Sie in der rechten Tafel &amp;ldquo;Add Target&amp;rdquo; und wählen Sie Ihre Lambda-Funktion. Sie wird automatisch zu Lambda hinzugefügt.&lt;/li>
&lt;li>Klicken Sie schließlich auf &amp;ldquo;Details konfigurieren&amp;rdquo;, geben Sie ihr einen Namen und klicken Sie auf &amp;ldquo;Regel erstellen&amp;rdquo;.&lt;/li>
&lt;/ol>
&lt;h2 id="5-optional-log-analysen-errorsuche">5. (optional) Log Analysen, Errorsuche&lt;/h2>
&lt;p>Wenn Sie es bis zu diesem Teil geschafft haben, sollten Sie fertig sein! Wenn Sie aber überprüfen wollen, ob alles funktioniert hat, können Sie mit CloudWatch einen Blick auf die Ausgaben der Lambda-Funktionen werfen. Gehen Sie zu CloudWatch -&amp;gt; Logs -&amp;gt; Log-Gruppen (&lt;a href="https://eu-central-1.console.aws.amazon.com/cloudwatch/home?region=eu-central-1#logsV2:log-groups">EU central Link&lt;/a>) und wählen Sie Ihre Lambda-Funktion aus. In dieser Übersicht sollten Sie die Ausgaben Ihrer Funktionen sehen können.&lt;/p>
&lt;p>Wenn Ihnen dieser Beitrag gefallen hat, hinterlassen Sie einen Kommentar oder schauen Sie sich andere Beiträge an, um mich weiterhin zum Schreiben zu motivieren 😊.&lt;/p></description></item><item><title>Gesichtserkennung mittels MTCNN</title><link>https://datafortress.cloud/de/blog/face-detection-using-mtcnn/</link><pubDate>Sun, 08 May 2022 07:10:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/face-detection-using-mtcnn/</guid><description>
&lt;h1 id="was-ist-mtcnn">Was ist MTCNN&lt;/h1>
&lt;!-- raw HTML omitted -->
&lt;p>MTCNN ist eine Python (pip)-Bibliothek, die von [Github-Benutzer ipacz] (&lt;a href="https://github.com/ipazc/mtcnn">https://github.com/ipazc/mtcnn&lt;/a>) geschrieben wurde und die [das Papier Zhang, Kaipeng et al. &amp;ldquo;Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks&amp;rdquo; implementiert. IEEE Signal Processing Letters 23.10 (2016): 1499-1503. Querverweis. Web](&lt;a href="https://arxiv.org/abs/1604.02878%5D(https://arxiv.org/abs/1604.02878%20%22https://arxiv.org/abs/1604.02878)">https://arxiv.org/abs/1604.02878%5D(https://arxiv.org/abs/1604.02878%20%22https://arxiv.org/abs/1604.02878)&lt;/a>.&lt;/p>
&lt;p>In diesem Papier schlagen sie einen tief kaskadierten Multi-Task-Rahmen vor, der verschiedene Merkmale von &amp;ldquo;Untermodellen&amp;rdquo; verwendet, um jeweils ihre korrelierenden Stärken zu verstärken.&lt;/p>
&lt;p>MTCNN ist auf einer CPU recht schnell, obwohl S3FD auf einer GPU immer noch schneller läuft - aber das ist ein Thema für einen anderen Beitrag.&lt;/p>
&lt;p>Dieser Beitrag verwendet Code aus den beiden folgenden Quellen, schauen Sie sich diese an, sie sind ebenfalls interessant:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/" title="https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/">https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution" title="https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution">https://www.kaggle.com/timesler/fast-mtcnn-detector-55-fps-at-full-resolution&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;h1 id="grundlegende-verwendung-von-mtcnn">Grundlegende Verwendung von MTCNN&lt;/h1>
&lt;!-- raw HTML omitted -->
&lt;p>Zögern Sie nicht, auf das gesamte Notebook zuzugreifen:&lt;/p>
&lt;p>&lt;a href="https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up" title="https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up">https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up&lt;/a>&lt;/p>
&lt;pre>&lt;code>git clone https://github.com/JustinGuese/mtcnn-face-extraction-eyes-mouth-nose-and-speeding-it-up
&lt;/code>&lt;/pre>
&lt;p>Glücklicherweise ist MTCNN als Pip-Paket erhältlich, was bedeutet, dass wir es leicht installieren können mit&lt;/p>
&lt;pre>&lt;code>pip install mtcnn
&lt;/code>&lt;/pre>
&lt;p>Wenn wir jetzt zu Python/Jupyter Notebook wechseln, können wir die Installation mit einem Import und einer schnellen Überprüfung überprüfen:&lt;/p>
&lt;pre>&lt;code>import mtcnn
# print version
print(mtcnn.__version__)
&lt;/code>&lt;/pre>
&lt;p>Danach sind wir bereit, das Testbild mit der Matplotlib [imread-Funktion] (&lt;a href="https://bit.ly/2vo3INw">https://bit.ly/2vo3INw&lt;/a>) auszuladen.&lt;/p>
&lt;pre>&lt;code>import matplotlib.pyplot as plt
# load image from file
filename = &amp;quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&amp;quot;
pixels = plt.imread(filename)
print(&amp;quot;Shape of image/array:&amp;quot;,pixels.shape)
imgplot = plt.imshow(pixels)
plt.show()
&lt;/code>&lt;/pre>
&lt;p>Nun wird Ihre Ausgabe in etwa so aussehen:&lt;/p>
&lt;pre>&lt;code>{'box': [1942, 716, 334, 415], 'Vertrauen': 0,999999997615814209, 'Schlüsselpunkte': {'linkes_Auge': (2053, 901), &amp;quot;rechtes_Auge&amp;quot;: (2205, 897), &amp;quot;Nase&amp;quot;: (2139, 976), &amp;quot;Mund_links&amp;quot;: (2139, 976), &amp;quot;Mund_links&amp;quot;: (2058, 1029), 'Mund_rechts': (2058, 1029), 'Mund_rechts': (2206, 1023)}}
{&amp;quot;Kiste&amp;quot;: [2084, 396, 37, 46], 'Vertrauen': 0,9999206066131592, 'Schlüsselpunkte': {'linkes_Auge': [2084, 396, 37, 46], 'Vertrauen': [2084, 396, 37, 46], 'Vertrauen': 0,99999206066131592, 'Schlüsselpunkte': [0,9999206066131592], 'Vertrauen (2094, 414), &amp;quot;rechtes_Auge&amp;quot;: (2094, 414), &amp;quot;rechtes_Auge&amp;quot;: (2112, 414), &amp;quot;Nase&amp;quot;: (2094, 414), &amp;quot;Nase&amp;quot;: (2102, 426), &amp;quot;Mund_links&amp;quot;: (2095, 432), &amp;quot;Mund_rechts&amp;quot;: (2112, 431)}}
{&amp;quot;Kiste&amp;quot;: [1980, 381, 44, 59], 'Vertrauen': 0,9998701810836792, 'Schlüsselpunkte': {'linkes_Auge': [1980, 381, 44, 59], 'Vertrauen': 0,9998701810836792, 'Schlüsselpunkte': [1980, 381, 44, 59]: (1997, 404), &amp;quot;rechtes_Auge&amp;quot;: (2019, 407), &amp;quot;Nase&amp;quot;: (1997, 404), &amp;quot;Nase&amp;quot;: (2010, 417), &amp;quot;Mund_links&amp;quot;: (2010, 417), &amp;quot;Mund_links&amp;quot;: (1995, 425), &amp;quot;Mund_rechts&amp;quot;: (1995, 425), &amp;quot;Mund_rechts&amp;quot;: (2015, 427)}}
{&amp;quot;Kiste&amp;quot;: [2039, 395, 39, 46], 'Vertrauen': 0,9993435740470886, 'Schlüsselpunkte': {'linkes_Auge': [2039, 395, 39, 46], 'Vertrauen': 0,9993435740470886, 'Vertrauen': 0,9993435740470886, 'Schlüsselpunkte': [2039, 395, 39, 46]: (2054, 409), &amp;quot;rechtes_Auge&amp;quot;: (2054, 409), &amp;quot;rechtes_Auge&amp;quot;: (2071, 415), &amp;quot;Nase&amp;quot;: (2054, 409), &amp;quot;Nase&amp;quot;: (2058, 422), &amp;quot;Mund_links&amp;quot;: (2048, 425), 'Mund_rechts': (2048, 425), 'Mund_rechts': (2065, 431)}}
&lt;/code>&lt;/pre>
&lt;p>Was sagt uns das? Vieles davon ist selbsterklärend, aber im Grunde liefert es Koordinaten oder die Pixelwerte eines Rechtecks, in dem der MTCNN-Algorithmus Gesichter erkannt hat. Der obige &amp;ldquo;Kasten&amp;rdquo;-Wert gibt die Position des gesamten Gesichts zurück, gefolgt von einem &amp;ldquo;Vertrauens&amp;rdquo;-Level.&lt;/p>
&lt;p>Wenn Sie fortgeschrittenere Extraktionen oder Algorithmen durchführen möchten, haben Sie auch Zugang zu anderen Landmarken des Gesichts, die als &amp;ldquo;Schlüsselpunkte&amp;rdquo; bezeichnet werden. Das MTCNN-Modell lokalisierte nämlich auch die Augen, den Mund und die Nase!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="zeichnen-eines-kastens-um-gesichter">Zeichnen eines Kastens um Gesichter&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;p>Um dies noch besser zu demonstrieren, zeichnen wir mit matplotlib einen Kasten um das Gesicht:&lt;/p>
&lt;pre>&lt;code># draw an image with detected objects
def draw_facebox(filename, result_list):
# load the image
data = plt.imread(filename)
# plot the image
plt.imshow(data)
# get the context for drawing boxes
ax = plt.gca()
# plot each box
for result in result_list:
# get coordinates
x, y, width, height = result['box']
# create the shape
rect = plt.Rectangle((x, y), width, height, fill=False, color='green')
# draw the box
ax.add_patch(rect)
# show the plot
plt.show()
# filename = 'test1.webp' # filename is defined above, otherwise uncomment
# load image from file
# pixels = plt.imread(filename) # defined above, otherwise uncomment
# detector is defined above, otherwise uncomment
#detector = mtcnn.MTCNN()
# detect faces in the image
faces = detector.detect_faces(pixels)
# display faces on the original image
draw_facebox(filename, faces)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://datafortress.cloud/images/index-1-150x150.webp" alt="">&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="darstellung-von-augen-mund-und-nase-um-gesichter">Darstellung von Augen, Mund und Nase um Gesichter&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;p>Werfen wir nun einen Blick auf die oben erwähnten &amp;ldquo;Schlüsselpunkte&amp;rdquo;, die das MTCNN-Modell zurückgebracht hat.&lt;/p>
&lt;p>Wir werden diese nun auch für die Darstellung von Nase, Mund und Augen verwenden.&lt;br>
Wir werden den folgenden Codeschnipsel zu unserem obigen Code hinzufügen:&lt;/p>
&lt;pre>&lt;code># draw the dots
for key, value in result['keypoints'].items():
# create and draw dot
dot = plt.Circle(value, radius=20, color='orange')
ax.add_patch(dot)
&lt;/code>&lt;/pre>
&lt;p>Mit dem vollständigen Code von oben, der wie folgt aussieht:&lt;/p>
&lt;pre>&lt;code># draw an image with detected objects
def draw_facebox(filename, result_list):
# load the image
data = plt.imread(filename)
# plot the image
plt.imshow(data)
# get the context for drawing boxes
ax = plt.gca()
# plot each box
for result in result_list:
# get coordinates
x, y, width, height = result['box']
# create the shape
rect = plt.Rectangle((x, y), width, height,fill=False, color='orange')
# draw the box
ax.add_patch(rect)
# draw the dots
for key, value in result['keypoints'].items():
# create and draw dot
dot = plt.Circle(value, radius=20, color='red')
ax.add_patch(dot)
# show the plot
plt.show()
# filename = 'test1.webp' # filename is defined above, otherwise uncomment
# load image from file
# pixels = plt.imread(filename) # defined above, otherwise uncomment
# detector is defined above, otherwise uncomment
#detector = mtcnn.MTCNN()
# detect faces in the image
faces = detector.detect_faces(pixels)
# display faces on the original image
draw_facebox(filename, faces)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://datafortress.cloud/images/index2-150x150.webp" alt="">&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="erweitertes-mtcnn-beschleunigen-sie-es-x100">Erweitertes MTCNN: Beschleunigen Sie es (\\~x100)!&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;p>Kommen wir nun zum interessanten Teil. Wenn Sie Millionen von Bildern verarbeiten wollen, müssen Sie MTCNN beschleunigen, sonst werden Sie entweder einschlafen oder Ihre CPU wird verbrennen, bevor sie fertig ist.&lt;/p>
&lt;p>Aber worüber genau reden wir hier? Wenn Sie den obigen Code ausführen, dauert es etwa eine Sekunde, d.h. wir werden etwa ein Bild pro Sekunde verarbeiten. Wenn Sie MTCNN auf einer GPU ausführen und die beschleunigte Version verwenden, werden etwa 60-100 Bilder pro Sekunde erreicht. Das ist eine Steigerung von bis zu &lt;strong>100 Mal&lt;/strong>!&lt;/p>
&lt;p>Wenn Sie z.B. alle Gesichter eines Films extrahieren wollen, wobei Sie 10 Gesichter pro Sekunde extrahieren (eine Sekunde des Films hat im Durchschnitt etwa 24 Bilder, also jedes zweite Bild), dann sind es 10 * 60 (Sekunden) * 120 (Minuten) = 72.000 Bilder.&lt;/p>
&lt;p>Das heißt, wenn die Verarbeitung eines Einzelbildes eine Sekunde dauert, dauert sie 72.000 * 1 (Sekunden) = 72.000s / 60s = 1.200m = &lt;strong>20 Stunden&lt;/strong>.&lt;/p>
&lt;p>Mit der Beschleunigungsversion von MTCNN wird diese Aufgabe 72.000 (Frames) / 100 (Frames/sec) = 720 Sekunden = &lt;strong>12 Minuten&lt;/strong> dauern!&lt;/p>
&lt;p>Um MTCNN auf einer GPU zu verwenden, müssen Sie CUDA, cudnn, pytorch usw. einrichten. &lt;a href="https://pytorch.org/get-started/locally/">Pytorch hat ein gutes Tutorial zu diesem Teil geschrieben&lt;/a>.&lt;/p>
&lt;p>Nach der Installation werden wir die notwendigen Importe wie folgt durchführen:&lt;/p>
&lt;pre>&lt;code>from facenet_pytorch import MTCNN
from PIL import Image
import torch
from imutils.video import FileVideoStream
import cv2
import time
import glob
from tqdm.notebook import tqdm
device = 'cuda' if torch.cuda.is_available() else 'cpu'
filenames = [&amp;quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&amp;quot;,&amp;quot;glediston-bastos-ZtmmR9D_2tA-unsplash.webp&amp;quot;]
&lt;/code>&lt;/pre>
&lt;p>Sehen Sie, wie wir das Gerät im obigen Code definiert haben. Sie können alles auch auf einer CPU laufen lassen, wenn Sie CUDA nicht einrichten wollen oder können.&lt;/p>
&lt;p>Als nächstes werden wir den Extraktor definieren:&lt;/p>
&lt;pre>&lt;code># define our extractor
fast_mtcnn = FastMTCNN(
stride=4,
resize=0.5,
margin=14,
factor=0.6,
keep_all=True,
device=device
)
&lt;/code>&lt;/pre>
&lt;p>In diesem Schnipsel geben wir einige Parameter weiter, wobei wir zum Beispiel nur die halbe Bildgröße verwenden, was einer der Haupteinflussfaktoren für die Beschleunigung ist.&lt;/p>
&lt;p>Und schließlich lassen wir das Skript zur Gesichtsextraktion laufen:&lt;/p>
&lt;pre>&lt;code>def run_detection(fast_mtcnn, filenames):
frames = []
frames_processed = 0
faces_detected = 0
batch_size = 60
start = time.time()
for filename in tqdm(filenames):
v_cap = FileVideoStream(filename).start()
v_len = int(v_cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))
for j in range(v_len):
frame = v_cap.read()
frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
frames.append(frame)
if len(frames) &amp;gt;= batch_size or j == v_len - 1:
faces = fast_mtcnn(frames)
frames_processed += len(frames)
faces_detected += len(faces)
frames = []
print(
f'Frames per second: {frames_processed / (time.time() - start):.3f},',
f'faces detected: {faces_detected}\r',
end=''
)
v_cap.stop()
run_detection(fast_mtcnn, filenames)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://datafortress.cloud/images/teslap100frames.webp" alt="">&lt;/p>
&lt;p>Das obige Bild zeigt die Ausgabe des Codes, der auf einem NVIDIA Tesla P100 läuft. Je nach Quellmaterial, Grafikprozessor und Prozessor kann die Leistung also besser oder schlechter ausfallen.&lt;/p>
&lt;p>&lt;a href="https://www.datafortress.cloud/de/contact/">Sie haben eine ähnliche Idee oder wir haben Ihr Interesse geweckt? Kontaktieren Sie uns jetzt für eine gratis 15-minütige Beratung!&lt;/a>&lt;/p></description></item><item><title>How To - Weg mit Ubuntu zugunsten von Arch Linux für eine Deep Learning-optimierte Arbeitsumgebung</title><link>https://datafortress.cloud/de/blog/anleitung-wie-bauche-ich-eine-arch-linux-machine-learning-workstation/</link><pubDate>Fri, 29 Apr 2022 07:10:46 +0200</pubDate><author>Justin Guese</author><guid>https://datafortress.cloud/de/blog/anleitung-wie-bauche-ich-eine-arch-linux-machine-learning-workstation/</guid><description>
&lt;h1 id="how-to---weg-mit-ubuntu-zugunsten-von-arch-linux-für-eine-machine-learning-optimierte-arbeitsumgebung">How To - Weg mit Ubuntu zugunsten von Arch Linux für eine Machine Learning-optimierte Arbeitsumgebung&lt;/h1>
&lt;h2 id="warum-sollte-ich-ubuntu-ersetzen">Warum sollte ich Ubuntu ersetzen?&lt;/h2>
&lt;p>Die meisten von Ihnen verwenden vielleicht Ubuntu für ihre Workstations, und das ist für die unerfahreneren Benutzer in Ordnung. Eines der Probleme, die ich jedoch mit Ubuntu und Tensorflow/CUDA hatte, war, dass der Umgang mit den verschiedenen Treibern und Versionen von CUDA, cudnn, TensorFlow und so weiter ein ziemlicher Kampf war. Bei Ihnen bin ich mir nicht sicher, aber sobald ich eine funktionierende Tensorflow 1.15 oder 2.0-Umgebung hatte, habe ich sie normalerweise nicht mehr angefasst, weil ich Angst hatte, diese heilige Konfiguration durcheinander zu bringen.&lt;/p>
&lt;p>Wenn man mit verschiedenen Programmen arbeitet, wäre es schön, eine Möglichkeit zu haben, zwischen den beiden meistgenutzten TensorFlow Versionen 1.15 und 2.0 zu wechseln, wie man es mit Google Colab mit einem einzigen Befehl tun kann, aber die Installation einer anderen TensorFlow Version hat mein System normalerweise wieder durcheinander gebracht.&lt;/p>
&lt;p>Außerdem stand Arch schon immer auf meiner To-Do-Liste, da es die beste &amp;ldquo;Barebone&amp;rdquo;-Linux-Distribution ist, die man bekommen kann, was bedeutet, dass man im Vergleich zu &amp;ldquo;höheren Abstraktionen&amp;rdquo; wie Ubuntu viel näher an der Hardware arbeitet. Nach ihren eigenen Worten ist Ubuntu dafür gebaut, &amp;ldquo;out of the box zu arbeiten und den Installationsprozess für neue Benutzer so einfach wie möglich zu machen&amp;rdquo;, während das Motto von Arch Linux &amp;ldquo;alles anpassen&amp;rdquo; lautet.
Da Arch viel näher an der Hardware ist, ist es im Vergleich zu Ubuntu wahnsinnig schneller (und Windows meilenweit voraus), und das bei den Kosten für mehr Terminal-Nutzung.&lt;/p>
&lt;p>Wenn ich Arch in den letzten Wochen benutzt habe, hat sich die RAM-Nutzung normalerweise im Vergleich zu Ubuntu halbiert, und die Installation von Machine-Learning-Paketen ist ein Kinderspiel. Ich kann sowohl TensorFlow 1.15 als auch 2.0 zusammenarbeiten lassen, indem ich die Versionen mit Anaconda-Umgebungen austausche. Außerdem arbeitet das System recht stabil, da ich die LTS-Kernel (Long Term Support) von Linux verwende und Aktualisierungen der berühmten AUR-Pakete (User Made Packages in Arch) normalerweise einen Monat vor den Debian-Paketen (Ubuntu) herauskommen.&lt;/p>
&lt;p>Alles in allem kann ich nur empfehlen, eine Arch-Linux-Deep-Learning-Station so einzurichten, wie sie ist:&lt;/p>
&lt;ol>
&lt;li>Schneller, so wie sich Pakete superschnell installieren lassen, ist tiefes Lernen aufgeladen, &amp;hellip;&lt;/li>
&lt;li>Stabiler&lt;/li>
&lt;li>Einfacherer Wechsel zwischen TensorFlow Versionen
im Vergleich zu Ubuntu.&lt;/li>
&lt;/ol>
&lt;p>Ich werde die Anleitung in zwei Teile aufteilen, wobei der erste Teil &amp;ldquo;&lt;a href="//www.datafortress.cloud/blog/howto-install-arch-linux-the-easy-way/">Wie installiere ich Arch Linux&lt;/a>&amp;rdquo; und der zweite Teil &amp;ldquo;&lt;a href="//www.datafortress.cloud/blog/howto-arch-linux-deeplearning-workstation/">Wie installiere ich die Deep-Learning-Workstation-Pakete&lt;/a>&amp;rdquo; lautet.&lt;/p>
&lt;p>Für das allgemeine &lt;a href="//www.datafortress.cloud/blog/howto-install-arch-linux-the-easy-way/">&amp;ldquo;Wie man Arch Linux installiert&amp;rdquo;, gehen Sie zu diesem Artikel&lt;/a>.&lt;/p>
&lt;p>Wenn Arch für den Moment zu komplex ist, könnten Sie &lt;a href="//manjaro.org/">Manjaro&lt;/a> ausprobieren, eine benutzerfreundliche Version von Arch, auch wenn ich nicht garantieren kann, dass alle Pakete gleich funktionieren, da sie leicht unterschiedlich sind. Alles in allem sollte es aber gleich funktionieren.&lt;/p>
&lt;p>Ich habe darüber nachgedacht, ein installationsfertiges Image (iso oder img) zu erstellen, wenn genügend Leute daran interessiert sind, hinterlassen Sie einen Kommentar unten oder schreiben Sie mir eine Nachricht!&lt;/p>
&lt;h2 id="installation-des-deep-learning-tensorflow-cuda-cudnn-anaconda-setups-auf-einer-frischen-arch-linux-installation">Installation des Deep Learning (TensorFlow, CUDA, CUDNN, Anaconda) Setups auf einer frischen Arch-Linux-Installation&lt;/h2>
&lt;p>Wenn Sie &lt;a href="//www.datafortress.cloud/blog/howto-install-arch-linux-the-easy-way/">mit der Installation von Arch (puh!)&lt;/a> fertig sind, lassen Sie uns zunächst einige Einstellungen so ändern, dass unser System stabiler arbeitet.&lt;/p>
&lt;h3 id="1-umschalten-auf-die-schnellsten-spiegel">1. Umschalten auf die schnellsten Spiegel&lt;/h3>
&lt;p>Software wird von so genannten &amp;ldquo;Mirrors&amp;rdquo; heruntergeladen, das sind Server, die alle Arch-Bibliotheken enthalten. Wenn dies nicht automatisch geschieht, kann es passieren, dass Ihre Server noch nicht optimiert sind. Deshalb werden wir ein kleines Tool installieren, das die schnellsten Server findet und speichert, den sogenannten &amp;ldquo;Spiegel&amp;rdquo;.&lt;/p>
&lt;p>Installieren Sie den Reflektor mit&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S reflector&lt;/p>
&lt;/blockquote>
&lt;p>Finden Sie die besten Server und laden Sie sie herunter&lt;/p>
&lt;blockquote>
&lt;p>reflector &amp;ndash;verbose -l 20 -n 20 &amp;ndash;sort rate &amp;ndash;save /etc/pacman.d/mirrorlist&lt;/p>
&lt;/blockquote>
&lt;p>Prüfen Sie die Ausgabe, ob sie sinnvoll ist, z.B. wenn die Domains in der Nähe Ihres Standortes liegen. Wenn nicht, können Sie das Länderkennzeichen hinzufügen, um genauere Ergebnisse zu erhalten, z.B. für Deutschland und Österreich:&lt;/p>
&lt;blockquote>
&lt;p>reflector -c “AT,DE” &amp;ndash;verbose -l 20 -n 20 &amp;ndash;sort rate &amp;ndash;save /etc/pacman.d/mirrorlist&lt;/p>
&lt;/blockquote>
&lt;p>Aktualisieren Sie Ihre Installation&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -Syyu&lt;/p>
&lt;/blockquote>
&lt;h3 id="2-ändern-der-desktop-umgebung">2. Ändern der Desktop-Umgebung&lt;/h3>
&lt;p>Wenn Sie Manjaro verwenden oder die &amp;ldquo;Gnome&amp;rdquo;-Desktop-Umgebung wählen, wie Sie sie von Ubuntu her kennen, könnte es sich lohnen, darüber nachzudenken, sie zu ändern, da Gnome bekanntermaßen mehr RAM als Chrome frisst, und wir in unserem Deep Learning-Setup sicherlich RAM benötigen.&lt;/p>
&lt;p>Wenn Ihnen Gnome gefällt, können Sie diesen Schritt gerne überspringen. Ansonsten kann ich den Xfce-Desktop empfehlen, da er eine gute Kombination aus geringem Gewicht und vielen Funktionen ist.&lt;/p>
&lt;p>Xfce herunterladen&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S xfce4 xfce4-goodies lxdm&lt;/p>
&lt;/blockquote>
&lt;p>Lxdm ist ein Displaymanager, mit dem Sie mehrere Desktops verwenden können.&lt;/p>
&lt;p>Melden Sie sich von Ihrer aktuellen Sitzung ab und drücken Sie Alt + F2 (oder Alt + F3, wenn es nicht funktioniert), um ein Terminal zu erhalten. Deaktivieren Sie zuerst Gnome und &amp;ldquo;aktivieren&amp;rdquo; Sie danach Xfce:&lt;/p>
&lt;blockquote>
&lt;p>sudo systemctl disable gdm &lt;br>
sudo pacman -R gnome gnome-extras&lt;/p>
&lt;/blockquote>
&lt;p>Aktiviere Xfce&lt;/p>
&lt;blockquote>
&lt;p>sudo systemctl enable lxdm &lt;br>
sudo systemctl start lxdm&lt;/p>
&lt;/blockquote>
&lt;p>Wenn die neue Xfce-Arbeitsoberfläche geöffnet wird, melden Sie sich einfach an und erkunden Sie sie, wenn nicht, versuchen Sie einen Neustart (sudo reboot). Wenn das nicht hilft, fahren Sie fort zu weinen und sich auf dem Boden zu wälzen, und senden Sie mir danach eine Nachricht oder einen Kommentar.&lt;/p>
&lt;h3 id="3-installation-der-lts-langzeit-unterstützung-linux-kernel-für-bessere-stabilität">3. Installation der LTS (Langzeit-Unterstützung) Linux-Kernel für bessere Stabilität&lt;/h3>
&lt;p>Arch ist berühmt dafür, dass er den aktuellen Linux-Kerneln sehr nahe kommt, was gut ist, wenn Sie immer die neuesten Pakete und Linux-Funktionen wollen, aber eine schlechte Idee, wenn Sie eine Deep Learning Workstation bauen.&lt;/p>
&lt;p>Deshalb bin ich auf die LTS-Kernel umgestiegen, die im Grunde Kernel sind, die mehr Unterstützung erhalten und stabiler sind als die neueren Versionen des Linux-Kernels.&lt;/p>
&lt;p>Zum Glück ist der Wechsel des Kernels in Arch. Zuerst werden wir die Kernel herunterladen und danach unserem Bootmanager mitteilen, welchen Kernel er wählen soll.&lt;/p>
&lt;p>Zuerst laden wir die LTS-Kernel herunter:&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S linux-lts linux-lts-headers&lt;/p>
&lt;/blockquote>
&lt;p>Werfen Sie einen Blick auf Ihre aktuellen Kernel-Versionen:&lt;/p>
&lt;blockquote>
&lt;p>ls -lsha /boot&lt;/p>
&lt;/blockquote>
&lt;p>Ein Kernel sollte vmlinuz-linux.img und initramfs-linux.img (Ihre aktuellen Versionen) heißen und die LTS-Kernel die gleichen mit -lts am Ende.&lt;/p>
&lt;p>Wenn Sie zwei Kernel sehen, können Sie nun damit fortfahren, die alten Kernel zu löschen:&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -R linux&lt;/p>
&lt;/blockquote>
&lt;p>Ein fortgeschrittener Teil ist nun, dass Sie Ihrem Bootloader mitteilen müssen, welchen Kernel er wählen soll. Die Frage ist, welchen Bootloader Sie verwenden, aber in den meisten Fällen ist es Grub. Wenn Sie &lt;a href="//www.datafortress.cloud/blog/howto-install-arch-linux-the-easy-way/">meinem Arch-Installations-Tutorial gefolgt sind&lt;/a>, ist Ihr Bootloader systemd-boot.&lt;/p>
&lt;p>Meine Empfehlung ist, die Grub-Anweisungen auszuprobieren, und wenn das nicht funktioniert, fahren Sie mit den anderen fort.&lt;/p>
&lt;h4 id="ändern-des-grub-bootloaders-für-die-lts-linux-kernel">Ändern des Grub-Bootloaders für die LTS-Linux-Kernel&lt;/h4>
&lt;blockquote>
&lt;p>grub-mkconfig -o /boot/grub/grub.cfg&lt;/p>
&lt;/blockquote>
&lt;p>Wenn Sie einen Fehler sehen, fahren Sie mit dem nächsten Bootloader fort, andernfalls führen Sie einen Neustart (sudo reboot) durch.&lt;/p>
&lt;h4 id="ändern-des-syslinux-bootloaders-für-die-lts-linux-kernel">Ändern des syslinux-Bootloaders für die LTS-Linux-Kernel&lt;/h4>
&lt;p>Bearbeiten Sie die Konfigurationsdatei:&lt;/p>
&lt;blockquote>
&lt;p>sudo nano /boot/syslinux/syslinux.cfg&lt;/p>
&lt;/blockquote>
&lt;p>Fügen Sie einfach &amp;ldquo;-lts&amp;rdquo; in die vmlinuz-linux.img und initramfs-linux.img ein, so dass sie vmlinuz-linux-lts.img und initramfs-linux-lts.img sind.&lt;/p>
&lt;h4 id="changing-the-systemd-boot-bootloader-for-the-lts-linux-kernels">Changing the systemd-boot bootloader for the LTS linux kernels&lt;/h4>
&lt;p>Wenn Sie aus meiner Arch-Installationsanleitung kommen, ist dies Ihr Bootloader.&lt;/p>
&lt;p>Bearbeiten Sie die Konfigurationsdatei:&lt;/p>
&lt;blockquote>
&lt;p>sudo nano /boot/loader/entries/arch.conf&lt;/p>
&lt;/blockquote>
&lt;p>Fügen Sie einfach &amp;ldquo;-lts&amp;rdquo; in die vmlinuz-linux.img und initramfs-linux.img ein, so dass sie vmlinuz-linux-lts.img und initramfs-linux-lts.img sind&lt;/p>
&lt;h3 id="4-installieren-von-yay-ein-einfacher-weg-aur-pakete-zu-installieren">4. Installieren von yay, ein einfacher Weg, AUR-Pakete zu installieren&lt;/h3>
&lt;p>Sie sollten es vorziehen, den ultraschnellen Pacman zur Installation der meisten Pakete zu verwenden, aber das Erstaunliche an Arch ist, dass Benutzer Millionen von benutzerdefinierten Paketen erstellen, die superleicht zu installieren sind. Sie können im Grunde jedes Programm, das Ihnen einfällt, in diesem Repo finden.&lt;/p>
&lt;p>git SVC installieren&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S git &lt;br>
mkdir ~/tmp &lt;br>
git-clone &lt;a href="https://aur.archlinux.org/yay-git.git">https://aur.archlinux.org/yay-git.git&lt;/a> ~/tmp/yay &lt;br>
cd ~/tmp/yay &lt;br>
makepkg -si&lt;/p>
&lt;/blockquote>
&lt;p>Jetzt können Sie all die schönen AUR-Pakete unter &lt;a href="https://aur.archlinux.org/packages/">https://aur.archlinux.org/packages/&lt;/a> durchstöbern oder einfach loslegen und tippen:&lt;/p>
&lt;blockquote>
&lt;p>yay -S [PAKET]&lt;/p>
&lt;/blockquote>
&lt;p>Um es zu installieren.&lt;/p>
&lt;h3 id="5-schließlich-die-eigentliche-cuda-cudnn-anaconda-installation-auf-der-sowohl-tensorflow-115-als-auch-20-läuft">5. Schließlich die eigentliche cuda, cudnn, anaconda-Installation, auf der sowohl TensorFlow 1.15 als auch 2.0 läuft&lt;/h3>
&lt;p>Installieren Sie Nvidia-Treiber, cuda, cudnn mit einem einfachen Befehl&lt;/p>
&lt;blockquote>
&lt;p>sudo pacman -S nvidia nvidia-utils cuda cudnn&lt;/p>
&lt;/blockquote>
&lt;p>Dies dauert einige Zeit, also holen Sie sich einen Kaffee oder fahren Sie mit den nächsten Schritten fort&lt;/p>
&lt;p>Anakonda herunterladen, ich mag Miniconda:&lt;/p>
&lt;blockquote>
&lt;p>wget &lt;a href="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh">https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh&lt;/a> ~/&lt;/p>
&lt;/blockquote>
&lt;p>Ausführbar machen und installieren&lt;/p>
&lt;blockquote>
&lt;p>cd ~/ &lt;br>
chmod +x ./Miniconda*.sh &lt;br>
./Miniconda*.sh&lt;/p>
&lt;/blockquote>
&lt;p>Lassen Sie einfach alles auf Standard.&lt;/p>
&lt;blockquote>
&lt;p>source ./bash_profile&lt;/p>
&lt;/blockquote>
&lt;p>Starten Sie Ihr System neu&lt;/p>
&lt;blockquote>
&lt;p>sudo reboot&lt;/p>
&lt;/blockquote>
&lt;p>Tensorflow installieren&lt;/p>
&lt;p>Jetzt ist es an der Zeit, sich zwischen TensorFlow für CPU oder GPU zu entscheiden. Ich werde mit der GPU-Option fortfahren, aber wenn Sie die CPU-Version laufen lassen wollen, entfernen Sie einfach das &amp;ldquo;-gpu&amp;rdquo; aus dem Paketnamen.&lt;/p>
&lt;h5 id="erstellen-sie-eine-anakonda-umgebung-für-tensorflow-20">Erstellen Sie eine Anakonda-Umgebung für Tensorflow 2.0&lt;/h5>
&lt;blockquote>
&lt;p>conda create &amp;ndash;name tf2.0 &lt;br>
conda activate tf2.0 &lt;br>
conda pip install &lt;br>
conda install tensorflow-gpu pandas numpy&lt;/p>
&lt;/blockquote>
&lt;p>Erledigt! Überprüfen Sie nun das Ergebnis mit:&lt;/p>
&lt;blockquote>
&lt;p>python &lt;br>
from tensorflow.python.client import device_lib &lt;br>
device_lib.list_local_devices()&lt;/p>
&lt;/blockquote>
&lt;p>Wenn das Ergebnis einen Gerätenamen wie diesen zeigt, sind Sie fertig!&lt;/p>
&lt;p>2018-05-01 05:25:25.929575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Gerät 0 mit Eigenschaften gefunden:
Name: GeForce GTX 3080 10GB Dur: &amp;hellip;&lt;/p>
&lt;h5 id="erstellen-sie-eine-anakonda-umgebung-für-tensorflow-115">Erstellen Sie eine Anakonda-Umgebung für Tensorflow 1.15&lt;/h5>
&lt;blockquote>
&lt;p>conda deactivate &lt;br>
conda create &amp;ndash;name tf1.15 &lt;br>
conda activate tf1.15 &lt;br>
conda install pip python==3.7 &lt;br>
conda install tensorflow-gpu===1.15&lt;/p>
&lt;/blockquote>
&lt;p>Und überprüfen Sie nochmals, ob alles funktioniert und Ihre gpu erkannt wird:&lt;/p>
&lt;blockquote>
&lt;p>python &lt;br>
from tensorflow.python.client import device_lib &lt;br>
device_lib.list_local_devices()&lt;/p>
&lt;/blockquote>
&lt;h3 id="6-umschalten-zwischen-tensorflow-115-und-tensorflow-20-auf-einem-gerät">6. Umschalten zwischen TensorFlow 1.15 und TensorFlow 2.0 auf einem Gerät!&lt;/h3>
&lt;p>Meiner Meinung nach ein Traum der wahr wird, wählen Sie einfach die Version 1.15 mit&lt;/p>
&lt;blockquote>
&lt;p>conda activate tf1.15&lt;/p>
&lt;/blockquote>
&lt;p>Und die TensorFlow 2.0 Version mit&lt;/p>
&lt;blockquote>
&lt;p>conda activate tf2.0&lt;/p>
&lt;/blockquote></description></item></channel></rss>